# SmallCaps Data Certification Suite

**Objetivo:** certificar cientÃ­ficamente que tus datasets cumplen los **pensamientos fundacionales** y son **aptos para backtesting** sin sesgos ni leakage.

## Contenido

```
smallcaps_data_cert_suite/
â”œâ”€â”€ checks/
â”‚   â”œâ”€â”€ _utils.py
â”‚   â”œâ”€â”€ a01_inventory.py
â”‚   â”œâ”€â”€ a02_schema.py
â”‚   â”œâ”€â”€ a03_tick2bar_conservation.py
â”‚   â”œâ”€â”€ a04_labels_logic.py
â”‚   â”œâ”€â”€ a05_weights_stats.py
â”‚   â”œâ”€â”€ a06_universe_pti.py
â”‚   â”œâ”€â”€ a06b_filings_dilution.py
â”‚   â”œâ”€â”€ a07_reproducibility.py
â”‚   â”œâ”€â”€ a08_split_purging.py
â”‚   â”œâ”€â”€ a09_events_schema.py
â”‚   â”œâ”€â”€ a10_events_lineage.py
â”‚   â””â”€â”€ a11_events_consistency.py
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ events_schema.json
â”‚   â””â”€â”€ reference_schema.json
â”œâ”€â”€ config/
â”‚   â””â”€â”€ example_paths.yaml
â””â”€â”€ README_CERTIFICATION.md
```

## Requisitos

- Python 3.10+
- `pip install polars pyarrow numpy`

## EjecuciÃ³n (PowerShell ejemplo)

```powershell
$env:SC_ROOT="D:/04_TRADING_SMALLCAPS"
$env:SC_REPORTS="$env:SC_ROOT/reports/audits"
mkdir $env:SC_REPORTS

python checks/a01_inventory.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a01_inventory.json"
python checks/a02_schema.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a02_schema.json"
python checks/a03_tick2bar_conservation.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a03_tick2bar.json" --sample 500 --tol 0.001
python checks/a04_labels_logic.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a04_labels.json"
python checks/a05_weights_stats.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a05_weights.json" --gini_max 0.9 --eps_sum 1e-6
python checks/a06_universe_pti.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a06_universe_pti.json" --mc_max 2000000000 --float_max 100000000 --pmin 0.5 --pmax 20.0 --volmin 500000 --chgmin 0.15
python checks/a06b_filings_dilution.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a06b_filings.json" --window_days 10
python checks/a07_reproducibility.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a07_repro.json"
python checks/a08_split_purging.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a08_split.json" --purge 50
python checks/a09_events_schema.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a09_events_schema.json"
python checks/a10_events_lineage.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a10_events_lineage.json"
python checks/a11_events_consistency.py --root "$env:SC_ROOT" --out "$env:SC_REPORTS/a11_events_consistency.json"
```

## GO/NO-GO

**GO** si:
1. A01â€“A11 = PASS
2. ConservaciÃ³n tickâ†’barra < 0.1%
3. Universo *pointâ€‘inâ€‘time* cumple marketcap/float/precio/vol/%chg/exchange
4. Filings de diluciÃ³n trazados
5. Î£ weights = 1 y Gini < 0.9
6. Split sin leakage (purge â‰¥ 50)
7. Eventos ML (esquema/lineage/consistencia) OK




# 3 maneras de ejecutar la suite **a tope de rÃ¡pido**, sin tocar los scripts.

# 0) PreparaciÃ³n (una vez)

* Pon los datos y la carpeta `smallcaps_data_cert_suite/` en **SSD/NVMe local** (evita discos de red).
* Instala deps: `pip install polars pyarrow numpy`
* Variables para usar **todos tus cores**:

* PowerShell:

```sh
$env:SC_ROOT="D:/04_TRADING_SMALLCAPS"
$env:SC_REPORTS="$env:SC_ROOT/reports/audits"
$env:POLARS_MAX_THREADS=[Environment]::ProcessorCount
mkdir $env:SC_REPORTS -Force | Out-Null
```
* Bash (WSL/Git Bash):

```sh
export SC_ROOT="D:/04_TRADING_SMALLCAPS"
export SC_REPORTS="$SC_ROOT/reports/audits"
export POLARS_MAX_THREADS=$(nproc)
mkdir -p "$SC_REPORTS"
```

---

### 1) PowerShell 7 â€” **Paralelo real** (rÃ¡pido y simple)

Copia/pega y ejecuta (usa 8 tareas simultÃ¡neas; ajusta `-ThrottleLimit`):

```powershell
$checks = @(
  "python checks/a01_inventory.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a01_inventory.json`"",
  "python checks/a02_schema.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a02_schema.json`"",
  "python checks/a03_tick2bar_conservation.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a03_tick2bar.json`" --sample 300 --tol 0.001",
  "python checks/a04_labels_logic.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a04_labels.json`"",
  "python checks/a05_weights_stats.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a05_weights.json`"",
  "python checks/a06_universe_pti.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a06_universe_pti.json`" --mc_max 2000000000 --float_max 100000000 --pmin 0.5 --pmax 20.0 --volmin 500000 --chgmin 0.15",
  "python checks/a06b_filings_dilution.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a06b_filings.json`" --window_days 10",
  "python checks/a07_reproducibility.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a07_repro.json`"",
  "python checks/a08_split_purging.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a08_split.json`" --purge 50",
  "python checks/a09_events_schema.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a09_events_schema.json`"",
  "python checks/a10_events_lineage.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a10_events_lineage.json`"",
  "python checks/a11_events_consistency.py --root `"$env:SC_ROOT`" --out `"$env:SC_REPORTS/a11_events_consistency.json`""
)

$checks |
  ForEach-Object -Parallel { & cmd.exe /c $_ } -ThrottleLimit 8 |
  Out-Host
```

âœ”ï¸ Esto lanza **todas** las verificaciones en paralelo.
ðŸ’¡ Para un *smoke test* ultra-rÃ¡pido, baja el muestreo de A03: `--sample 100`.

---

### 2) Git Bash / WSL + GNU Parallel (tambiÃ©n muy rÃ¡pido)

Si tienes `parallel`, ejecuta:

```bash
cat > /tmp/checks.list <<'EOF'
python checks/a01_inventory.py --root "$SC_ROOT" --out "$SC_REPORTS/a01_inventory.json"
python checks/a02_schema.py --root "$SC_ROOT" --out "$SC_REPORTS/a02_schema.json"
python checks/a03_tick2bar_conservation.py --root "$SC_ROOT" --out "$SC_REPORTS/a03_tick2bar.json" --sample 300 --tol 0.001
python checks/a04_labels_logic.py --root "$SC_ROOT" --out "$SC_REPORTS/a04_labels.json"
python checks/a05_weights_stats.py --root "$SC_ROOT" --out "$SC_REPORTS/a05_weights.json"
python checks/a06_universe_pti.py --root "$SC_ROOT" --out "$SC_REPORTS/a06_universe_pti.json" --mc_max 2000000000 --float_max 100000000 --pmin 0.5 --pmax 20.0 --volmin 500000 --chgmin 0.15
python checks/a06b_filings_dilution.py --root "$SC_ROOT" --out "$SC_REPORTS/a06b_filings.json" --window_days 10
python checks/a07_reproducibility.py --root "$SC_ROOT" --out "$SC_REPORTS/a07_repro.json"
python checks/a08_split_purging.py --root "$SC_ROOT" --out "$SC_REPORTS/a08_split.json" --purge 50
python checks/a09_events_schema.py --root "$SC_ROOT" --out "$SC_REPORTS/a09_events_schema.json"
python checks/a10_events_lineage.py --root "$SC_ROOT" --out "$SC_REPORTS/a10_events_lineage.json"
python checks/a11_events_consistency.py --root "$SC_ROOT" --out "$SC_REPORTS/a11_events_consistency.json"
EOF

parallel -j $(nproc) < /tmp/checks.list
```

---

### 3) Runner incluido + multi-proceso del SO (rÃ¡pido y ordenado)

Usa el runner que ya te dejÃ© y permite que el SO paralelice E/S entre procesos Python:

```powershell
python run_all_checks.py
```

Si quieres **paralelizar por lotes**, abre 2â€“3 consolas y reparte comandos (p.ej. en una A01â€“A05, en otra A06â€“A08, en otra A09â€“A11).

---

### Ajustes prÃ¡cticos para â€œmodo turboâ€

* **Baja muestreo de A03** si solo quieres *smoke test*: `--sample 100` (luego subes a 300â€“500 para certificaciÃ³n).
* **Cierra antivirus** para la carpeta del proyecto (o exclÃºyela) si tu equipo lo permite â€” reduce E/S bloqueante.
* **Evita subprocesos innecesarios** abiertos en el mismo disco (copias, compresiones, etc.).
* MantÃ©n `POLARS_MAX_THREADS` al nÃºmero de cores fÃ­sicos o lÃ³gicos disponibles.
* Si el disco es NVMe, pon **datos y scripts en el mismo volumen**.

`summary_semÃ¡foro.py` que lea todos los JSON de `reports/audits` y te imprima el **GO/NO-GO** con los umbrales.