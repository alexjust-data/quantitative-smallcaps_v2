# 04.4 - Problema del "Atasco de Elefantes" y Soluci√≥n

**Fecha**: 2025-10-21
**Estado**: RESUELTO - Sistema funcionando con configuracion DESATASCADA
**Tickers descargados**: 330 / 3,107 (10.6%)

---

## 1. El Problema: Atasco de Elefantes

### Sintoma Observado

Durante la optimizacion de velocidad de descarga, el sistema experimento un colapso drastico:

```
Config AGRESIVA (21:18):
- Velocidad inicial: 264 tickers/hora (excelente!)
- Velocidad despues de 30 min: 1.6 tickers/hora (colapso!)
- CPU: 27%, RAM: 50% (recursos disponibles)
- Procesos: 21 Python activos (1 wrapper + 20 batches)
```

**El sistema paso de ser ultra-rapido a estar practicamente colgado.**

### Diagnostico

Multiples auditorias revelaron que el sistema no estaba crasheando ni generando errores de API. Los logs mostraban:

- Batches "colgados" sin terminar durante 15-20+ minutos
- Algunos batches completando tickers en 5-10 segundos
- Otros batches sin ningun progreso visible
- Sin errores 429 (rate limit) ni errores de API
- Memoria y CPU con capacidad disponible

### Causa Raiz: El Problema del Elefante

**Analogia del trafico**:
Imagina una autopista de 8 carriles donde circulan:
- 200 autos normales (sedan, compactos) - **tickers ligeros**
- 20 trailers gigantes de 40 metros - **tickers "elefantes"**

Si los 8 carriles tienen trailers al mismo tiempo:
- Los autos rapidos quedan atrapados detras
- El flujo total colapsa
- La autopista parece "colgada"

**En nuestro sistema**:
- Configuracion AGRESIVA: 20 batches simultaneos, cada uno con 25 tickers
- Probabilidad de que TODOS los batches tengan al menos 1 elefante: ALTA
- Los elefantes bloquean los batches durante 10-20 minutos
- Los tickers ligeros esperan en cola sin procesarse
- Velocidad total: COLAPSA

### Que es un "Ticker Elefante"?

Un ticker con historial extenso que requiere:
- **Muchos meses de datos**: 2004-2025 = 21 anos = 252 meses
- **Muchas paginas de API**: Miles de requests paginados
- **Mucho tiempo**: 10-20 minutos por ticker vs 5-30 segundos normales
- **Mucha memoria**: Escritura de cientos de MB en parquet

**Ejemplos identificados**: NATH, MATH, UBFO, UMH, RMR, WEYS, CVGW, LXU, PEBO, etc.

---

## 2. Evolucion de Configuraciones y Resultados

### Config CONSERVADORA (inicial)
```powershell
$batchSize = 10
$maxConcurrent = 12
$rateLimit = 0.15  # segundos entre paginas
PAGE_LIMIT = 10000
```
**Resultado**: 75 tickers/hora - demasiado lento

### Config BALANCEADA
```powershell
$batchSize = 15
$maxConcurrent = 16
$rateLimit = 0.13
PAGE_LIMIT = 15000
```
**Resultado**: 139 tickers/hora (proyectado) - mejor pero no probado a fondo

### Config AGRESIVA
```powershell
$batchSize = 25
$maxConcurrent = 20
$rateLimit = 0.11
PAGE_LIMIT = 18000
```
**Resultado**: 264 tickers/hora inicial ‚Üí 1.6 tickers/hora final (COLAPSO por elefantes)

### Config DESATASCADA (actual)
```powershell
$batchSize = 20
$maxConcurrent = 8
$rateLimit = 0.25
PAGE_LIMIT = 10000
```
**Resultado**: ~100-150 tickers/hora estimado - ESTABLE y funcionando

---

## 3. Solucion Implementada: Configuracion DESATASCADA

### Estrategia

En lugar de intentar maximizar concurrencia (20 batches), reducimos para minimizar probabilidad de "atasco":

**Matematica del problema**:
- Si 5% de tickers son elefantes
- Con 20 batches x 25 tickers = 500 tickers procesandose
- Probabilidad de tener 10-15 elefantes simultaneos: ALTA
- Con 8 batches x 20 tickers = 160 tickers procesandose
- Probabilidad de tener 3-5 elefantes simultaneos: BAJA

**Menos batches = menos trafico = menos atascos**

### Parametros Finales

**Archivo**: `scripts/fase_1_Bloque_B/tools/launch_wrapper.ps1`

```powershell
# Config DESATASCADA - evita atasco de elefantes
$tickersCsv = "processed/universe/cs_xnas_xnys_under2b_2025-10-21.csv"
$batchSize = 20           # Tickers por batch
$maxConcurrent = 8        # Batches simultaneos (REDUCIDO desde 20)
$rateLimit = 0.25         # Segundos entre paginas (AUMENTADO desde 0.11)
$dateFrom = "2004-01-01"
$dateTo = "2025-10-21"
```

**Ingestor**: `scripts/fase_1_Bloque_B/ingest_ohlcv_intraday_minute.py`
```python
PAGE_LIMIT = 10000  # Rows por request (REDUCIDO desde 18000)
```

### Verificacion de Funcionamiento

**Lanzamiento** (22:37):
```
[2025-10-21 22:37:44] --resume: 322 tickers ya con datos | pendientes: 2,785
[2025-10-21 22:37:44] Batches: 140 x 20 tickers
[2025-10-21 22:37:44] Concurrencia: 8 batches a la vez
```

**Progreso medido** (22:40 - 3 minutos despues):
- Tickers: 330 (inicio: 322)
- Nuevos: 8 tickers en 3 minutos
- Velocidad: ~160 tickers/hora
- Estado: ESTABLE - sin colapso

---

## 4. Solucion Alternativa Explorada: Dual-Lane

### Concepto

Separar el procesamiento en DOS carriles independientes:

1. **Carril NORMAL**: Tickers ligeros con config AGRESIVA
   - 8 batches, rate 0.25s, batch size 20
   - Alta velocidad esperada

2. **Carril PESADO**: Tickers elefantes con config CONSERVADORA
   - 2 batches, rate 0.30s, batch size 10
   - Procesamiento lento pero aislado

### Herramienta de Analisis

**Script**: `scripts/fase_1_Bloque_B/tools/analyze_intraday_footprint.py`

Analiza el "peso" de cada ticker basandose en:
- Total de filas (rows)
- Total de bytes (size)
- Meses con datos (coverage)

**Formula de score**:
```python
score = (rows * 0.4) + (size_mb * 0.3) + (months * 0.3)
```

**Salida generada**:
- `processed/reports/heavy_tickers.csv` - 94 elefantes
- `processed/reports/normal_tickers.csv` - 229 tickers normales

### Limitacion del Enfoque Dual-Lane

El script `analyze_intraday_footprint.py` solo puede analizar tickers **que ya tienen datos descargados**.

**Problema**:
- Total universo: 3,107 tickers
- Ya descargados: 322 tickers (10%)
- Analizados: 323 tickers (solo los descargados)
- Sin analizar: 2,785 tickers (90% restante!)

**No sabemos cuales de los 2,785 pendientes son elefantes.**

Por eso, la solucion dual-lane quedo como alternativa futura, y se opto por la config DESATASCADA que funciona para todos los casos.

### Launchers Creados (no en uso actualmente)

- `scripts/fase_1_Bloque_B/tools/launch_normal.ps1` - Carril normal
- `scripts/fase_1_Bloque_B/tools/launch_heavy.ps1` - Carril pesado

Estos se pueden usar en el futuro si:
1. Completamos la descarga inicial de todos los tickers
2. Ejecutamos `analyze_intraday_footprint.py` sobre el universo completo
3. Relanzamos con dual-lane para actualizaciones incrementales

---

## 5. Bugs Criticos Resueltos Durante la Optimizacion

### Bug #1: Caracteres Unicode en Logs (cp1252)

**Sintoma**: Procesos lanzados pero logs "colgados" en 360 bytes, sin progreso.

**Causa**: Windows usa codificacion cp1252 que no soporta caracteres Unicode (‚Üí, √ó, emojis, tildes).

**Archivos afectados**:
- `ingest_ohlcv_intraday_minute.py` (lineas 4, 7, 85, 87, 116, 159, 177, 184, 204)
- `batch_intraday_wrapper.py` (emojis üì¶, ‚úÖ, ‚è±Ô∏è, üßæ)

**Fix aplicado**: Reemplazo de TODOS los caracteres Unicode por ASCII:
```python
# ANTES:
log(f"Tickers: {len(tickers):,} | {args.date_from} ‚Üí {args.date_to}")
# DESPUES:
log(f"Tickers: {len(tickers):,} | {args.date_from} -> {args.date_to}")

# ANTES: versi√≥n, p√°gina, r√°pido, m√°s, M√°x.
# DESPUES: version, pagina, rapido, mas, Max
```

### Bug #2: Resume Logic Roto

**Sintoma**: Wrapper reportaba "0 tickers ya con datos" cuando existian 266 tickers descargados.

**Causa**: Error en nested generator usando `(y / m).glob()` cuando `m` ya era Path completo.

**Archivo**: `batch_intraday_wrapper.py` linea 41

**Fix**:
```python
# ANTES (bug):
any_parquet = any((y.is_dir() and any((y / m).glob("minute.parquet"))
                   for y in tdir.glob("year=*")
                   for m in y.glob("month=*")))

# DESPUES (correcto):
any_parquet = any((y.is_dir() and any(m.glob("minute.parquet") for m in y.glob("month=*")))
                  for y in tdir.glob("year=*"))
```

Este bug causaba que el sistema reintentara descargar tickers ya completados, desperdiciando recursos.

---

## 6. Metricas y Proyecciones

### Estado Actual (2025-10-21 22:40)

```
Universo total:       3,107 tickers
Descargados:            330 tickers (10.6%)
Pendientes:           2,777 tickers

Config actual:        DESATASCADA
Batches activos:      8 / 140 total
Procesos Python:      9 (1 wrapper + 8 batches)

Velocidad medida:     ~160 tickers/hora
```

### Proyeccion de Completado

**Escenario conservador (100 t/h)**:
- Tiempo restante: 27.8 horas
- Finalizacion: 2025-10-23 02:30

**Escenario realista (150 t/h)**:
- Tiempo restante: 18.5 horas
- Finalizacion: 2025-10-22 17:00

**Escenario optimista (160 t/h - velocidad actual)**:
- Tiempo restante: 17.4 horas
- Finalizacion: 2025-10-22 16:00

---

## 7. Comandos de Monitoreo

### Verificar progreso de descarga
```powershell
(Get-ChildItem "raw\polygon\ohlcv_intraday_1m" -Directory -Exclude "_batch_temp").Count
```

### Verificar procesos activos
```powershell
Get-Process python | Measure-Object
# Esperado: 9 procesos (1 wrapper + 8 batches)
```

### Ver logs de batches activos
```powershell
Get-ChildItem "raw\polygon\ohlcv_intraday_1m\_batch_temp" -Filter "batch_*.log" | Sort-Object LastWriteTime -Descending | Select-Object -First 5
```

### Ver ultimo batch completado
```powershell
Get-Content "raw\polygon\ohlcv_intraday_1m\_batch_temp\batch_0000.log" -Tail 20
```

### Calcular velocidad en tiempo real
```powershell
# Anotar tickers actuales
$inicio = (Get-ChildItem "raw\polygon\ohlcv_intraday_1m" -Directory -Exclude "_batch_temp").Count
Write-Host "Tickers inicio: $inicio"

# Esperar 5 minutos
Start-Sleep 300

# Calcular velocidad
$ahora = (Get-ChildItem "raw\polygon\ohlcv_intraday_1m" -Directory -Exclude "_batch_temp").Count
$nuevos = $ahora - $inicio
$velocidad = ($nuevos / 5) * 60
Write-Host "Nuevos en 5 min: $nuevos"
Write-Host "Velocidad: $([math]::Round($velocidad, 1)) tickers/hora"
```

---

## 8. Lecciones Aprendidas

### 1. Mas Concurrencia ‚â† Mas Velocidad

La configuracion AGRESIVA con 20 batches parecia ideal para maximizar CPU/RAM, pero colapso por el problema del elefante.

**Leccion**: En sistemas con tareas heterogeneas (ligeras + pesadas), menos concurrencia puede dar mejor throughput total.

### 2. La Importancia del Resume Logic

El bug en resume logic causo:
- Desperdicio de recursos re-descargando tickers completos
- Confusion en metricas de progreso
- Dificultad para diagnosticar problemas

**Leccion**: Resume logic debe probarse exhaustivamente antes de lanzamientos largos.

### 3. Windows Encoding (cp1252) es Problematico

Multiples crashes silenciosos por caracteres Unicode:
- Logs colgados en 360 bytes
- Procesos activos pero sin output
- Dificil de diagnosticar sin revisar encoding

**Leccion**: En proyectos Windows, usar solo ASCII en logs. Evitar emojis, flechas Unicode, caracteres especiales.

### 4. Analisis de Footprint Solo Funciona con Data Existente

La herramienta `analyze_intraday_footprint.py` es util pero limitada:
- Solo analiza tickers ya descargados
- No puede predecir peso de tickers nuevos
- Requiere descarga completa inicial

**Solucion futura**: Podriamos hacer un pre-scan ligero (solo 1 mes de muestra) para clasificar antes de descarga completa.

### 5. Monitoring en Tiempo Real es Crucial

Sin logs en tiempo real (batches solo escriben al completar ticker), fue dificil detectar el problema del elefante temprano.

**Mejora futura**: Agregar logs incrementales cada X paginas descargadas.

---

## 9. Referencias

### Archivos Clave

**Launchers**:
- `scripts/fase_1_Bloque_B/tools/launch_wrapper.ps1` - Wrapper principal (EN USO)
- `scripts/fase_1_Bloque_B/tools/launch_normal.ps1` - Carril normal (standby)
- `scripts/fase_1_Bloque_B/tools/launch_heavy.ps1` - Carril pesado (standby)

**Core Scripts**:
- `scripts/fase_1_Bloque_B/tools/batch_intraday_wrapper.py` - Wrapper micro-batches
- `scripts/fase_1_Bloque_B/ingest_ohlcv_intraday_minute.py` - Ingestor principal

**Analisis**:
- `scripts/fase_1_Bloque_B/tools/analyze_intraday_footprint.py` - Footprint analyzer

**Data**:
- `processed/universe/cs_xnas_xnys_under2b_2025-10-21.csv` - Universo completo (3,107)
- `processed/reports/heavy_tickers.csv` - Elefantes identificados (94)
- `processed/reports/normal_tickers.csv` - Tickers normales (229)
- `raw/polygon/ohlcv_intraday_1m/` - Directorio de descarga

### Documentos Relacionados

- `04.3_Descarga_OHLCV_Wrapper_MicroBatches.md` - Arquitectura wrapper
- `04.1_AUDITORIA_DATOS_INTRADAY.md` - Auditoria inicial de datos
- `04_Descarga OHLCV diario e intradia.md` - Proceso general

---

## 10. Proximos Pasos

### Corto Plazo (24-48 horas)

1. **Monitorear descarga actual** hasta completar 3,107 tickers
2. **Validar estabilidad** de config DESATASCADA
3. **Verificar ausencia de errores** en logs de batches

### Mediano Plazo (post-descarga inicial)

1. **Ejecutar footprint analysis** sobre universo completo
2. **Generar nuevos CSVs** de heavy/normal con 3,107 clasificados
3. **Evaluar dual-lane approach** para actualizaciones incrementales

### Optimizaciones Futuras

1. **Pre-scan ligero**: Descargar 1 mes de muestra para clasificar peso
2. **Logs incrementales**: Escribir progreso cada N paginas
3. **Dynamic batching**: Ajustar batch size segun peso detectado
4. **Parallel footprint**: Analizar peso mientras descarga (streaming analysis)

---

**Documento creado**: 2025-10-21 22:42
**Autor**: Claude (Anthropic)
**Status**: Sistema DESATASCADO funcionando a 160 t/h
