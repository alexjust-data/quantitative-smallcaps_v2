# Qué datos tienes y para qué sirve cada uno

* **Referencia (universo sin sesgo)**: lista de tickers (activos y delistados) + detalles.
  → Sirve para evitar sesgo de supervivencia y reconstruir universos históricos por fecha.

* **OHLCV diario (20 años)**: velas diarias.
  → Sirve para ver *regímenes*, %change diarios, ATR, validaciones y guard-rails.

* **OHLCV 1-min (20 años)**: velas por minuto.
  → Sirve para medir **actividad del día** (RVOL, dollar-volume, %chg intradía) y para detectar *runners*.
  → También será tu “malla” base si algún día no tienes ticks.

> **Aún no** has bajado **ticks (trades/quotes)** → lo haremos **solo para lo que importa** (info-rich).

---

## 1) Qué significa “info-rich” y **por qué** lo hacemos

Tus setups (Gap&Go, VWAP reclaim, First Red Day, OGD, LDF…) **solo aparecen** cuando el día está “encendido”:

* **RVOL** (volumen relativo) alto → hay participación anómala.
* **%chg** diario grande (positivo o negativo) → hay *momentum* o *flush*.
* **Dollar-volume** elevado → hay **liquidez real** (no “humo”).

**Filtro típico (parametrizable):**
`info_rich = (rvol30 ≥ 2) AND (|%chg| ≥ 15%) AND (dollar_vol ≥ $5M) AND (0.5 ≤ precio ≤ 20)`

Con esto pasas de miles de tickers a **100–400 al día** que **sí** merecen bajar **tick-level**.

---

## 2) Archivo que genera la *watchlist* y el **TopN12m** (qué es y cómo usarlo)

* **Watchlist diaria (por fecha)**: para cada día `D`, guarda los tickers que cumplen `info_rich`.
  Ruta sugerida:

  ```
  processed/universe/info_rich/daily/date=YYYY-MM-DD/watchlist.parquet
  ```

  Columnas: `ticker, date, close_d, pctchg_d, rvol30, vol_d, dollar_vol_d, info_rich, (market_cap opcional)`

* **TopN12m**: ranking de *runners recurrentes* en los **últimos 12 meses x 5 años** (≈252 sesiones x 5 años).
  ¿Cómo se calcula? Cuenta cuántos días “info-rich” ha tenido cada ticker en ese periodo y ordena por (frecuencia, recencia).
  Te da **un club de reincidentes** (los típicos “ralliers” de small caps).
  Lo usas para:

  * Priorizar descargas **tick** históricas (si quieres ampliar más atrás).
  * Dar más peso a tickers “de personalidad volátil” al entrenar.

> Con lo anterior, ya tienes **un fichero por día** (para el *live* o backfill) y **una lista global 12m x 5 años** para estrategias.

---

## 3) **Procedimiento operativo** (lo que harías cada día y para backfill)

### 3.1 Backfill (reconstruir años pasados para empezar con todo armado)

1. **Genera info-rich** desde tus 1-min descargados:

```bash
python scripts/fase_C_ingesta_tiks/build_dynamic_universe.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/universe/info_rich \
  --from 2017-01-01 --to 2025-10-21 \
  --rvol-th 2.0 --pctchg-th 0.15 --dvol-th 5000000 \
  --cap-filter-parquet processed/ref/tickers_dim/tickers_dim.parquet \
  --cap-max 2000000000
```

→ Resultado: *watchlists* por día + `topN_12m.csv`.

2. **Decide a quién bajar ticks**:

   * **Diario de hoy (y de días del backtest)**: usa la *watchlist* de ese día.
   * **Estudio histórico profundo**: usa `topN_12m.csv` para priorizar tickers “reincidentes”.

3. **Descarga ticks (trades y/o quotes) solo de esos tickers** (por ventanas; rolling 3–5 años si quieres limitar).

   * Puedes reutilizar tu **wrapper por batches** y escribir un `ingest_trades_day.py` análogo al de 1-min.

4. **Construye barras informacionales (DIB/VIB)** desde los **trades**:

   * Dollar/Volume/Imbalance Bars → más homogéneas estadísticamente que 1-min.
   * Si aún no tienes trades para un día, **usa 1-min como fallback** para correr detectores.

### 3.2 Operación diaria (EOD o intradía)

1. Llegan las nuevas 1-min del día → **recalculas info-rich del día** → *watchlist* `date=HOY`.
2. Con esa *watchlist* descargas ticks del mismo día (o de una ventana fija reciente).
3. Construyes DIB/VIB y corres detectores / etiquetas / modelos.

---

## 4) ¿Dónde encaja “la mezcla” con lo de tu compañero?

Tu compañero ya tiene **detectores intradía** (VWAP break, ORB, flush, consolidation break…) que están bien.
La **diferencia clave** es **cuándo y dónde** ejecutarlos:

* **Él**: corre detectores sobre **Top-2000 por frecuencia** (derivado de su *propio* detector diario) → riesgo de **circularidad** y **sesgo**.
* **Tú** (lo que propongo): corre **exactamente esos detectores**, pero **solo** sobre la **watchlist info-rich** del día (definida por *estadística simple*, independiente de los detectores).

  * Evitas circularidad.
  * Ahorra cómputo (miles → cientos).
  * Mantienes neutralidad (sirve long **y** short).

### Integración práctica (paso a paso)

**Paso A — Generar watchlist del día D**
(ya visto en §3)

**Paso B — Adaptar detectores intradía**

* Cambia el “input universo” de `detect_events_intraday.py` para que lea:
  `processed/universe/info_rich/daily/date=D/watchlist.parquet`
  en lugar de “Top-2000 por frecuencia” u “universo completo”.

* Fuente de barras para detectores:

  1. **Si tienes trades de ese día** → usa **DIB/VIB** (mejor).
  2. Si **no** → usa **1-min** (tu malla).
     → La lógica de los detectores no cambia (VWAP reclaim, ORB, flush…), **solo cambia la “serie” de entrada**.

**Paso C — Etiquetado robusto (López de Prado)**

* Por cada *evento* detectado (sea de tu compi o tuyo), aplica **Triple Barrier**:

  * Barrera superior (profit) = +k·σ
  * Barrera inferior (stop)   = −m·σ
  * Barrera vertical (timeout) en T minutos/horas
* Obtienes una etiqueta objetiva: **continuación / reversión / timeout**.
* Esto convierte “eventos detectados” en **dataset supervisado** para ML.

**Paso D — Muestras y validación**

* **Sample Weights** por *unicidad* (evita sobre-contar eventos solapados) + **time-decay**.
* **Purged walk-forward** (o purged k-fold) para evitar *look-ahead*.
* **FFD** en features no estacionarias (precios/vwap acumulados).

---

## 5) ¿Qué ganas con esta mezcla?

1. **Menos sesgos**: el *universo info-rich* no depende de los detectores →
   evaluamos los detectores **sin circularidad**.

2. **Ahorro masivo de cómputo**: del universo completo pasas a **solo los días/tickers vivos**.
   Eso permite **tick-level** y **DIB/VIB** donde realmente suma.

3. **Mayor calidad**: cuando hay ticks, las DIB/VIB dan señales más limpias (menos ruido que 1-min).

4. **Portabilidad**: si mañana cambias detectores, la “capa info-rich” sigue válida (es estadística básica).

---

## 6) “Receta” concreta con comandos (ejemplo de un día)

### 6.1 Generar la *watchlist* del día D

```bash
python scripts/fase_C_ingesta_tiks/build_dynamic_universe.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/universe/info_rich \
  --from 2025-10-21 --to 2025-10-21 \
  --rvol-th 2.0 --pctchg-th 0.15 --dvol-th 5000000 \
  --cap-filter-parquet processed/ref/tickers_dim/tickers_dim.parquet \
  --cap-max 2000000000
```

### 6.2 Descargar **ticks** solo de esa *watchlist*

(Usa tu wrapper por batches pasando ese CSV/Parquet como universo temporal)

```bash
# Ejemplo conceptual (tu wrapper espera CSV con columna 'ticker')
python scripts/fase_C_ingesta_tiks/tools/batch_intraday_wrapper.py \
  --tickers-csv processed/universe/info_rich/daily/date=2025-10-21/watchlist.csv \
  --outdir raw/polygon/trades \
  --from 2025-10-21 --to 2025-10-21 \
  --batch-size 20 --max-concurrent 8 --rate-limit 0.2 \
  --ingest-script scripts/fase_C_ingesta_tiks/ingest_trades_day.py \
  --resume
```

### 6.3 Construir **DIB/VIB** para esos tickers/día

```bash
python scripts/fase_C_ingesta_tiks/build_bars.py \
  --trades-root raw/polygon/trades \
  --outdir processed/bars \
  --bar-type dollar_imbalance --bar-value 10000 \
  --date 2025-10-21
```

### 6.4 Correr **detectores intradía** de tu compañero **solo** sobre esta lista

* Modifica `detect_events_intraday.py` para que lea la *watchlist* del día y use:

  * `processed/bars/<ticker>/...` si existen (DIB/VIB),
  * si no existen, `raw/polygon/ohlcv_intraday_1m/<ticker>/...` (1-min).

### 6.5 **Triple Barrier** + **Sample Weights**

```bash
python scripts/labeling/triple_barrier.py \
  --events processed/events/events_intraday_2025-10-21.parquet \
  --prices processed/bars_or_1min/... \
  --pt-mult 3 --sl-mult 2 --t1 "90m" \
  --out processed/labels/labels_2025-10-21.parquet

python scripts/labeling/sample_weights.py \
  --labels processed/labels/labels_2025-10-21.parquet \
  --out processed/labels/weights_2025-10-21.parquet
```

---

## 7) Dudas típicas resueltas

* **“¿TopN12m es necesario?”** Sí. No decide el día-a-día (eso lo hace la *watchlist* diaria),
  pero sí **prioriza** dónde merece la pena profundizar tick-level hacia atrás (tus reincidentes).

* **“¿Y si no tengo trades de un día?”** No pasa nada: usas **1-min** para detectores y etiquetas.
  Cuando luego tengas **trades**, podrás reconstruir DIB/VIB y re-evaluar.

* **“¿Por qué no correr detectores sobre todo el universo?”**
  Porque el coste (tick, CPU) se dispara y **la mayoría de días/tickers están muertos**.
  La capa *info-rich* separa el grano de la paja con reglas simples, neutras y baratas.

---

# Resumen en una línea

1. **Filtra** con 1-min → *watchlist diaria* + *TopN12m*.
2. **Descarga ticks** solo para esa watchlist.
3. **Construye DIB/VIB** y **corre detectores** (los vuestros o los de tu compi).
4. **Etiqueta** con **Triple Barrier** + **Sample Weights**.
5. **Entrena/valida** (walk-forward, FFD) y **opera**.

Si quieres, te preparo el “pegamento” para que `detect_events_intraday.py` acepte como **input** la *watchlist* diaria y escoja **DIB/VIB** si existen, o **1-min** en su defecto.
