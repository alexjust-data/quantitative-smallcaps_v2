{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validacion Multi-Event Fuser\n",
    "\n",
    "**Fecha**: 2025-10-28  \n",
    "**Objetivo**: Validar el Multi-Event Fuser confirmando E.2_multi_event_fuser.md\n",
    "\n",
    "---\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. Cargar watchlist consolidada\n",
    "2. Validar schema (11 columnas ML-ready)\n",
    "3. Verificar metricas clave\n",
    "4. Validar top 10 combinaciones\n",
    "5. Validar coherencia con eventos originales\n",
    "6. Deserializar JSON details (validacion tecnica)\n",
    "7. Generar visualizaciones\n",
    "8. Resumen ejecutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print('=' * 80)\n",
    "print('VALIDACION MULTI-EVENT FUSER')\n",
    "print('=' * 80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar Watchlist Consolidada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar watchlist\n",
    "watchlist_file = Path('../../../../processed/watchlist/multi_event_watchlist.parquet')\n",
    "metadata_file = Path('../../../../processed/watchlist/watchlist_metadata.json')\n",
    "\n",
    "print(f'Cargando watchlist desde: {watchlist_file}')\n",
    "df_watchlist = pl.read_parquet(watchlist_file)\n",
    "\n",
    "print(f'Cargando metadata desde: {metadata_file}')\n",
    "with open(metadata_file) as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print()\n",
    "print(f'Watchlist cargada: {len(df_watchlist):,} entries')\n",
    "print(f'Metadata cargada: {len(metadata)} keys')\n",
    "print()\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print('Primeras 5 filas:')\n",
    "df_watchlist.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validar Schema (11 Columnas ML-Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('VALIDACION SCHEMA')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# Columnas esperadas\n",
    "expected_columns = [\n",
    "    'ticker', 'date', 'event_types', 'num_events', 'event_details',\n",
    "    'has_e1', 'has_e4', 'has_e7', 'has_e8',\n",
    "    'event_combination', 'is_multi_event'\n",
    "]\n",
    "\n",
    "# Verificar columnas\n",
    "actual_columns = df_watchlist.columns\n",
    "missing = set(expected_columns) - set(actual_columns)\n",
    "extra = set(actual_columns) - set(expected_columns)\n",
    "\n",
    "print(f'Columnas esperadas: {len(expected_columns)}')\n",
    "print(f'Columnas actuales: {len(actual_columns)}')\n",
    "print()\n",
    "\n",
    "if len(missing) == 0 and len(extra) == 0:\n",
    "    print('[OK] Schema correcto: 11 columnas presentes')\n",
    "else:\n",
    "    if missing:\n",
    "        print(f'[ERROR] Columnas faltantes: {missing}')\n",
    "    if extra:\n",
    "        print(f'[WARNING] Columnas extra: {extra}')\n",
    "\n",
    "print()\n",
    "print('Schema detallado:')\n",
    "print(df_watchlist.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verificar Metricas Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('METRICAS CLAVE')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# Metricas esperadas (de E.2_multi_event_fuser.md)\n",
    "expected_total = 274_623\n",
    "expected_tickers = 8_110\n",
    "expected_single = 258_332\n",
    "expected_multi = 16_291\n",
    "\n",
    "# Metricas actuales\n",
    "actual_total = len(df_watchlist)\n",
    "actual_tickers = df_watchlist['ticker'].n_unique()\n",
    "actual_single = df_watchlist.filter(pl.col('num_events') == 1).shape[0]\n",
    "actual_multi = df_watchlist.filter(pl.col('num_events') > 1).shape[0]\n",
    "\n",
    "# Validar\n",
    "print('Total watchlist entries:')\n",
    "print(f'  Esperado: {expected_total:,}')\n",
    "print(f'  Actual: {actual_total:,}')\n",
    "print(f'  Match: {actual_total == expected_total}')\n",
    "print()\n",
    "\n",
    "print('Unique tickers:')\n",
    "print(f'  Esperado: {expected_tickers:,}')\n",
    "print(f'  Actual: {actual_tickers:,}')\n",
    "print(f'  Match: {actual_tickers == expected_tickers}')\n",
    "print()\n",
    "\n",
    "print('Single event days:')\n",
    "print(f'  Esperado: {expected_single:,} (94.1%)')\n",
    "print(f'  Actual: {actual_single:,} ({actual_single/actual_total*100:.1f}%)')\n",
    "print(f'  Match: {actual_single == expected_single}')\n",
    "print()\n",
    "\n",
    "print('Multi-event days:')\n",
    "print(f'  Esperado: {expected_multi:,} (5.9%)')\n",
    "print(f'  Actual: {actual_multi:,} ({actual_multi/actual_total*100:.1f}%)')\n",
    "print(f'  Match: {actual_multi == expected_multi}')\n",
    "print()\n",
    "\n",
    "# Date range\n",
    "date_min = df_watchlist['date'].min()\n",
    "date_max = df_watchlist['date'].max()\n",
    "print(f'Date range: {date_min} -> {date_max}')\n",
    "print()\n",
    "\n",
    "# Event type coverage\n",
    "print('Event Type Coverage:')\n",
    "print(f'  E1: {df_watchlist.filter(pl.col(\"has_e1\")).shape[0]:,} days')\n",
    "print(f'  E4: {df_watchlist.filter(pl.col(\"has_e4\")).shape[0]:,} days')\n",
    "print(f'  E7: {df_watchlist.filter(pl.col(\"has_e7\")).shape[0]:,} days')\n",
    "print(f'  E8: {df_watchlist.filter(pl.col(\"has_e8\")).shape[0]:,} days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validar Top 10 Combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('TOP 10 COMBINACIONES')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# Calcular top combinations\n",
    "df_top = df_watchlist.group_by('event_combination').agg([\n",
    "    pl.len().alias('count')\n",
    "]).sort('count', descending=True).head(10)\n",
    "\n",
    "df_top = df_top.with_columns([\n",
    "    (pl.col('count') / len(df_watchlist) * 100).alias('pct_of_total')\n",
    "])\n",
    "\n",
    "print('Top 10 combinaciones (actuales):')\n",
    "print(df_top)\n",
    "print()\n",
    "\n",
    "# Comparar con esperados (de E.2_multi_event_fuser.md)\n",
    "expected_top = {\n",
    "    'E1': 153_516,\n",
    "    'E4': 75_832,\n",
    "    'E7': 15_430,\n",
    "    'E8': 13_554,\n",
    "    'E1_E4': 8_544,\n",
    "    'E4_E8': 4_357,\n",
    "    'E1_E8': 1_609,\n",
    "    'E1_E7': 944,\n",
    "    'E4_E7': 404,\n",
    "    'E1_E4_E8': 292\n",
    "}\n",
    "\n",
    "print('Comparacion con esperados:')\n",
    "for combo, expected_count in expected_top.items():\n",
    "    actual = df_top.filter(pl.col('event_combination') == combo)\n",
    "    if len(actual) > 0:\n",
    "        actual_count = actual['count'][0]\n",
    "        match = '✓' if actual_count == expected_count else 'X'\n",
    "        print(f'  {combo}: esperado={expected_count:,}, actual={actual_count:,} [{match}]')\n",
    "    else:\n",
    "        print(f'  {combo}: esperado={expected_count:,}, actual=0 [X - NOT FOUND]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validar Coherencia con Eventos Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('COHERENCIA CON EVENTOS ORIGINALES')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# Cargar eventos originales\n",
    "events_dir = Path('../../../../processed/events')\n",
    "\n",
    "events = {}\n",
    "for event_type in ['E1', 'E4', 'E7', 'E8']:\n",
    "    event_file = events_dir / f'events_{event_type.lower()}.parquet'\n",
    "    if event_file.exists():\n",
    "        events[event_type] = pl.read_parquet(event_file)\n",
    "        print(f'{event_type}: {len(events[event_type]):,} eventos')\n",
    "\n",
    "print()\n",
    "\n",
    "# Validar num_events = len(event_types) = len(event_details)\n",
    "print('Validando coherencia interna...')\n",
    "df_check = df_watchlist.with_columns([\n",
    "    pl.col('event_types').list.len().alias('len_event_types'),\n",
    "    pl.col('event_details').list.len().alias('len_event_details')\n",
    "])\n",
    "\n",
    "inconsistent = df_check.filter(\n",
    "    (pl.col('num_events') != pl.col('len_event_types')) |\n",
    "    (pl.col('num_events') != pl.col('len_event_details'))\n",
    ")\n",
    "\n",
    "if len(inconsistent) == 0:\n",
    "    print('[OK] Todas las entradas son coherentes: num_events = len(event_types) = len(event_details)')\n",
    "else:\n",
    "    print(f'[ERROR] {len(inconsistent)} entradas inconsistentes encontradas:')\n",
    "    print(inconsistent.head(10))\n",
    "\n",
    "print()\n",
    "\n",
    "# Validar binary flags\n",
    "print('Validando binary flags...')\n",
    "for event_type in ['E1', 'E4', 'E7', 'E8']:\n",
    "    flag_col = f'has_{event_type.lower()}'\n",
    "    \n",
    "    # Contar donde flag=True\n",
    "    flag_true_count = df_watchlist.filter(pl.col(flag_col)).shape[0]\n",
    "    \n",
    "    # Contar donde event_types contiene el evento\n",
    "    contains_count = df_watchlist.filter(pl.col('event_types').list.contains(event_type)).shape[0]\n",
    "    \n",
    "    match = '✓' if flag_true_count == contains_count else 'X'\n",
    "    print(f'  {flag_col}: flag_true={flag_true_count:,}, contains={contains_count:,} [{match}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deserializar JSON Details (Validacion Tecnica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('DESERIALIZACION JSON DETAILS')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# Tomar muestra aleatoria\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "sample = df_watchlist.sample(n=5, seed=42)\n",
    "\n",
    "print('Validando 5 filas aleatorias:')\n",
    "print()\n",
    "\n",
    "for row in sample.iter_rows(named=True):\n",
    "    ticker = row['ticker']\n",
    "    date = row['date']\n",
    "    event_types = row['event_types']\n",
    "    event_details = row['event_details']\n",
    "    \n",
    "    print(f'{ticker} {date}: {event_types}')\n",
    "    \n",
    "    # Deserializar cada JSON detail\n",
    "    for i, (event_type, detail_json) in enumerate(zip(event_types, event_details)):\n",
    "        try:\n",
    "            detail = json.loads(detail_json)\n",
    "            print(f'  {event_type}: {len(detail)} campos - {list(detail.keys())[:3]}...')\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f'  {event_type}: [ERROR] JSONDecodeError: {e}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "print('[OK] JSON deserializacion validada correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generar Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribucion de num_events\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Distribucion num_events\n",
    "df_num_events = df_watchlist.group_by('num_events').agg([\n",
    "    pl.len().alias('count')\n",
    "]).sort('num_events')\n",
    "\n",
    "axes[0, 0].bar(df_num_events['num_events'], df_num_events['count'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('Numero de eventos simultáneos')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].set_title('Distribucion de eventos simultáneos por día')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Top 15 combinaciones\n",
    "df_top15 = df_watchlist.group_by('event_combination').agg([\n",
    "    pl.len().alias('count')\n",
    "]).sort('count', descending=True).head(15)\n",
    "\n",
    "axes[0, 1].barh(range(len(df_top15)), df_top15['count'], color='coral')\n",
    "axes[0, 1].set_yticks(range(len(df_top15)))\n",
    "axes[0, 1].set_yticklabels(df_top15['event_combination'])\n",
    "axes[0, 1].set_xlabel('Frecuencia')\n",
    "axes[0, 1].set_title('Top 15 combinaciones de eventos')\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# 3. Event type coverage\n",
    "event_counts = {\n",
    "    'E1': df_watchlist.filter(pl.col('has_e1')).shape[0],\n",
    "    'E4': df_watchlist.filter(pl.col('has_e4')).shape[0],\n",
    "    'E7': df_watchlist.filter(pl.col('has_e7')).shape[0],\n",
    "    'E8': df_watchlist.filter(pl.col('has_e8')).shape[0]\n",
    "}\n",
    "\n",
    "axes[1, 0].bar(event_counts.keys(), event_counts.values(), color='seagreen')\n",
    "axes[1, 0].set_xlabel('Tipo de evento')\n",
    "axes[1, 0].set_ylabel('Dias con evento')\n",
    "axes[1, 0].set_title('Cobertura por tipo de evento')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Multi-event vs Single-event\n",
    "pie_data = [actual_single, actual_multi]\n",
    "pie_labels = [f'Single event\\n({actual_single:,})', f'Multi-event\\n({actual_multi:,})']\n",
    "axes[1, 1].pie(pie_data, labels=pie_labels, autopct='%1.1f%%', colors=['lightblue', 'salmon'])\n",
    "axes[1, 1].set_title('Single vs Multi-event days')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multieventfuser_validation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('[OK] Visualizaciones generadas: multieventfuser_validation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen Ejecutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('RESUMEN EJECUTIVO: VALIDACION MULTI-EVENT FUSER')\n",
    "print('=' * 80)\n",
    "print()\n",
    "\n",
    "# Calcular resultados de validacion\n",
    "validations = {\n",
    "    'Schema (11 columnas)': len(missing) == 0 and len(extra) == 0,\n",
    "    'Total entries (274,623)': actual_total == expected_total,\n",
    "    'Unique tickers (8,110)': actual_tickers == expected_tickers,\n",
    "    'Single event days': actual_single == expected_single,\n",
    "    'Multi-event days': actual_multi == expected_multi,\n",
    "    'Coherencia interna': len(inconsistent) == 0\n",
    "}\n",
    "\n",
    "all_passed = all(validations.values())\n",
    "\n",
    "print('Validaciones:')\n",
    "for check, passed in validations.items():\n",
    "    status = '[OK]' if passed else '[FAIL]'\n",
    "    print(f'  {status} {check}')\n",
    "\n",
    "print()\n",
    "\n",
    "if all_passed:\n",
    "    print('[OK] TODAS LAS VALIDACIONES PASARON')\n",
    "    print()\n",
    "    print('El Multi-Event Fuser esta funcionando correctamente:')\n",
    "    print('  - 274,623 watchlist entries consolidadas')\n",
    "    print('  - 11 columnas ML-ready presentes')\n",
    "    print('  - JSON-based event details funcionales')\n",
    "    print('  - Coherencia interna verificada')\n",
    "    print('  - Top 10 combinaciones confirmadas')\n",
    "else:\n",
    "    print('[WARNING] ALGUNAS VALIDACIONES FALLARON')\n",
    "    print('Revisar output anterior para detalles')\n",
    "\n",
    "print()\n",
    "print('=' * 80)\n",
    "print('FIN DE VALIDACION')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
