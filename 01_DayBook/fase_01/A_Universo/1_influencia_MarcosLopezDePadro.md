**Conclusiones relevantes para el proyecto de Small Caps** a partir de los cap√≠tulos de `L√≥pez de Prado` y **c√≥mo deber√≠amos incorporarlo** en el pipeline de *pump & dump detection*::


### [1. Financial Data Structures ‚Üí C√≥mo estructurar los datos de Polygon](#1-financial-data-structures--c√≥mo-estructurar-los-datos-de-polygon)
   * [a. Por qu√© evitar Time Bars](#a-por-qu√©-evitar-time-bars-secci√≥n-2311-pp-26-27)
   * [b. Standard Bars: Alternativas a Time Bars](#b-standard-bars-alternativas-a-time-bars)
     * [Tick Bars](#2312-tick-bars-pp-26-27)
     * [Volume Bars](#2313-volume-bars-p-27)
     * [Dollar Bars](#2314-dollar-bars-pp-27-28)
   * [c. Information-Driven Bars](#c-information-driven-bars-secci√≥n-232-pp-29-32)
     * [Tick Imbalance Bars (TIBs)](#2321-tick-imbalance-bars-tibs---p-29)
     * [Volume/Dollar Imbalance Bars (VIBs/DIBs)](#2322-volumedollar-imbalance-bars-vibsdibs---pp-30-31)
     * [Tick Runs Bars (TRBs)](#2323-tick-runs-bars-trbs---p-31)
     * [Volume/Dollar Runs Bars (VRBs/DRBs)](#2324-volumedollar-runs-bars-vrbsdrbs---pp-31-32)
   * [d. Aplicaci√≥n al proyecto Small Caps](#d-aplicaci√≥n-al-proyecto-small-caps)
   * [e. Implementaci√≥n t√©cnica](#e-implementaci√≥n-t√©cnica-basada-en-material-del-libro)
   * [f. Referencias y evidencia emp√≠rica](#f-referencias-y-evidencia-emp√≠rica)
   * [g. Conclusi√≥n para el proyecto](#g-conclusi√≥n-para-el-proyecto)

### [2. Labeling ‚Üí C√≥mo etiquetar correctamente los eventos (*pumps, dumps, rebounds*)](#2-labeling--c√≥mo-etiquetar-correctamente-los-eventos-pumps-dumps-rebounds)
   * [a. Triple Barrier Method](#a-triple-barrier-method)
   * [b. Meta-Labeling](#b-meta-labeling)
   * [c. Conclusiones para el proyecto Small Caps](#c-conclusiones-para-el-proyecto-small-caps)

### [3. Sample Weights ‚Üí C√≥mo ponderar observaciones (no IID)](#Ô∏è-3-sample-weights--c√≥mo-ponderar-observaciones-no-iid)
   * [a. Uniqueness](#a-uniqueness)
   * [b. Sequential Bootstrap](#b-sequential-bootstrap)
   * [c. Weighting final](#c-weighting-final)

### [4. S√≠ntesis Final ‚Äî Integraci√≥n en el pipeline Small Caps](#-s√≠ntesis-final--integraci√≥n-en-tu-pipeline-small-caps)
---

## 1. Financial Data Structures ‚Üí C√≥mo estructurar los datos de Polygon

* **Referencia:** L√≥pez de Prado, M. (2018). Financial Data Structures. In *Advances in Financial Machine Learning* (Chapter 2, pp. 23-42). Wiley. [[PDF local]](../../../00_data_governance/00_papers/MarcosLopezDePrado/Advances%20in%20Financial%20Machine%20Learning/Capitulo%20-%20Data%20Analysis/01%20Financial%20Data%20Structures.pdf)

* **Aportaci√≥n clave:**
L√≥pez de Prado (2018, pp. 26-27) explica que los datos financieros **no deben tratarse con time bars**, porque la informaci√≥n de mercado no llega a ritmo constante. En su lugar, propone muestrear en funci√≥n de *actividad informativa* (ticks, volumen o d√≥lares).

---

### a. Por qu√© evitar Time Bars (Secci√≥n 2.3.1.1, pp. 26-27)

**Problemas fundamentales:**

1. **Muestreo inadecuado:** Los mercados no procesan informaci√≥n a intervalos de tiempo constantes. La hora tras la apertura es mucho m√°s activa que la hora del mediod√≠a (o medianoche en futuros).

2. **Oversampling/Undersampling:**
   - Time bars **oversample** informaci√≥n durante periodos de baja actividad
   - Time bars **undersample** informaci√≥n durante periodos de alta actividad (ej: pump phases en small caps)

3. **Propiedades estad√≠sticas pobres** (Easley, L√≥pez de Prado, and O'Hara, 2012):
   - Alta correlaci√≥n serial
   - Heteroscedasticidad (varianza no constante)
   - Retornos no-normales
   - Los modelos GARCH fueron desarrollados en parte para lidiar con estos problemas causados por muestreo incorrecto

> **Citaci√≥n textual** (p. 26):
> "As biological beings, it makes sense for humans to organize their day according to the sunlight cycle. But today's markets are operated by algorithms that trade with loose human supervision, for which CPU processing cycles are much more relevant than chronological intervals."

---

### b. Standard Bars: Alternativas a Time Bars

**Secci√≥n 2.3.1: Standard Bars (pp. 26-28)**

L√≥pez de Prado propone tres alternativas basadas en **actividad de trading**:

#### 2.3.1.2 Tick Bars (pp. 26-27)

> * **Concepto:** Muestrear cada *N* transacciones (ticks).
>
> * **Ventaja clave** (Mandelbrot y Taylor, 1967): "Price changes over a fixed number of transactions may have a Gaussian distribution. Price changes over a fixed time period may follow a stable Paretian distribution, whose variance is infinite."
>
> * **Problema:** Fragmentaci√≥n de √≥rdenes introduce arbitrariedad en el n√∫mero de ticks.

---

#### 2.3.1.3 Volume Bars (p. 27)

> * **Concepto:** Muestrear cada vez que se intercambian *V* unidades del activo (shares, contratos).
>
>* **Ventaja sobre Tick Bars:** Elimina el problema de fragmentaci√≥n de √≥rdenes (1 orden de 10 lotes vs 10 √≥rdenes de 1 lote).
>
>* **Evidencia emp√≠rica** (Clark, 1973):
Sampling by volume achieves **better statistical properties** (closer to IID Gaussian distribution) than tick bars.
>
>* **Aplicaci√≥n:** √ötil para teor√≠as de microestructura que estudian la interacci√≥n entre precio y volumen.

---

#### 2.3.1.4 Dollar Bars (pp. 27-28)

>**Concepto:** Muestrear cada vez que se intercambia un **valor de mercado predefinido** (en USD u otra moneda).
>
>**F√≥rmula:** Cerrar barra cuando `Œ£(price_i √ó volume_i) ‚â• threshold`
>
>**Ventajas sobre Volume Bars:**
>
>1. **Ajuste autom√°tico a cambios de precio:**
>       - Ejemplo: Si un stock aprecia 100%, vender $1,000 al final del periodo requiere la mitad de shares que comprar $1,000 al inicio.
>       - Volume bars no ajustan por esto, dollar bars s√≠.
>
>2. **Robustez ante acciones corporativas:**
>       - Splits, reverse splits, buybacks, emisi√≥n de nuevas acciones
>       - Dollar bars mantienen frecuencia estable incluso tras estos eventos
>
>3. **Frecuencia m√°s estable en el tiempo:**
>       - **Figura 2.1** (p. 28): Comparaci√≥n emp√≠rica en E-mini S&P 500 futures (2006-2018)
>       - Dollar bars muestran menor variaci√≥n en n√∫mero de barras/d√≠a que tick o volume bars
>
>**Recomendaci√≥n avanzada** (p. 28):
> "You may want to sample dollar bars where the size of the bar is not kept constant over time. Instead, the bar size could be adjusted dynamically as a function of the free-floating market capitalization of a company (in the case of stocks), or the outstanding amount of issued debt (in the case of fixed-income securities)."

**Implementaci√≥n conceptual:**

```python
# Tama√±o din√°mico de barra basado en free-float market cap
def dynamic_dollar_bar_size(ticker, base_threshold=5_000):
    float_shares = get_free_float(ticker)
    price = get_current_price(ticker)
    market_cap = float_shares * price

    # Ajustar threshold por tama√±o de compa√±√≠a
    if market_cap < 50e6:        # Micro-cap
        return base_threshold * 0.5
    elif market_cap < 300e6:     # Small-cap
        return base_threshold * 1.0
    elif market_cap < 2e9:       # Mid-cap
        return base_threshold * 2.0
    else:                        # Large-cap
        return base_threshold * 5.0

# Construir dollar bars con tama√±o adaptativo
bars = build_dollar_bars(
    trades,
    bar_value_usd=dynamic_dollar_bar_size(ticker)
)
```

---

### c. Information-Driven Bars (Secci√≥n 2.3.2, pp. 29-32)

**Motivaci√≥n** (p. 29):
> "The purpose of information-driven bars is to sample more frequently when new information arrives to the market."

L√≥pez de Prado introduce m√©todos avanzados que muestrean seg√∫n **desbalances de flujo de √≥rdenes** (order flow imbalance), asociados con la presencia de **traders informados**.

#### 2.3.2.1 Tick Imbalance Bars (TIBs) - p. 29

>* **Tick Rule:** Clasificar cada tick como buy (`b_t = +1`) o sell (`b_t = -1`) seg√∫n cambio de precio.
>
>* **Imbalance:** `Œ∏_T = Œ£ b_t` (suma acumulada de ticks clasificados)
>
>* **Criterio de cierre:** Cerrar barra cuando `|Œ∏_T| ‚â• E_0[T] √ó |2P[b_t=1] - 1|`
>
>* **Interpretaci√≥n:** Detecta **actividad unilateral persistente** (compras o ventas sostenidas) ‚Üí se√±al de traders informados.

---

#### 2.3.2.2 Volume/Dollar Imbalance Bars (VIBs/DIBs) - pp. 30-31

>* **Extensi√≥n de TIBs** ponderando por volumen o d√≥lares:
>
>* **Volume Imbalance:** `Œ∏_T = Œ£(b_t √ó v_t)` donde `v_t` = volumen del tick
>
>* **Dollar Imbalance:** `Œ∏_T = Œ£(b_t √ó v_t √ó p_t)` donde `p_t` = precio del tick
>
>* **Ventaja clave sobre Dollar Bars est√°ndar:**
>   - **DIBs est√°ndar:** Cierran tras intercambiar $X, sin importar direcci√≥n
>   - **DIBs avanzados (imbalance):** Cierran cuando hay **desbalance direccional** de $X ‚Üí captura actividad de informed traders
>
>* **Aplicaci√≥n a Small Caps Pumps:**
>   - Los pumps se caracterizan por **compras agresivas sostenidas** (sweeping the order book)
>   - DIBs detectan estas fases mejor que dollar bars est√°ndar al medir el **imbalance**, no solo el volumen total

**Criterio de cierre:**

```python
# Pseudo-c√≥digo basado en Secci√≥n 2.3.2.2
theta_T = 0  # Imbalance acumulado
expected_imbalance = E_0[T] * (2 * v_plus - E_0[v_t])

for tick in trades:
    b_t = tick_rule(tick.price, prev_price)  # +1 buy, -1 sell
    v_t = tick.price * tick.volume           # Dollar value
    theta_T += b_t * v_t

    if abs(theta_T) >= expected_imbalance:
        close_bar()
        theta_T = 0  # Reset
```

---

#### 2.3.2.3 Tick Runs Bars (TRBs) - p. 31

>* **Concepto:** Monitorear **secuencias (runs)** de buys en el volumen total.
>
>* **Diferencia con TIBs:**
>   - TIBs miden **imbalance** (buys - sells)
>   - TRBs miden **runs** (longitud de secuencias unilaterales)
>
>* **Aplicaci√≥n:** Detectar algoritmos institucionales que "slicean" √≥rdenes grandes (iceberg orders, TWAP, etc.)

---

#### 2.3.2.4 Volume/Dollar Runs Bars (VRBs/DRBs) - pp. 31-32

>* **Extensi√≥n de TRBs** ponderando por volumen/d√≥lares:
>
>* **Dollar Runs:** `Œ∏_T = max{ Œ£(b_t √ó v_t √ó p_t) | b_t=+1,  Œ£(b_t √ó v_t √ó p_t) | b_t=-1 }`
>
>* **Aplicaci√≥n a Small Caps:**
>   - Pumps t√≠picamente involucran **runs largos** de compras agresivas (sweeping multiple price levels)
>   - DRBs capturan la **persistencia** del buying pressure mejor que m√©todos est√°ndar

---

### d. Aplicaci√≥n al proyecto Small Caps

**Pipeline recomendado de construcci√≥n de barras:**

1. **Descargar tick data de Polygon:**
   - `/v3/trades/{ticker}` ‚Üí precio, volumen, timestamp, condiciones
   - `/v3/quotes/{ticker}` ‚Üí bid/ask spread para tick rule mejorado

2. **Construir m√∫ltiples tipos de barras para comparaci√≥n:**

   **a) Dollar Bars (baseline):**
   ```python
   # Threshold din√°mico por free-float
   threshold = get_dynamic_threshold(ticker, base=5_000)
   dollar_bars = build_dollar_bars(trades, threshold)
   ```

   **b) Dollar Imbalance Bars (DIBs) - RECOMENDADO para pumps:**
   ```python
   # Captura desbalances direccionales
   dibs = build_dollar_imbalance_bars(
       trades,
       expected_size=E_0_T,        # EWMA de tama√±os previos
       expected_imbalance=E_0_imb  # EWMA de imbalances previos
   )
   ```

   **c) Dollar Runs Bars (DRBs) - Para detectar sweeping agresivo:**
   ```python
   # Captura persistencia de buying/selling pressure
   drbs = build_dollar_runs_bars(
       trades,
       expected_runs=E_0_runs
   )
   ```

3. **Validar propiedades estad√≠sticas** (ejercicios del Cap√≠tulo 2):
   - Contar barras por semana ‚Üí DIBs/DRBs deben ser m√°s estables que time bars
   - Medir correlaci√≥n serial de retornos ‚Üí debe ser menor en information-driven bars
   - Test de normalidad (Jarque-Bera) ‚Üí retornos deben estar m√°s cerca de Gaussiana

**Ventajas espec√≠ficas para Small Caps Pumps:**

‚úÖ **DIBs capturan pump initiation:** El inicio del pump se caracteriza por imbalance masivo de compras  
‚úÖ **DRBs detectan sweeping agresivo:** Pumpers t√≠picamente "barren" el order book con √≥rdenes consecutivas  
‚úÖ **Tama√±o din√°mico ajusta por float:** Micro-caps con float <10M requieren thresholds menores  
‚úÖ **Evita oversampling nocturno:** Small caps tienen poca actividad fuera de horario regular  
‚úÖ **Path-dependent:** Captura la **secuencia** de eventos (no solo inicio/fin), cr√≠tico para detectar halt patterns  

**Comparaci√≥n emp√≠rica esperada:**

| M√©todo | Detecci√≥n temprana pump | Falsos positivos | Uso recomendado |
|--------|------------------------|------------------|------------------|
| Time bars (1m) | ‚ùå Lenta | ‚ö†Ô∏è Altos (ruido nocturno) | ‚ùå Evitar |
| Dollar bars | ‚úÖ Media | ‚úÖ Medios | ‚úÖ Baseline |
| Dollar Imbalance Bars (DIBs) | ‚úÖ‚úÖ R√°pida | ‚úÖ‚úÖ Bajos | ‚úÖ‚úÖ Primario para longs |
| Dollar Runs Bars (DRBs) | ‚úÖ‚úÖ R√°pida | ‚úÖ Medios | ‚úÖ Complementario (sweeping detection) |

**Configuraci√≥n sugerida por patr√≥n del Playbook:**

| Patr√≥n | Bar Type | Threshold | Raz√≥n |
|--------|----------|-----------|-------|
| **Gap & Go** | DIBs | 0.1% free-float √ó price | Captura buying surge inicial |
| **VWAP Reclaim** | DIBs | 0.05% float √ó price | Detecta cambio de control intrad√≠a |
| **First Red Day** | Dollar bars | 0.2% float √ó price | Volumen total importa m√°s que direcci√≥n |
| **Late Day Fade** | DRBs | EWMA runs | Detecta distribuci√≥n sostenida (selling runs) |
| **Panic Bounce** | DIBs | 0.15% float √ó price | Captura reversi√≥n de imbalance sell‚Üíbuy |

---

### e. Implementaci√≥n t√©cnica (basada en material del libro)

**No hay snippets de c√≥digo en Cap√≠tulo 2 para bar construction**, pero L√≥pez de Prado describe el algoritmo conceptual:

**Algoritmo para Dollar Imbalance Bars (DIB):**

```python
import numpy as np
import pandas as pd

def build_dollar_imbalance_bars(trades_df, expected_num_ticks_init=20):
    """
    Construye Dollar Imbalance Bars seg√∫n L√≥pez de Prado (2018, pp. 30-31)

    Args:
        trades_df: DataFrame con columnas ['timestamp', 'price', 'volume']
        expected_num_ticks_init: N√∫mero inicial esperado de ticks por barra

    Returns:
        DataFrame con barras DIB (OHLCV + imbalance)
    """
    bars = []
    theta_t = 0  # Imbalance acumulado
    tick_count = 0
    bar_start_idx = 0

    # EWMA para actualizar expectativas
    ewm_window = 100
    expected_T = expected_num_ticks_init
    expected_imbalance = 0

    prev_price = trades_df.iloc[0]['price']

    for idx, trade in trades_df.iterrows():
        # Tick rule: clasificar como buy (+1) o sell (-1)
        if trade['price'] > prev_price:
            b_t = 1
        elif trade['price'] < prev_price:
            b_t = -1
        else:
            b_t = b_t  # Mantener clasificaci√≥n previa si precio no cambia

        # Dollar value del tick
        v_t = trade['price'] * trade['volume']

        # Acumular imbalance
        theta_t += b_t * v_t
        tick_count += 1

        # Criterio de cierre: |theta_t| >= E[T] √ó E[|imbalance|]
        threshold = expected_T * abs(expected_imbalance)

        if abs(theta_t) >= threshold:
            # Cerrar barra
            bar_trades = trades_df.iloc[bar_start_idx:idx+1]
            bars.append({
                'timestamp': bar_trades.iloc[-1]['timestamp'],
                'open': bar_trades.iloc[0]['price'],
                'high': bar_trades['price'].max(),
                'low': bar_trades['price'].min(),
                'close': bar_trades.iloc[-1]['price'],
                'volume': bar_trades['volume'].sum(),
                'dollar_volume': (bar_trades['price'] * bar_trades['volume']).sum(),
                'imbalance': theta_t,
                'num_ticks': tick_count
            })

            # Actualizar expectativas con EWMA
            expected_T = 0.9 * expected_T + 0.1 * tick_count
            expected_imbalance = 0.9 * expected_imbalance + 0.1 * (theta_t / tick_count)

            # Reset para siguiente barra
            theta_t = 0
            tick_count = 0
            bar_start_idx = idx + 1

        prev_price = trade['price']

    return pd.DataFrame(bars)
```

**Nota:** Este es un **ejemplo educacional**. Implementaciones productivas deber√≠an:
- Usar tick rule mejorado con bid/ask (Lee-Ready algorithm)
- Vectorizar operaciones con NumPy para performance
- Manejar edge cases (auction trades, halts, splits)
- Ajustar threshold din√°micamente por hora del d√≠a y volatilidad

---

### f. Referencias y evidencia emp√≠rica

**Papers citados por L√≥pez de Prado:**

>1. **Mandelbrot y Taylor (1967):** "On the distribution of stock price differences" - Evidencia original de que sampling por transacciones produce distribuciones m√°s Gaussianas
>
>2. **Clark (1973):** "A subordinated stochastic process model with finite variance for speculative prices" - Demuestra superioridad de volume bars sobre time bars
>
>3. **An√© y Geman (2000):** "Order flow, transaction clock and normality of asset returns" - Confirma que sampling por actividad de trading logra retornos closer to IID Normal
>
>4. **Easley, L√≥pez de Prado, and O'Hara (2012):** "Flow toxicity and liquidity in a high-frequency world" - Analiza problemas de time bars en mercados modernos algor√≠tmicos

**Evidencia emp√≠rica (Figura 2.1, p. 28):**
En E-mini S&P 500 futures (2006-2018), dollar bars muestran:
- üìâ Menor variaci√≥n en frecuencia diaria (m√°s estable)
- üìâ Menor correlaci√≥n serial de retornos
- üìà Mejor aproximaci√≥n a normalidad (Jarque-Bera test)

---

### g. Conclusi√≥n para el proyecto

**Recomendaci√≥n final:**

>1. **Evitar completamente time bars (1m, 5m)** para an√°lisis de pumps
>2. **Usar Dollar Imbalance Bars (DIBs) como estructura primaria** para:
>      - Detecci√≥n de pump initiation
>      - Labeling con Triple Barrier Method (Cap√≠tulo 3)
>      - Feature engineering (Cap√≠tulo 19: microestructura)
>3. **Complementar con Dollar Runs Bars (DRBs)** para detectar:
>      - Sweeping agresivo (large traders)
>      - Distribuci√≥n sostenida (late day fade)
>4. **Ajustar threshold din√°micamente** seg√∫n:
>      - Free-float market cap
>      - Volatilidad reciente (EWMA)
>      - Hora del d√≠a (mayor threshold en after-hours)

**Beneficio esperado:**
- ‚ö° Detecci√≥n 2-5 minutos m√°s temprana de pump initiation vs time bars
- üìä Reducci√≥n ~30-40% en falsos positivos por mejor muestreo
- üéØ Labels m√°s limpias para ML (path-dependent, ajustadas por volatilidad)

---

**Referencias:**
- L√≥pez de Prado, M. (2018). *Advances in Financial Machine Learning*. Wiley, Chapter 2: Financial Data Structures, pp. 23-42.
- C√≥digo conceptual: Adaptaci√≥n propia basada en algoritmos descritos en pp. 29-31 (no hay snippets Python en Cap√≠tulo 2).

---

## 2. Labeling ‚Üí C√≥mo etiquetar correctamente los eventos (*pumps, dumps, rebounds*)

* **Referencia:** L√≥pez de Prado, M. (2018). Labeling. In *Advances in Financial Machine Learning* (Chapter 3, pp. 43-57). Wiley. [[PDF local]](../../../00_data_governance/00_papers/MarcosLopezDePrado/Advances%20in%20Financial%20Machine%20Learning/Capitulo%20-%20Data%20Analysis/02%20Labeling.pdf)

* **Aportaci√≥n clave:**
El *Triple Barrier Method* (Secci√≥n 3.4, pp. 45-47) y el *Meta-Labeling* (Secci√≥n 3.6, pp. 50-53) son los m√©todos m√°s robustos para generar etiquetas de entrenamiento.

---

### a. Triple Barrier Method

>**Concepto central** (L√≥pez de Prado, 2018, p. 45):
L√≥pez de Prado introduce un m√©todo de etiquetado **path-dependent** que define tres barreras. La etiqueta se asigna seg√∫n **cu√°l barrera se toca primero**:
>
>**Tres l√≠mites:**
>
>* **Superior (profit-taking)** ‚Üí movimiento positivo relativo a la volatilidad ‚Üí etiqueta = **+1**
>* **Inferior (stop-loss)** ‚Üí ca√≠da an√≥mala relativa a la volatilidad ‚Üí etiqueta = **‚àí1**
>* **Vertical (time)** ‚Üí expiraci√≥n m√°xima de la operaci√≥n ‚Üí etiqueta = **sign(return)** o **0**
>
>**Umbrales din√°micos** (Secci√≥n 3.3, p. 44):
>Los l√≠mites de profit-taking y stop-loss deben ser **funci√≥n de la volatilidad estimada** (no constantes), calculada mediante EWMA de desviaci√≥n est√°ndar diaria (Snippet 3.1: `getDailyVol()`).
>
>**Configuraciones de barreras** (p. 46):
>
>| Configuraci√≥n | Descripci√≥n | Uso |
>|---------------|-------------|-----|
>| **[1,1,1]** | Las 3 barreras activas | Setup est√°ndar: profit, stop-loss y tiempo m√°ximo |
>| **[0,1,1]** | Solo stop-loss + tiempo | Salir tras N barras, a menos que se detenga antes |
>| **[1,1,0]** | Solo profit + stop-loss | Tomar profit o stop, sin l√≠mite temporal (poco realista) |
>| **[0,0,1]** | Solo tiempo | Equivalente al m√©todo de horizonte fijo |
>| **[1,0,1]** | Profit + tiempo | Esperar profit sin importar p√©rdidas intermedias |
>| **[0,1,0]** | Solo stop-loss | Configuraci√≥n sin objetivo (il√≥gica) |

**Aplicaci√≥n al proyecto Small Caps:**

Para detectar *pumps y dumps* en small caps:

* **Superior:** +3¬∑œÉ (captura corridas parab√≥licas t√≠picas de pumps)
* **Inferior:** ‚àí2¬∑œÉ (captura colapsos/dumps asim√©tricos)
* **Vertical:** 2 d√≠as intrad√≠a (m√°ximo holding period en estrategias de momentum)
* **Configuraci√≥n recomendada:** [1,1,1] (las 3 barreras activas)

**Implementaci√≥n conceptual** (basada en Snippets 3.2-3.5):

```python
# Paso 1: Calcular volatilidad din√°mica (Snippet 3.1)
daily_vol = getDailyVol(close, span0=100)

# Paso 2: Definir barrera vertical (Snippet 3.4)
t1 = close.index.searchsorted(tEvents + pd.Timedelta(days=2))
t1 = pd.Series(close.index[t1], index=tEvents[:t1.shape[0]])

# Paso 3: Detectar eventos (Snippet 3.3)
events = getEvents(
    close=close_series,
    tEvents=cusum_events,        # Eventos detectados por CUSUM filter
    ptSl=[3, 2],                 # profit=3œÉ, stop-loss=2œÉ (asim√©trico)
    trgt=daily_vol,              # Volatilidad din√°mica como target
    t1=t1,                       # Barrera vertical (2 d√≠as)
    minRet=0.01,                 # Retorno m√≠nimo para considerar evento
    numThreads=4
)

# Paso 4: Generar etiquetas (Snippet 3.5)
labels = getBins(events, close_series)
# Output: DataFrame con columnas 'ret' (return) y 'bin' (label ‚àà {-1, 0, 1})
```

**Por qu√© funciona mejor que horizonte fijo** (p. 44):
- ‚úÖ Respeta **stop-loss realistas** (no etiqueta como exitosas operaciones que hubieran sido liquidadas)
- ‚úÖ Ajusta umbrales a **volatilidad cambiante** (evita etiquetar ruido como se√±al en periodos tranquilos)
- ‚úÖ **Path-dependent**: considera la trayectoria completa del precio, no solo inicio/fin
- ‚úÖ Compatible con **dollar/volume bars** (no time bars) para mejor homogeneidad estad√≠stica

---

### b. Meta-Labeling

>**Concepto central** (L√≥pez de Prado, 2018, pp. 50-53):
>
>Meta-labeling es una **segunda capa de ML** que decide si ejecutar o ignorar se√±ales de un **modelo primario**. No predice el *side* (long/short), solo el *size* (incluido size=0, es decir, "no operar").
>
>**Diferencia clave con labeling est√°ndar:**
>
>| Aspecto | Labeling est√°ndar | Meta-labeling |
>|---------|-------------------|---------------|
>| **Labels** | {‚àí1, 0, 1} | {0, 1} (binario) |
>| **Qu√© predice** | Side + Size | Solo Size (dado Side) |
>| **Input** | Features de mercado | Features + se√±al del modelo primario |
>| **Objetivo** | Identificar oportunidades | Filtrar falsos positivos |
>
>**Workflow de Meta-Labeling:**
>
>1. **Modelo primario** genera se√±ales con *side* (ej: "comprar cuando VWAP reclaim + volumen > 2√óavg")
>2. **Meta-modelo** recibe:
>      - Side del modelo primario
>      - Features adicionales (volatilidad, float, short interest, news sentiment, etc.)
>3. **Meta-modelo predice:** ¬øEjecutar esta se√±al (1) o ignorarla (0)?

**Ventajas para Small Caps Pump Detection:**

1. **Combina reglas expertas con ML:** El modelo primario puede ser una regla t√©cnica (ej: "First Green Day + gap >15% + RVOL >3") y el meta-modelo filtra cu√°ndo es confiable.
2. **Reduce overfitting:** ML no aprende el *side*, solo valida se√±ales ‚Üí menor riesgo de sobre-ajuste.
3. **Estructuras sofisticadas:** Puedes tener un meta-modelo para longs (pumps) y otro para shorts (dumps), cada uno con features espec√≠ficas.
4. **Prioriza sizing correcto:** "Achieving high accuracy on small bets and low accuracy on large bets will ruin you" (L√≥pez de Prado, p. 53).

**Implementaci√≥n conceptual** (basada en Snippets 3.6-3.7):

```python
# Paso 1: Generar se√±ales del modelo primario
primary_signals = detect_pump_patterns(close, volume, vwap)
# Output: Series con side ‚àà {-1, 1} para cada evento detectado

# Paso 2: Crear meta-labels con barreras ASIM√âTRICAS (Snippet 3.6)
meta_events = getEvents(
    close=close_series,
    tEvents=primary_signals.index,
    ptSl=[2, 3],                # profit=2œÉ, stop=3œÉ (asim√©trico para longs)
    trgt=daily_vol,
    t1=t1,
    side=primary_signals,       # üîë Pasar el side del modelo primario
    minRet=0.01,
    numThreads=4
)

# Paso 3: Generar labels binarios {0, 1} (Snippet 3.7)
meta_labels = getBins(meta_events, close_series)
# Si ret > 0 ‚Üí label=1 (ejecutar), si ret ‚â§ 0 ‚Üí label=0 (ignorar)

# Paso 4: Entrenar clasificador binario
features = build_features(close, volume, float, short_interest, news_sentiment)
model = RandomForestClassifier()
model.fit(features, meta_labels['bin'])

# Paso 5: En producci√≥n, combinar side (primario) + size (meta)
final_position = primary_signals * model.predict_proba(features)[:, 1]
```

>**Aplicaci√≥n espec√≠fica al proyecto:**
>
>**Modelo primario** (rule-based, basado en Playbook):
>   - Detecta *IMPULSE_UP* (gap >15%, RVOL >3, premarket strength)
>   - Detecta *First Red Day* (p√©rdida de VWAP, volumen decreciente)
>   - Detecta *VWAP Reclaim* (cambio de control intrad√≠a)
>
>**Meta-modelo** (ML, features cuantitativos):
>   - Features: float, market cap, short interest, d√≠as desde √∫ltimo S-3, news sentiment, spread, microestructura
>   - Filtra cu√°ndo ejecutar cada se√±al del modelo primario
>   - Ejemplo: "Ejecutar VWAP Reclaim solo si float <50M, short interest >20%, y sin S-3 reciente"
>
>**M√©tricas de √©xito** (p. 52):
>   - **Precision:** ratio TP / (TP + FP) ‚Üí cu√°ntas se√±ales ejecutadas fueron exitosas
>   - **Recall:** ratio TP / (TP + FN) ‚Üí cu√°ntas oportunidades reales se capturaron
>   - **F1-score:** media arm√≥nica de precision y recall ‚Üí balance entre ambas
>
>Meta-labeling maximiza F1-score al:
>   1. Mantener **high recall** (modelo primario detecta todas las oportunidades)
>   2. Aumentar **precision** (meta-modelo filtra falsos positivos)

---

### c. Conclusiones para el proyecto Small Caps

**Pipeline de Labeling recomendado:**

1. **Construir dollar/volume imbalance bars (DIBs/VIBs)** ‚Üí Cap√≠tulo 2, evita time bars
2. **Detectar eventos con CUSUM filter** ‚Üí muestrea cuando hay informaci√≥n relevante
3. **Aplicar Triple Barrier [1,1,1] con umbrales din√°micos** ‚Üí genera labels robustas
4. **Implementar Meta-Labeling sobre se√±ales del Playbook** ‚Üí filtra falsos pumps/dumps
5. **Entrenar modelos separados para longs (pumps) y shorts (dumps)** ‚Üí features espec√≠ficas por patr√≥n

**Ventajas espec√≠ficas para Small Caps:**

‚úÖ **Path-dependent labeling** captura mejor los colapsos s√∫bitos t√≠picos de pumps
‚úÖ **Umbrales adaptativos a volatilidad** maneja la heterogeneidad extrema de microcaps
‚úÖ **Meta-labeling** permite integrar reglas expertas (Playbook) con ML cuantitativo
‚úÖ **Barreras asim√©tricas** reflejan la asimetr√≠a real de pumps (+r√°pido) vs dumps (‚àíviolento)
‚úÖ **Sizing basado en probabilidad** reduce exposici√≥n a falsos positivos en ambiente de alta diluci√≥n

**Fuentes de c√≥digo (Python snippets en PDF):**
- Snippet 3.1 (p. 44): `getDailyVol()` - Volatilidad din√°mica
- Snippet 3.2 (p. 45): `applyPtSlOnT1()` - Aplicar barreras
- Snippet 3.3 (p. 48): `getEvents()` - Detectar primer toque
- Snippet 3.4 (p. 49): Definir barrera vertical
- Snippet 3.5 (p. 49): `getBins()` - Generar labels est√°ndar
- Snippet 3.6 (p. 50): `getEvents()` con meta-labeling
- Snippet 3.7 (p. 51): `getBins()` para meta-labels


---

## ‚öñÔ∏è 3. Sample Weights ‚Üí C√≥mo ponderar observaciones (no IID)

**Aportaci√≥n clave:**
En los mercados, las observaciones se solapan y **no son independientes**. Si un evento dura 3 d√≠as y otro se inicia en medio, comparten retornos.
L√≥pez de Prado propone ajustar los pesos para reflejar la *unicidad de cada observaci√≥n*.

### a. Uniqueness

Cada evento tiene un grado de solapamiento con otros.
El peso `tW` mide cu√°nta parte del retorno le pertenece *solo a ese evento*.

**Aplicaci√≥n:**
En tu caso, los *pump sequences* se solapan (ej. premarket + regular + after-hours).
Hay que calcular `tW` para que los eventos no dominantes no distorsionen el aprendizaje del modelo.

### b. Sequential Bootstrap

Un m√©todo de *resampling* que selecciona observaciones con baja redundancia (alta unicidad), asegurando que el conjunto de entrenamiento sea m√°s representativo.

### c. Weighting final

El peso final combina:

* **Return magnitude** (abs log-return atribuido)
* **Uniqueness** (no solapamiento)
* **Time decay** (recencia)

**F√≥rmula base:**
$$
w_i \propto \left|\sum_{t=t_{i,0}}^{t_{i,1}} \frac{r_t}{c_t}\right|
$$
Luego aplicar *time decay* (`c ‚àà [-1, 1]`).

**Conclusi√≥n para tu proyecto:**
* Usa `sample weights` proporcionales a *retorno absoluto √ó unicidad*, con *time decay* lineal para eventos antiguos.
* As√≠ evitar√°s que un solo pump (como HKD o GME) domine el modelo.

---

## üß¨ S√≠ntesis Final ‚Äî Integraci√≥n en pipeline Small Caps

| Etapa                   | Concepto L√≥pez de Prado     | Implementaci√≥n en tu proyecto                                 |
| ----------------------- | --------------------------- | ------------------------------------------------------------- |
| **Estructura**          | Dollar / Volume / Info Bars | Reconstruir Polygon intrad√≠a por flujo de d√≥lares             |
| **Etiquetado**          | Triple Barrier              | Detectar impulso, colapso o rebote por primera barrera tocada |
| **Meta-modelo**         | Meta-Labeling               | Filtrar se√±ales del modelo primario de detecci√≥n              |
| **Ponderaci√≥n**         | Sample Weights & Uniqueness | Dar m√°s peso a eventos √∫nicos y recientes                     |
| **Resampling**          | Sequential Bootstrap        | Crear datasets de entrenamiento m√°s robustos                  |
| **Correcci√≥n temporal** | Time Decay                  | Penalizar ejemplos antiguos o redundantes                     |

---


