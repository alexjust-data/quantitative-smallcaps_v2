{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_Universo - Validación de Descarga Polygon Reference Data\n",
    "\n",
    "**Objetivo**: Certificar empíricamente que hemos descargado el universo completo de tickers + corporate actions.\n",
    "\n",
    "**Documentación**: [3_descarga_Universo_y_referencia.md](3_descarga_Universo_y_referencia.md)\n",
    "\n",
    "**Stack**: Polygon API → Parquet (raw/polygon/reference/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "BASE_PATH = Path(\"../../../raw/polygon/reference\")\n",
    "TICKERS_PATH = BASE_PATH / \"tickers_snapshot\"\n",
    "SPLITS_PATH = BASE_PATH / \"splits\"\n",
    "DIVIDENDS_PATH = BASE_PATH / \"dividends\"\n",
    "DETAILS_PATH = BASE_PATH / \"ticker_details\"\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ PASO 1: Universe Snapshot (`/v3/reference/tickers`)\n",
    "\n",
    "**Objetivo**: Descargar universo completo con activos + inactivos (anti-survivorship bias)\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_reference_tickers.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/tickers?market=stocks&active=true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Archivos encontrados: 4\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-19\\tickers.parquet (0.39 MB)\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-24\\tickers_all.parquet (1.09 MB)\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-24\\tickers_active.parquet (0.37 MB)\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-24\\tickers_inactive.parquet (0.69 MB)\n"
     ]
    }
   ],
   "source": [
    "# Verificar archivos descargados\n",
    "ticker_files = list(TICKERS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"📂 Archivos encontrados: {len(ticker_files)}\")\n",
    "for f in ticker_files:\n",
    "    size_mb = f.stat().st_size / (1024*1024)\n",
    "    print(f\"  - {f.relative_to(BASE_PATH)} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSE SNAPSHOT - 2025-10-24\n",
      "================================================================================\n",
      "Total tickers: 34,380\n",
      "Columnas: 14\n",
      "\n",
      "Columnas disponibles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ticker',\n",
       " 'name',\n",
       " 'market',\n",
       " 'locale',\n",
       " 'primary_exchange',\n",
       " 'type',\n",
       " 'active',\n",
       " 'currency_name',\n",
       " 'cik',\n",
       " 'composite_figi',\n",
       " 'share_class_figi',\n",
       " 'last_updated_utc',\n",
       " 'snapshot_date',\n",
       " 'delisted_utc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar snapshot más reciente (2025-10-24)\n",
    "df_all = pl.read_parquet(TICKERS_PATH / \"snapshot_date=2025-10-24\" / \"tickers_all.parquet\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UNIVERSE SNAPSHOT - 2025-10-24\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total tickers: {df_all.shape[0]:,}\")\n",
    "print(f\"Columnas: {len(df_all.columns)}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "[i for i in df_all.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANTI-SURVIVORSHIP BIAS VERIFICATION\n",
      "================================================================================\n",
      "✅ Activos:     11,853 (34.5%)\n",
      "✅ Inactivos:   22,527 (65.5%)\n",
      "\n",
      "📊 Total:       34,380\n",
      "\n",
      "✓ Incluye tickers delistados → NO survivorship bias\n"
     ]
    }
   ],
   "source": [
    "# Análisis active vs inactive (anti-survivorship bias)\n",
    "active_count = df_all.filter(pl.col(\"active\") == True).shape[0]\n",
    "inactive_count = df_all.filter(pl.col(\"active\") == False).shape[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANTI-SURVIVORSHIP BIAS VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✅ Activos:   {active_count:>8,} ({active_count/df_all.shape[0]*100:.1f}%)\")\n",
    "print(f\"✅ Inactivos: {inactive_count:>8,} ({inactive_count/df_all.shape[0]*100:.1f}%)\")\n",
    "print(f\"\\n📊 Total:     {df_all.shape[0]:>8,}\")\n",
    "print(\"\\n✓ Incluye tickers delistados → NO survivorship bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE: TICKERS INACTIVOS (DELISTADOS)\n",
      "================================================================================\n",
      "shape: (10, 5)\n",
      "┌────────┬─────────────────────────────────┬────────┬─────────┬──────────────────────┐\n",
      "│ ticker ┆ name                            ┆ market ┆ type    ┆ delisted_utc         │\n",
      "│ ---    ┆ ---                             ┆ ---    ┆ ---     ┆ ---                  │\n",
      "│ str    ┆ str                             ┆ str    ┆ str     ┆ str                  │\n",
      "╞════════╪═════════════════════════════════╪════════╪═════════╪══════════════════════╡\n",
      "│ AAAP   ┆ Advanced Accelerator Applicati… ┆ stocks ┆ ADRC    ┆ 2018-02-12T05:00:00Z │\n",
      "│ AAB.WS ┆ LEHMAN BROTHERS CURRENCY BASKE… ┆ stocks ┆ null    ┆ 2008-02-11T05:00:00Z │\n",
      "│ AABA   ┆ Altaba Inc. Common Stock        ┆ stocks ┆ CS      ┆ 2019-10-07T04:00:00Z │\n",
      "│ AABC   ┆ ACCESS ANYTIME BANCORP INC      ┆ stocks ┆ null    ┆ 2006-01-04T05:00:00Z │\n",
      "│ AAC    ┆ Ares Acquisition Corporation    ┆ stocks ┆ CS      ┆ 2023-11-07T05:00:00Z │\n",
      "│ AAC.U  ┆ Ares Acquisition Corporation U… ┆ stocks ┆ UNIT    ┆ 2023-11-07T05:00:00Z │\n",
      "│ AAC.WS ┆ Ares Acquisition Corporation R… ┆ stocks ┆ WARRANT ┆ 2023-11-07T05:00:00Z │\n",
      "│ AACC   ┆ ASSET ACCEP CAP CORP            ┆ stocks ┆ null    ┆ 2013-06-14T04:00:00Z │\n",
      "│ AACE   ┆ ACE CASH EXPRESS INC            ┆ stocks ┆ null    ┆ 2006-10-06T04:00:00Z │\n",
      "│ AACOU  ┆ AUSTRALIA ACQUISITION CORP   U… ┆ stocks ┆ null    ┆ 2012-10-16T04:00:00Z │\n",
      "└────────┴─────────────────────────────────┴────────┴─────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Sample de tickers inactivos (delistados)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE: TICKERS INACTIVOS (DELISTADOS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_inactive_sample = df_all.filter(pl.col(\"active\") == False).head(10).select(\n",
    "    [\"ticker\", \"name\", \"market\", \"type\", \"delisted_utc\"]\n",
    ")\n",
    "print(df_inactive_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DISTRIBUCIÓN POR TIPO\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexJ\\AppData\\Local\\Temp\\ipykernel_29072\\2593403979.py:7: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"count\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (16, 3)\n",
      "┌──────┬───────┬────────┐\n",
      "│ type ┆ count ┆ active │\n",
      "│ ---  ┆ ---   ┆ ---    │\n",
      "│ str  ┆ u32   ┆ u32    │\n",
      "╞══════╪═══════╪════════╡\n",
      "│ CS   ┆ 11471 ┆ 5229   │\n",
      "│ null ┆ 6830  ┆ 0      │\n",
      "│ ETF  ┆ 5728  ┆ 4365   │\n",
      "│ PFD  ┆ 2206  ┆ 441    │\n",
      "│ SP   ┆ 2164  ┆ 159    │\n",
      "│ …    ┆ …     ┆ …      │\n",
      "│ ETN  ┆ 252   ┆ 49     │\n",
      "│ ETS  ┆ 141   ┆ 126    │\n",
      "│ ETV  ┆ 74    ┆ 69     │\n",
      "│ ADRP ┆ 15    ┆ 0      │\n",
      "│ ADRR ┆ 5     ┆ 0      │\n",
      "└──────┴───────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Análisis por tipo de ticker\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DISTRIBUCIÓN POR TIPO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "type_dist = df_all.group_by(\"type\").agg([\n",
    "    pl.count().alias(\"count\"),\n",
    "    (pl.col(\"active\").sum()).alias(\"active\")\n",
    "]).sort(\"count\", descending=True)\n",
    "\n",
    "print(type_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ CERTIFICACIÓN PASO 1\n",
    "\n",
    "**Resultado**: Universe snapshot descargado correctamente\n",
    "\n",
    "**Evidencia**:\n",
    "- Total tickers: 34,380\n",
    "- Activos: 11,853 (34.5%)\n",
    "- Inactivos: 22,527 (65.5%)\n",
    "- Anti-survivorship bias: ✅ Incluye delistados\n",
    "\n",
    "**Path**: `raw/polygon/reference/tickers_snapshot/snapshot_date=2025-10-24/tickers_all.parquet`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ PASO 2: Splits (`/v3/reference/splits`)\n",
    "\n",
    "**Objetivo**: Descargar historial de splits para ajuste de precios\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_splits_dividends.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/splits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Archivos de splits: 31\n",
      "\n",
      "================================================================================\n",
      "SPLITS HISTÓRICOS\n",
      "================================================================================\n",
      "Total registros: 26,641\n",
      "Columnas: ['execution_date', 'id', 'split_from', 'split_to', 'ticker', 'ratio']\n"
     ]
    }
   ],
   "source": [
    "# Verificar archivos de splits\n",
    "split_files = list(SPLITS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"📂 Archivos de splits: {len(split_files)}\")\n",
    "\n",
    "# Cargar todos los splits\n",
    "df_splits = pl.scan_parquet(SPLITS_PATH / \"**\" / \"*.parquet\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPLITS HISTÓRICOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total registros: {df_splits.shape[0]:,}\")\n",
    "print(f\"Columnas: {df_splits.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISIS SPLITS\n",
      "================================================================================\n",
      "Rango temporal: 1978-10-25 → 2025-12-05\n",
      "\n",
      "Sample (5 splits más recientes):\n",
      "shape: (5, 6)\n",
      "┌────────────────┬─────────────────────────────────┬────────────┬──────────┬────────┬───────┐\n",
      "│ execution_date ┆ id                              ┆ split_from ┆ split_to ┆ ticker ┆ ratio │\n",
      "│ ---            ┆ ---                             ┆ ---        ┆ ---      ┆ ---    ┆ ---   │\n",
      "│ str            ┆ str                             ┆ f64        ┆ f64      ┆ str    ┆ f64   │\n",
      "╞════════════════╪═════════════════════════════════╪════════════╪══════════╪════════╪═══════╡\n",
      "│ 2025-12-05     ┆ E1a62e2d20c68089280a893dc8394f… ┆ 2.0        ┆ 1.0      ┆ LBIIX  ┆ 2.0   │\n",
      "│ 2025-12-05     ┆ E80f07aa0c5ba57b124f70f270189c… ┆ 2.0        ┆ 1.0      ┆ AAHYX  ┆ 2.0   │\n",
      "│ 2025-12-05     ┆ E92b4fe3b7af6add95df70182ac0c8… ┆ 2.0        ┆ 1.0      ┆ LUBIX  ┆ 2.0   │\n",
      "│ 2025-12-05     ┆ E6e01e48aab675431c6a166e82d365… ┆ 2.0        ┆ 1.0      ┆ THYFX  ┆ 2.0   │\n",
      "│ 2025-12-05     ┆ Eaf2c45217528b55c3dbb4f54c8233… ┆ 4.0        ┆ 1.0      ┆ LBHIX  ┆ 4.0   │\n",
      "└────────────────┴─────────────────────────────────┴────────────┴──────────┴────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Análisis de splits\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS SPLITS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Rango temporal\n",
    "if \"execution_date\" in df_splits.columns:\n",
    "    date_col = \"execution_date\"\n",
    "elif \"split_date\" in df_splits.columns:\n",
    "    date_col = \"split_date\"\n",
    "else:\n",
    "    date_col = df_splits.columns[2]  # fallback\n",
    "\n",
    "print(f\"Rango temporal: {df_splits[date_col].min()} → {df_splits[date_col].max()}\")\n",
    "print(f\"\\nSample (5 splits más recientes):\")\n",
    "print(df_splits.sort(date_col, descending=True).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Reverse splits: 15,175 (57.0%)\n",
      "\n",
      "Sample reverse splits:\n",
      "shape: (10, 4)\n",
      "┌────────┬────────────┬──────────┬────────────────┐\n",
      "│ ticker ┆ split_from ┆ split_to ┆ execution_date │\n",
      "│ ---    ┆ ---        ┆ ---      ┆ ---            │\n",
      "│ str    ┆ f64        ┆ f64      ┆ str            │\n",
      "╞════════╪════════════╪══════════╪════════════════╡\n",
      "│ GLCO   ┆ 8.0        ┆ 1.0      ┆ 2001-12-21     │\n",
      "│ IOM    ┆ 5.0        ┆ 1.0      ┆ 2001-10-01     │\n",
      "│ MDDC.E ┆ 5.0        ┆ 1.0      ┆ 2001-03-27     │\n",
      "│ RSMI   ┆ 20.0       ┆ 1.0      ┆ 2001-06-01     │\n",
      "│ VCMP   ┆ 10.0       ┆ 1.0      ┆ 2002-07-08     │\n",
      "│ HDMP   ┆ 100.0      ┆ 1.0      ┆ 2002-12-30     │\n",
      "│ SWLL   ┆ 100.0      ┆ 1.0      ┆ 2002-07-12     │\n",
      "│ NWTB   ┆ 20.0       ┆ 1.0      ┆ 2002-07-01     │\n",
      "│ CDJM   ┆ 10.0       ┆ 1.0      ┆ 2002-04-03     │\n",
      "│ SLVR   ┆ 5000.0     ┆ 1.0      ┆ 2002-10-07     │\n",
      "└────────┴────────────┴──────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Verificar reverse splits (críticos para small caps)\n",
    "# Reverse split: split_from > split_to (ej: 10:1 → 10 shares → 1 share)\n",
    "if \"split_from\" in df_splits.columns and \"split_to\" in df_splits.columns:\n",
    "    df_reverse = df_splits.filter(pl.col(\"split_from\") > pl.col(\"split_to\"))\n",
    "    print(f\"\\n🔍 Reverse splits: {df_reverse.shape[0]:,} ({df_reverse.shape[0]/df_splits.shape[0]*100:.1f}%)\")\n",
    "    print(f\"\\nSample reverse splits:\")\n",
    "    print(df_reverse.head(10).select([\"ticker\", \"split_from\", \"split_to\", date_col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ CERTIFICACIÓN PASO 2\n",
    "\n",
    "**Resultado**: Splits históricos descargados correctamente\n",
    "\n",
    "**Evidencia**:\n",
    "- Total splits: 26,641\n",
    "- Archivos particionados: 31 parquet files\n",
    "- Incluye reverse splits (críticos para small caps)\n",
    "\n",
    "**Path**: `raw/polygon/reference/splits/**/*.parquet`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ PASO 3: Dividends (`/v3/reference/dividends`)\n",
    "\n",
    "**Objetivo**: Descargar historial de dividendos\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_splits_dividends.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/dividends`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\..\\raw\\polygon\\reference\\dividends\n",
      "📂 Archivos de dividendos: 31\n",
      "\n",
      "================================================================================\n",
      "DIVIDENDOS HISTÓRICOS\n",
      "================================================================================\n",
      "Total registros: 1,878,357\n",
      "Columnas:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cash_amount',\n",
       " 'currency',\n",
       " 'dividend_type',\n",
       " 'ex_dividend_date',\n",
       " 'frequency',\n",
       " 'id',\n",
       " 'pay_date',\n",
       " 'record_date',\n",
       " 'ticker',\n",
       " 'declaration_date']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar archivos de dividendos\n",
    "print(DIVIDENDS_PATH)\n",
    "dividend_files = list(DIVIDENDS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"📂 Archivos de dividendos: {len(dividend_files)}\")\n",
    "\n",
    "# Cargar todos los dividendos\n",
    "df_dividends = pl.scan_parquet(DIVIDENDS_PATH / \"**\" / \"*.parquet\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIVIDENDOS HISTÓRICOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total registros: {df_dividends.shape[0]:,}\")\n",
    "print(f\"Columnas:\")\n",
    "[i for i in df_dividends.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISIS DIVIDENDOS\n",
      "================================================================================\n",
      "\n",
      "Sample (5 dividendos más recientes):\n",
      "shape: (5, 10)\n",
      "┌────────────┬──────────┬────────────┬────────────┬───┬───────────┬───────────┬────────┬───────────┐\n",
      "│ cash_amoun ┆ currency ┆ dividend_t ┆ ex_dividen ┆ … ┆ pay_date  ┆ record_da ┆ ticker ┆ declarati │\n",
      "│ t          ┆ ---      ┆ ype        ┆ d_date     ┆   ┆ ---       ┆ te        ┆ ---    ┆ on_date   │\n",
      "│ ---        ┆ str      ┆ ---        ┆ ---        ┆   ┆ str       ┆ ---       ┆ str    ┆ ---       │\n",
      "│ f64        ┆          ┆ str        ┆ str        ┆   ┆           ┆ str       ┆        ┆ str       │\n",
      "╞════════════╪══════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪════════╪═══════════╡\n",
      "│ 0.489757   ┆ USD      ┆ CD         ┆ 2030-12-13 ┆ … ┆ 2030-12-3 ┆ 2030-12-1 ┆ GECCG  ┆ null      │\n",
      "│            ┆          ┆            ┆            ┆   ┆ 1         ┆ 5         ┆        ┆           │\n",
      "│ 0.484375   ┆ USD      ┆ CD         ┆ 2030-09-13 ┆ … ┆ 2030-09-3 ┆ 2030-09-1 ┆ GECCG  ┆ null      │\n",
      "│            ┆          ┆            ┆            ┆   ┆ 0         ┆ 5         ┆        ┆           │\n",
      "│ 0.51719    ┆ USD      ┆ CD         ┆ 2030-07-15 ┆ … ┆ 2030-07-3 ┆ 2030-07-1 ┆ METCI  ┆ null      │\n",
      "│            ┆          ┆            ┆            ┆   ┆ 0         ┆ 5         ┆        ┆           │\n",
      "│ 0.478993   ┆ USD      ┆ CD         ┆ 2030-06-14 ┆ … ┆ 2030-06-3 ┆ 2030-06-1 ┆ GECCG  ┆ null      │\n",
      "│            ┆          ┆            ┆            ┆   ┆ 0         ┆ 5         ┆        ┆           │\n",
      "│ 0.51719    ┆ USD      ┆ CD         ┆ 2030-04-15 ┆ … ┆ 2030-04-3 ┆ 2030-04-1 ┆ METCI  ┆ null      │\n",
      "│            ┆          ┆            ┆            ┆   ┆ 0         ┆ 5         ┆        ┆           │\n",
      "└────────────┴──────────┴────────────┴────────────┴───┴───────────┴───────────┴────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Análisis de dividendos\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DIVIDENDOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sample\n",
    "print(f\"\\nSample (5 dividendos más recientes):\")\n",
    "if \"ex_dividend_date\" in df_dividends.columns:\n",
    "    date_col = \"ex_dividend_date\"\n",
    "elif \"pay_date\" in df_dividends.columns:\n",
    "    date_col = \"pay_date\"\n",
    "else:\n",
    "    date_col = df_dividends.columns[2]\n",
    "\n",
    "print(df_dividends.sort(date_col, descending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ CERTIFICACIÓN PASO 3\n",
    "\n",
    "**Resultado**: Dividendos históricos descargados correctamente\n",
    "\n",
    "**Evidencia**:\n",
    "- Total dividendos: 1,878,357\n",
    "- Archivos particionados: 31 parquet files\n",
    "\n",
    "**Path**: `raw/polygon/reference/dividends/**/*.parquet`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⏳ PASO 4: Ticker Details (`/v3/reference/tickers/{ticker}`)\n",
    "\n",
    "**Objetivo**: Enriquecimiento con float, market cap, sector, etc.\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_ticker_details.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/tickers/{ticker}`\n",
    "\n",
    "**Status**: ⚠️ PARCIALMENTE COMPLETADO (solo sample ejecutado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Archivos de ticker details: 2\n"
     ]
    },
    {
     "ename": "SchemaError",
     "evalue": "extra column in file outside of expected schema: error, hint: specify this column in the schema, or pass extra_columns='ignore' in scan options. File containing extra column: '..\\..\\..\\raw\\polygon\\reference\\ticker_details\\ticker_details_2025-10-24.parquet'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSchemaError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📂 Archivos de ticker details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(details_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(details_files) > \u001b[32m0\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df_details = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscan_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDETAILS_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m**\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTICKER DETAILS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\04_TRADING_SMALLCAPS\\.venv-smallcap\\Lib\\site-packages\\polars\\_utils\\deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\04_TRADING_SMALLCAPS\\.venv-smallcap\\Lib\\site-packages\\polars\\lazyframe\\opt_flags.py:328\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    327\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\04_TRADING_SMALLCAPS\\.venv-smallcap\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2415\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2413\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2414\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mSchemaError\u001b[39m: extra column in file outside of expected schema: error, hint: specify this column in the schema, or pass extra_columns='ignore' in scan options. File containing extra column: '..\\..\\..\\raw\\polygon\\reference\\ticker_details\\ticker_details_2025-10-24.parquet'."
     ]
    }
   ],
   "source": [
    "# Verificar archivos de ticker details\n",
    "details_files = list(DETAILS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"📂 Archivos de ticker details: {len(details_files)}\")\n",
    "\n",
    "if len(details_files) > 0:\n",
    "    df_details = pl.scan_parquet(DETAILS_PATH / \"**\" / \"*.parquet\").collect()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TICKER DETAILS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total registros: {df_details.shape[0]:,}\")\n",
    "    print(f\"Esperados: ~34,380 (universo completo)\")\n",
    "    print(f\"\\n⚠️  Completitud: {df_details.shape[0]/34380*100:.1f}%\")\n",
    "    print(f\"\\nColumnas: {df_details.columns}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  NO HAY ARCHIVOS DE TICKER DETAILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏳ CERTIFICACIÓN PASO 4\n",
    "\n",
    "**Resultado**: Ticker details PARCIALMENTE descargado\n",
    "\n",
    "**Evidencia**:\n",
    "- Archivos: 2 parquet files\n",
    "- Esperado: ~34,380 tickers\n",
    "- Completitud: <1%\n",
    "\n",
    "**Acción pendiente**: Ejecutar descarga completa con `ingest_ticker_details.py`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 RESUMEN EJECUTIVO - A_Universo\n",
    "\n",
    "### Completitud del Bloque A\n",
    "\n",
    "| Paso | Componente | Status | Registros | Completitud |\n",
    "|------|-----------|--------|-----------|-------------|\n",
    "| 1 | Universe Snapshot | ✅ | 34,380 | 100% |\n",
    "| 2 | Splits | ✅ | 26,641 | 100% |\n",
    "| 3 | Dividends | ✅ | 1,878,357 | 100% |\n",
    "| 4 | Ticker Details | ⏳ | ~100 | <1% |\n",
    "| 5 | SCD-2 Dimension | ⏳ | 0 | 0% |\n",
    "\n",
    "### Hallazgos Clave\n",
    "\n",
    "1. ✅ **Anti-survivorship bias**: Incluye 22,527 tickers inactivos (65.5%)\n",
    "2. ✅ **Reverse splits**: Incluidos (críticos para small caps)\n",
    "3. ✅ **Particionamiento**: Datos particionados por fecha/ticker\n",
    "4. ⚠️  **Ticker Details incompleto**: Solo sample descargado\n",
    "5. ⚠️  **SCD-2 no construido**: Dimensión temporal pendiente\n",
    "\n",
    "### Próximos Pasos\n",
    "\n",
    "1. **Completar Ticker Details**: Ejecutar descarga full (34k+ tickers)\n",
    "2. **Construir SCD-2**: Tabla temporal con historial de cambios\n",
    "3. **Filtrado Small Caps**: Aplicar filtros (market cap < $2B, float < 100M, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "**Documentación completa**: [3_descarga_Universo_y_referencia.md](3_descarga_Universo_y_referencia.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-smallcap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
