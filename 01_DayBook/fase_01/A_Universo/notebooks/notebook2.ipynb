{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_Universo - Validaci√≥n de Descarga Polygon Reference Data\n",
    "\n",
    "**Objetivo**: Certificar emp√≠ricamente que hemos descargado el universo completo de tickers + corporate actions.\n",
    "\n",
    "**Documentaci√≥n**: [3_descarga_Universo_y_referencia.md](3_descarga_Universo_y_referencia.md)\n",
    "\n",
    "**Stack**: Polygon API ‚Üí Parquet (raw/polygon/reference/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "BASE_PATH = Path(\"../../../raw/polygon/reference\")\n",
    "TICKERS_PATH = BASE_PATH / \"tickers_snapshot\"\n",
    "SPLITS_PATH = BASE_PATH / \"splits\"\n",
    "DIVIDENDS_PATH = BASE_PATH / \"dividends\"\n",
    "DETAILS_PATH = BASE_PATH / \"ticker_details\"\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ PASO 1: Universe Snapshot (`/v3/reference/tickers`)\n",
    "\n",
    "**Objetivo**: Descargar universo completo con activos + inactivos (anti-survivorship bias)\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_reference_tickers.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/tickers?market=stocks&active=true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Archivos encontrados: 4\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-19\\tickers.parquet (0.39 MB)\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-24\\tickers_all.parquet (1.09 MB)\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-24\\tickers_active.parquet (0.37 MB)\n",
      "  - tickers_snapshot\\snapshot_date=2025-10-24\\tickers_inactive.parquet (0.69 MB)\n"
     ]
    }
   ],
   "source": [
    "# Verificar archivos descargados\n",
    "ticker_files = list(TICKERS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"üìÇ Archivos encontrados: {len(ticker_files)}\")\n",
    "for f in ticker_files:\n",
    "    size_mb = f.stat().st_size / (1024*1024)\n",
    "    print(f\"  - {f.relative_to(BASE_PATH)} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNIVERSE SNAPSHOT - 2025-10-24\n",
      "================================================================================\n",
      "Total tickers: 34,380\n",
      "Columnas: 14\n",
      "\n",
      "Columnas disponibles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ticker',\n",
       " 'name',\n",
       " 'market',\n",
       " 'locale',\n",
       " 'primary_exchange',\n",
       " 'type',\n",
       " 'active',\n",
       " 'currency_name',\n",
       " 'cik',\n",
       " 'composite_figi',\n",
       " 'share_class_figi',\n",
       " 'last_updated_utc',\n",
       " 'snapshot_date',\n",
       " 'delisted_utc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar snapshot m√°s reciente (2025-10-24)\n",
    "df_all = pl.read_parquet(TICKERS_PATH / \"snapshot_date=2025-10-24\" / \"tickers_all.parquet\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UNIVERSE SNAPSHOT - 2025-10-24\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total tickers: {df_all.shape[0]:,}\")\n",
    "print(f\"Columnas: {len(df_all.columns)}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "[i for i in df_all.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANTI-SURVIVORSHIP BIAS VERIFICATION\n",
      "================================================================================\n",
      "‚úÖ Activos:     11,853 (34.5%)\n",
      "‚úÖ Inactivos:   22,527 (65.5%)\n",
      "\n",
      "üìä Total:       34,380\n",
      "\n",
      "‚úì Incluye tickers delistados ‚Üí NO survivorship bias\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis active vs inactive (anti-survivorship bias)\n",
    "active_count = df_all.filter(pl.col(\"active\") == True).shape[0]\n",
    "inactive_count = df_all.filter(pl.col(\"active\") == False).shape[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANTI-SURVIVORSHIP BIAS VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Activos:   {active_count:>8,} ({active_count/df_all.shape[0]*100:.1f}%)\")\n",
    "print(f\"‚úÖ Inactivos: {inactive_count:>8,} ({inactive_count/df_all.shape[0]*100:.1f}%)\")\n",
    "print(f\"\\nüìä Total:     {df_all.shape[0]:>8,}\")\n",
    "print(\"\\n‚úì Incluye tickers delistados ‚Üí NO survivorship bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE: TICKERS INACTIVOS (DELISTADOS)\n",
      "================================================================================\n",
      "shape: (10, 5)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ ticker ‚îÜ name                            ‚îÜ market ‚îÜ type    ‚îÜ delisted_utc         ‚îÇ\n",
      "‚îÇ ---    ‚îÜ ---                             ‚îÜ ---    ‚îÜ ---     ‚îÜ ---                  ‚îÇ\n",
      "‚îÇ str    ‚îÜ str                             ‚îÜ str    ‚îÜ str     ‚îÜ str                  ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ AAAP   ‚îÜ Advanced Accelerator Applicati‚Ä¶ ‚îÜ stocks ‚îÜ ADRC    ‚îÜ 2018-02-12T05:00:00Z ‚îÇ\n",
      "‚îÇ AAB.WS ‚îÜ LEHMAN BROTHERS CURRENCY BASKE‚Ä¶ ‚îÜ stocks ‚îÜ null    ‚îÜ 2008-02-11T05:00:00Z ‚îÇ\n",
      "‚îÇ AABA   ‚îÜ Altaba Inc. Common Stock        ‚îÜ stocks ‚îÜ CS      ‚îÜ 2019-10-07T04:00:00Z ‚îÇ\n",
      "‚îÇ AABC   ‚îÜ ACCESS ANYTIME BANCORP INC      ‚îÜ stocks ‚îÜ null    ‚îÜ 2006-01-04T05:00:00Z ‚îÇ\n",
      "‚îÇ AAC    ‚îÜ Ares Acquisition Corporation    ‚îÜ stocks ‚îÜ CS      ‚îÜ 2023-11-07T05:00:00Z ‚îÇ\n",
      "‚îÇ AAC.U  ‚îÜ Ares Acquisition Corporation U‚Ä¶ ‚îÜ stocks ‚îÜ UNIT    ‚îÜ 2023-11-07T05:00:00Z ‚îÇ\n",
      "‚îÇ AAC.WS ‚îÜ Ares Acquisition Corporation R‚Ä¶ ‚îÜ stocks ‚îÜ WARRANT ‚îÜ 2023-11-07T05:00:00Z ‚îÇ\n",
      "‚îÇ AACC   ‚îÜ ASSET ACCEP CAP CORP            ‚îÜ stocks ‚îÜ null    ‚îÜ 2013-06-14T04:00:00Z ‚îÇ\n",
      "‚îÇ AACE   ‚îÜ ACE CASH EXPRESS INC            ‚îÜ stocks ‚îÜ null    ‚îÜ 2006-10-06T04:00:00Z ‚îÇ\n",
      "‚îÇ AACOU  ‚îÜ AUSTRALIA ACQUISITION CORP   U‚Ä¶ ‚îÜ stocks ‚îÜ null    ‚îÜ 2012-10-16T04:00:00Z ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# Sample de tickers inactivos (delistados)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE: TICKERS INACTIVOS (DELISTADOS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_inactive_sample = df_all.filter(pl.col(\"active\") == False).head(10).select(\n",
    "    [\"ticker\", \"name\", \"market\", \"type\", \"delisted_utc\"]\n",
    ")\n",
    "print(df_inactive_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DISTRIBUCI√ìN POR TIPO\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexJ\\AppData\\Local\\Temp\\ipykernel_29072\\2593403979.py:7: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"count\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (16, 3)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ type ‚îÜ count ‚îÜ active ‚îÇ\n",
      "‚îÇ ---  ‚îÜ ---   ‚îÜ ---    ‚îÇ\n",
      "‚îÇ str  ‚îÜ u32   ‚îÜ u32    ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ CS   ‚îÜ 11471 ‚îÜ 5229   ‚îÇ\n",
      "‚îÇ null ‚îÜ 6830  ‚îÜ 0      ‚îÇ\n",
      "‚îÇ ETF  ‚îÜ 5728  ‚îÜ 4365   ‚îÇ\n",
      "‚îÇ PFD  ‚îÜ 2206  ‚îÜ 441    ‚îÇ\n",
      "‚îÇ SP   ‚îÜ 2164  ‚îÜ 159    ‚îÇ\n",
      "‚îÇ ‚Ä¶    ‚îÜ ‚Ä¶     ‚îÜ ‚Ä¶      ‚îÇ\n",
      "‚îÇ ETN  ‚îÜ 252   ‚îÜ 49     ‚îÇ\n",
      "‚îÇ ETS  ‚îÜ 141   ‚îÜ 126    ‚îÇ\n",
      "‚îÇ ETV  ‚îÜ 74    ‚îÜ 69     ‚îÇ\n",
      "‚îÇ ADRP ‚îÜ 15    ‚îÜ 0      ‚îÇ\n",
      "‚îÇ ADRR ‚îÜ 5     ‚îÜ 0      ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis por tipo de ticker\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DISTRIBUCI√ìN POR TIPO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "type_dist = df_all.group_by(\"type\").agg([\n",
    "    pl.count().alias(\"count\"),\n",
    "    (pl.col(\"active\").sum()).alias(\"active\")\n",
    "]).sort(\"count\", descending=True)\n",
    "\n",
    "print(type_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ CERTIFICACI√ìN PASO 1\n",
    "\n",
    "**Resultado**: Universe snapshot descargado correctamente\n",
    "\n",
    "**Evidencia**:\n",
    "- Total tickers: 34,380\n",
    "- Activos: 11,853 (34.5%)\n",
    "- Inactivos: 22,527 (65.5%)\n",
    "- Anti-survivorship bias: ‚úÖ Incluye delistados\n",
    "\n",
    "**Path**: `raw/polygon/reference/tickers_snapshot/snapshot_date=2025-10-24/tickers_all.parquet`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ PASO 2: Splits (`/v3/reference/splits`)\n",
    "\n",
    "**Objetivo**: Descargar historial de splits para ajuste de precios\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_splits_dividends.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/splits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Archivos de splits: 31\n",
      "\n",
      "================================================================================\n",
      "SPLITS HIST√ìRICOS\n",
      "================================================================================\n",
      "Total registros: 26,641\n",
      "Columnas: ['execution_date', 'id', 'split_from', 'split_to', 'ticker', 'ratio']\n"
     ]
    }
   ],
   "source": [
    "# Verificar archivos de splits\n",
    "split_files = list(SPLITS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"üìÇ Archivos de splits: {len(split_files)}\")\n",
    "\n",
    "# Cargar todos los splits\n",
    "df_splits = pl.scan_parquet(SPLITS_PATH / \"**\" / \"*.parquet\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPLITS HIST√ìRICOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total registros: {df_splits.shape[0]:,}\")\n",
    "print(f\"Columnas: {df_splits.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS SPLITS\n",
      "================================================================================\n",
      "Rango temporal: 1978-10-25 ‚Üí 2025-12-05\n",
      "\n",
      "Sample (5 splits m√°s recientes):\n",
      "shape: (5, 6)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ execution_date ‚îÜ id                              ‚îÜ split_from ‚îÜ split_to ‚îÜ ticker ‚îÜ ratio ‚îÇ\n",
      "‚îÇ ---            ‚îÜ ---                             ‚îÜ ---        ‚îÜ ---      ‚îÜ ---    ‚îÜ ---   ‚îÇ\n",
      "‚îÇ str            ‚îÜ str                             ‚îÜ f64        ‚îÜ f64      ‚îÜ str    ‚îÜ f64   ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 2025-12-05     ‚îÜ E1a62e2d20c68089280a893dc8394f‚Ä¶ ‚îÜ 2.0        ‚îÜ 1.0      ‚îÜ LBIIX  ‚îÜ 2.0   ‚îÇ\n",
      "‚îÇ 2025-12-05     ‚îÜ E80f07aa0c5ba57b124f70f270189c‚Ä¶ ‚îÜ 2.0        ‚îÜ 1.0      ‚îÜ AAHYX  ‚îÜ 2.0   ‚îÇ\n",
      "‚îÇ 2025-12-05     ‚îÜ E92b4fe3b7af6add95df70182ac0c8‚Ä¶ ‚îÜ 2.0        ‚îÜ 1.0      ‚îÜ LUBIX  ‚îÜ 2.0   ‚îÇ\n",
      "‚îÇ 2025-12-05     ‚îÜ E6e01e48aab675431c6a166e82d365‚Ä¶ ‚îÜ 2.0        ‚îÜ 1.0      ‚îÜ THYFX  ‚îÜ 2.0   ‚îÇ\n",
      "‚îÇ 2025-12-05     ‚îÜ Eaf2c45217528b55c3dbb4f54c8233‚Ä¶ ‚îÜ 4.0        ‚îÜ 1.0      ‚îÜ LBHIX  ‚îÜ 4.0   ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis de splits\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS SPLITS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Rango temporal\n",
    "if \"execution_date\" in df_splits.columns:\n",
    "    date_col = \"execution_date\"\n",
    "elif \"split_date\" in df_splits.columns:\n",
    "    date_col = \"split_date\"\n",
    "else:\n",
    "    date_col = df_splits.columns[2]  # fallback\n",
    "\n",
    "print(f\"Rango temporal: {df_splits[date_col].min()} ‚Üí {df_splits[date_col].max()}\")\n",
    "print(f\"\\nSample (5 splits m√°s recientes):\")\n",
    "print(df_splits.sort(date_col, descending=True).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Reverse splits: 15,175 (57.0%)\n",
      "\n",
      "Sample reverse splits:\n",
      "shape: (10, 4)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ ticker ‚îÜ split_from ‚îÜ split_to ‚îÜ execution_date ‚îÇ\n",
      "‚îÇ ---    ‚îÜ ---        ‚îÜ ---      ‚îÜ ---            ‚îÇ\n",
      "‚îÇ str    ‚îÜ f64        ‚îÜ f64      ‚îÜ str            ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ GLCO   ‚îÜ 8.0        ‚îÜ 1.0      ‚îÜ 2001-12-21     ‚îÇ\n",
      "‚îÇ IOM    ‚îÜ 5.0        ‚îÜ 1.0      ‚îÜ 2001-10-01     ‚îÇ\n",
      "‚îÇ MDDC.E ‚îÜ 5.0        ‚îÜ 1.0      ‚îÜ 2001-03-27     ‚îÇ\n",
      "‚îÇ RSMI   ‚îÜ 20.0       ‚îÜ 1.0      ‚îÜ 2001-06-01     ‚îÇ\n",
      "‚îÇ VCMP   ‚îÜ 10.0       ‚îÜ 1.0      ‚îÜ 2002-07-08     ‚îÇ\n",
      "‚îÇ HDMP   ‚îÜ 100.0      ‚îÜ 1.0      ‚îÜ 2002-12-30     ‚îÇ\n",
      "‚îÇ SWLL   ‚îÜ 100.0      ‚îÜ 1.0      ‚îÜ 2002-07-12     ‚îÇ\n",
      "‚îÇ NWTB   ‚îÜ 20.0       ‚îÜ 1.0      ‚îÜ 2002-07-01     ‚îÇ\n",
      "‚îÇ CDJM   ‚îÜ 10.0       ‚îÜ 1.0      ‚îÜ 2002-04-03     ‚îÇ\n",
      "‚îÇ SLVR   ‚îÜ 5000.0     ‚îÜ 1.0      ‚îÜ 2002-10-07     ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# Verificar reverse splits (cr√≠ticos para small caps)\n",
    "# Reverse split: split_from > split_to (ej: 10:1 ‚Üí 10 shares ‚Üí 1 share)\n",
    "if \"split_from\" in df_splits.columns and \"split_to\" in df_splits.columns:\n",
    "    df_reverse = df_splits.filter(pl.col(\"split_from\") > pl.col(\"split_to\"))\n",
    "    print(f\"\\nüîç Reverse splits: {df_reverse.shape[0]:,} ({df_reverse.shape[0]/df_splits.shape[0]*100:.1f}%)\")\n",
    "    print(f\"\\nSample reverse splits:\")\n",
    "    print(df_reverse.head(10).select([\"ticker\", \"split_from\", \"split_to\", date_col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ CERTIFICACI√ìN PASO 2\n",
    "\n",
    "**Resultado**: Splits hist√≥ricos descargados correctamente\n",
    "\n",
    "**Evidencia**:\n",
    "- Total splits: 26,641\n",
    "- Archivos particionados: 31 parquet files\n",
    "- Incluye reverse splits (cr√≠ticos para small caps)\n",
    "\n",
    "**Path**: `raw/polygon/reference/splits/**/*.parquet`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ PASO 3: Dividends (`/v3/reference/dividends`)\n",
    "\n",
    "**Objetivo**: Descargar historial de dividendos\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_splits_dividends.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/dividends`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\..\\raw\\polygon\\reference\\dividends\n",
      "üìÇ Archivos de dividendos: 31\n",
      "\n",
      "================================================================================\n",
      "DIVIDENDOS HIST√ìRICOS\n",
      "================================================================================\n",
      "Total registros: 1,878,357\n",
      "Columnas:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cash_amount',\n",
       " 'currency',\n",
       " 'dividend_type',\n",
       " 'ex_dividend_date',\n",
       " 'frequency',\n",
       " 'id',\n",
       " 'pay_date',\n",
       " 'record_date',\n",
       " 'ticker',\n",
       " 'declaration_date']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar archivos de dividendos\n",
    "print(DIVIDENDS_PATH)\n",
    "dividend_files = list(DIVIDENDS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"üìÇ Archivos de dividendos: {len(dividend_files)}\")\n",
    "\n",
    "# Cargar todos los dividendos\n",
    "df_dividends = pl.scan_parquet(DIVIDENDS_PATH / \"**\" / \"*.parquet\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIVIDENDOS HIST√ìRICOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total registros: {df_dividends.shape[0]:,}\")\n",
    "print(f\"Columnas:\")\n",
    "[i for i in df_dividends.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS DIVIDENDOS\n",
      "================================================================================\n",
      "\n",
      "Sample (5 dividendos m√°s recientes):\n",
      "shape: (5, 10)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ cash_amoun ‚îÜ currency ‚îÜ dividend_t ‚îÜ ex_dividen ‚îÜ ‚Ä¶ ‚îÜ pay_date  ‚îÜ record_da ‚îÜ ticker ‚îÜ declarati ‚îÇ\n",
      "‚îÇ t          ‚îÜ ---      ‚îÜ ype        ‚îÜ d_date     ‚îÜ   ‚îÜ ---       ‚îÜ te        ‚îÜ ---    ‚îÜ on_date   ‚îÇ\n",
      "‚îÇ ---        ‚îÜ str      ‚îÜ ---        ‚îÜ ---        ‚îÜ   ‚îÜ str       ‚îÜ ---       ‚îÜ str    ‚îÜ ---       ‚îÇ\n",
      "‚îÇ f64        ‚îÜ          ‚îÜ str        ‚îÜ str        ‚îÜ   ‚îÜ           ‚îÜ str       ‚îÜ        ‚îÜ str       ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 0.489757   ‚îÜ USD      ‚îÜ CD         ‚îÜ 2030-12-13 ‚îÜ ‚Ä¶ ‚îÜ 2030-12-3 ‚îÜ 2030-12-1 ‚îÜ GECCG  ‚îÜ null      ‚îÇ\n",
      "‚îÇ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ 1         ‚îÜ 5         ‚îÜ        ‚îÜ           ‚îÇ\n",
      "‚îÇ 0.484375   ‚îÜ USD      ‚îÜ CD         ‚îÜ 2030-09-13 ‚îÜ ‚Ä¶ ‚îÜ 2030-09-3 ‚îÜ 2030-09-1 ‚îÜ GECCG  ‚îÜ null      ‚îÇ\n",
      "‚îÇ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ 0         ‚îÜ 5         ‚îÜ        ‚îÜ           ‚îÇ\n",
      "‚îÇ 0.51719    ‚îÜ USD      ‚îÜ CD         ‚îÜ 2030-07-15 ‚îÜ ‚Ä¶ ‚îÜ 2030-07-3 ‚îÜ 2030-07-1 ‚îÜ METCI  ‚îÜ null      ‚îÇ\n",
      "‚îÇ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ 0         ‚îÜ 5         ‚îÜ        ‚îÜ           ‚îÇ\n",
      "‚îÇ 0.478993   ‚îÜ USD      ‚îÜ CD         ‚îÜ 2030-06-14 ‚îÜ ‚Ä¶ ‚îÜ 2030-06-3 ‚îÜ 2030-06-1 ‚îÜ GECCG  ‚îÜ null      ‚îÇ\n",
      "‚îÇ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ 0         ‚îÜ 5         ‚îÜ        ‚îÜ           ‚îÇ\n",
      "‚îÇ 0.51719    ‚îÜ USD      ‚îÜ CD         ‚îÜ 2030-04-15 ‚îÜ ‚Ä¶ ‚îÜ 2030-04-3 ‚îÜ 2030-04-1 ‚îÜ METCI  ‚îÜ null      ‚îÇ\n",
      "‚îÇ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ 0         ‚îÜ 5         ‚îÜ        ‚îÜ           ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis de dividendos\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS DIVIDENDOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sample\n",
    "print(f\"\\nSample (5 dividendos m√°s recientes):\")\n",
    "if \"ex_dividend_date\" in df_dividends.columns:\n",
    "    date_col = \"ex_dividend_date\"\n",
    "elif \"pay_date\" in df_dividends.columns:\n",
    "    date_col = \"pay_date\"\n",
    "else:\n",
    "    date_col = df_dividends.columns[2]\n",
    "\n",
    "print(df_dividends.sort(date_col, descending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ CERTIFICACI√ìN PASO 3\n",
    "\n",
    "**Resultado**: Dividendos hist√≥ricos descargados correctamente\n",
    "\n",
    "**Evidencia**:\n",
    "- Total dividendos: 1,878,357\n",
    "- Archivos particionados: 31 parquet files\n",
    "\n",
    "**Path**: `raw/polygon/reference/dividends/**/*.parquet`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è≥ PASO 4: Ticker Details (`/v3/reference/tickers/{ticker}`)\n",
    "\n",
    "**Objetivo**: Enriquecimiento con float, market cap, sector, etc.\n",
    "\n",
    "**Script**: `scripts/fase_A_universo/ingest_ticker_details.py`\n",
    "\n",
    "**Endpoint**: `https://api.polygon.io/v3/reference/tickers/{ticker}`\n",
    "\n",
    "**Status**: ‚ö†Ô∏è PARCIALMENTE COMPLETADO (solo sample ejecutado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Archivos de ticker details: 2\n"
     ]
    },
    {
     "ename": "SchemaError",
     "evalue": "extra column in file outside of expected schema: error, hint: specify this column in the schema, or pass extra_columns='ignore' in scan options. File containing extra column: '..\\..\\..\\raw\\polygon\\reference\\ticker_details\\ticker_details_2025-10-24.parquet'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSchemaError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìÇ Archivos de ticker details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(details_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(details_files) > \u001b[32m0\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df_details = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscan_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDETAILS_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m**\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTICKER DETAILS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\04_TRADING_SMALLCAPS\\.venv-smallcap\\Lib\\site-packages\\polars\\_utils\\deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\04_TRADING_SMALLCAPS\\.venv-smallcap\\Lib\\site-packages\\polars\\lazyframe\\opt_flags.py:328\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    327\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\04_TRADING_SMALLCAPS\\.venv-smallcap\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2415\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2413\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2414\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mSchemaError\u001b[39m: extra column in file outside of expected schema: error, hint: specify this column in the schema, or pass extra_columns='ignore' in scan options. File containing extra column: '..\\..\\..\\raw\\polygon\\reference\\ticker_details\\ticker_details_2025-10-24.parquet'."
     ]
    }
   ],
   "source": [
    "# Verificar archivos de ticker details\n",
    "details_files = list(DETAILS_PATH.rglob(\"*.parquet\"))\n",
    "print(f\"üìÇ Archivos de ticker details: {len(details_files)}\")\n",
    "\n",
    "if len(details_files) > 0:\n",
    "    df_details = pl.scan_parquet(DETAILS_PATH / \"**\" / \"*.parquet\").collect()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TICKER DETAILS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total registros: {df_details.shape[0]:,}\")\n",
    "    print(f\"Esperados: ~34,380 (universo completo)\")\n",
    "    print(f\"\\n‚ö†Ô∏è  Completitud: {df_details.shape[0]/34380*100:.1f}%\")\n",
    "    print(f\"\\nColumnas: {df_details.columns}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  NO HAY ARCHIVOS DE TICKER DETAILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è≥ CERTIFICACI√ìN PASO 4\n",
    "\n",
    "**Resultado**: Ticker details PARCIALMENTE descargado\n",
    "\n",
    "**Evidencia**:\n",
    "- Archivos: 2 parquet files\n",
    "- Esperado: ~34,380 tickers\n",
    "- Completitud: <1%\n",
    "\n",
    "**Acci√≥n pendiente**: Ejecutar descarga completa con `ingest_ticker_details.py`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä RESUMEN EJECUTIVO - A_Universo\n",
    "\n",
    "### Completitud del Bloque A\n",
    "\n",
    "| Paso | Componente | Status | Registros | Completitud |\n",
    "|------|-----------|--------|-----------|-------------|\n",
    "| 1 | Universe Snapshot | ‚úÖ | 34,380 | 100% |\n",
    "| 2 | Splits | ‚úÖ | 26,641 | 100% |\n",
    "| 3 | Dividends | ‚úÖ | 1,878,357 | 100% |\n",
    "| 4 | Ticker Details | ‚è≥ | ~100 | <1% |\n",
    "| 5 | SCD-2 Dimension | ‚è≥ | 0 | 0% |\n",
    "\n",
    "### Hallazgos Clave\n",
    "\n",
    "1. ‚úÖ **Anti-survivorship bias**: Incluye 22,527 tickers inactivos (65.5%)\n",
    "2. ‚úÖ **Reverse splits**: Incluidos (cr√≠ticos para small caps)\n",
    "3. ‚úÖ **Particionamiento**: Datos particionados por fecha/ticker\n",
    "4. ‚ö†Ô∏è  **Ticker Details incompleto**: Solo sample descargado\n",
    "5. ‚ö†Ô∏è  **SCD-2 no construido**: Dimensi√≥n temporal pendiente\n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "\n",
    "1. **Completar Ticker Details**: Ejecutar descarga full (34k+ tickers)\n",
    "2. **Construir SCD-2**: Tabla temporal con historial de cambios\n",
    "3. **Filtrado Small Caps**: Aplicar filtros (market cap < $2B, float < 100M, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "**Documentaci√≥n completa**: [3_descarga_Universo_y_referencia.md](3_descarga_Universo_y_referencia.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-smallcap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
