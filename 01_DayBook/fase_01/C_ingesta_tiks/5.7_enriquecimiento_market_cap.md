# 5.7 - Enriquecimiento de Market Cap (SCD-2)

**Fecha**: 2025-10-22
**Script**: `build_market_cap_dim.py`
**Estado**: Listo para ejecutar (después del caché diario)

---

## 📦 Contexto

El caché diario (`build_daily_cache.py`) incluye la columna `market_cap_d`, pero inicialmente está en **null** porque:
- `tickers_dim.parquet` NO tiene columna `market_cap`
- Necesitamos una **dimensión SCD-2** dedicada con historial de market cap por fecha

**Solución**: `build_market_cap_dim.py` genera una SCD-2 desde snapshots de ticker_details.

---

## 🎯 ¿Qué hace `build_market_cap_dim.py`?

1. **Lee snapshots** de `raw/polygon/reference/ticker_details/as_of_date=*/details.parquet`
2. **Consolida en SCD-2**:
   - Detecta cambios en `market_cap` o `shares_outstanding`
   - Crea periodos de validez: `(effective_from, effective_to]`
   - Cierra rangos abiertos con `2099-12-31`
3. **(Opcional) Imputa** market_cap faltante usando `close_d × shares_outstanding` desde el caché diario
4. **Escribe** `processed/ref/market_cap_dim/market_cap_dim.parquet` con ZSTD

---

## 🚀 Uso

### **Paso 1: Generar dimensión SCD-2**

```bash
python scripts/fase_C_ingesta_tiks/build_market_cap_dim.py \
  --details-root raw/polygon/reference/ticker_details \
  --outdir processed/ref/market_cap_dim
```

**Output esperado**:
```
processed/ref/market_cap_dim/
├── market_cap_dim.parquet    (SCD-2: ticker, effective_from, effective_to, market_cap, shares_outstanding)
├── MANIFEST.json             (metadata: cobertura, tickers, periodos)
└── _SUCCESS
```

**Tiempo estimado**: <1 minuto (solo hay 1 snapshot: 2025-10-19)

---

### **Paso 2 (Opcional): Imputar market_cap faltante**

Si algunos tickers tienen `market_cap = null` pero `shares_outstanding` disponible, puedes imputar usando precios históricos del caché diario:

```bash
python scripts/fase_C_ingesta_tiks/build_market_cap_dim.py \
  --details-root raw/polygon/reference/ticker_details \
  --outdir processed/ref/market_cap_dim \
  --daily-cache processed/daily_cache \
  --impute
```

**Qué hace**:
- Para cada periodo SCD-2 donde `market_cap = null`:
  - Lee `daily_cache` del ticker
  - Filtra por rango `[effective_from, effective_to)`
  - Calcula: `market_cap_imputed = median(close_d × shares_outstanding)`
  - Reemplaza `market_cap = null` con `market_cap_imputed`

**Cuándo usarlo**:
- Si la cobertura de `market_cap` es baja (<80%)
- Si trabajas con small caps que pueden no tener market_cap en ticker_details

---

### **Paso 3: Re-generar caché diario CON market_cap**

Una vez creada la dimensión SCD-2, re-ejecuta el caché apuntando a `market_cap_dim.parquet`:

```bash
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2020-01-01 --to 2025-10-21 \
  --cap-filter-parquet processed/ref/market_cap_dim/market_cap_dim.parquet \
  --parallel 8
```

**Nota**: El parámetro `--cap-filter-parquet` acepta cualquier parquet SCD-2 con columnas `(ticker, effective_from, effective_to, market_cap)`.

**Resultado**:
- `processed/daily_cache/ticker=XYZ/daily.parquet` ahora tendrá `market_cap_d` poblado (no null)

---

### **Paso 4: Aplicar filtro de cap en universo dinámico**

Re-ejecuta el universo dinámico con el caché actualizado:

```bash
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2020-01-01 --to 2025-10-21 \
  --config configs/universe_config.yaml
```

**Qué cambia**:
- El filtro `cap_max: 2000000000` (configs/universe_config.yaml) ahora **SÍ se aplica**
- Tickers con `market_cap_d > $2B` serán **excluidos** del universo info-rich

**Tiempo estimado**: 10-30 minutos (lee desde caché, no desde 1-min)

---

## 📊 Schema de `market_cap_dim.parquet`

| Columna | Tipo | Descripción |
|---------|------|-------------|
| `ticker` | Utf8 | Símbolo del ticker |
| `effective_from` | Date | Fecha inicio validez (inclusive) |
| `effective_to` | Date | Fecha fin validez (exclusive) |
| `market_cap` | Float64 | Market cap en USD |
| `shares_outstanding` | Float64 | Acciones en circulación |

**SCD-2 (Slowly Changing Dimension Type 2)**:
- Cada fila representa un **periodo de validez** para un ticker
- `effective_from <= trading_day < effective_to`
- Si `market_cap` o `shares_outstanding` cambian, se crea un **nuevo periodo**
- Ultimo periodo tiene `effective_to = 2099-12-31`

---

## 🔍 Validación

### Verificar dimensión creada:

```bash
# Ver MANIFEST
cat processed/ref/market_cap_dim/MANIFEST.json | jq

# Output esperado:
{
  "timestamp": "2025-10-22T...",
  "total_tickers": 10482,
  "total_periods": 10482,  # Si solo hay 1 snapshot, 1 periodo por ticker
  "market_cap_coverage": {
    "total": 10482,
    "with_cap": 8500,      # ~81% tienen market_cap
    "with_shares": 10200   # ~97% tienen shares_outstanding
  }
}
```

---

### Verificar caché actualizado:

```python
import polars as pl

# Antes (sin market_cap_dim)
df_before = pl.read_parquet("processed/daily_cache/ticker=AAPL/daily.parquet")
print(df_before["market_cap_d"].is_null().sum())  # Todos null

# Después (con market_cap_dim)
# Re-ejecutar build_daily_cache.py con --cap-filter-parquet
df_after = pl.read_parquet("processed/daily_cache/ticker=AAPL/daily.parquet")
print(df_after["market_cap_d"].is_null().sum())   # 0 (o muy pocos null)
```

---

### Verificar filtro en universo:

```python
import polars as pl

# Watchlist del día
df = pl.read_parquet("processed/universe/info_rich/daily/date=2025-10-21/watchlist.parquet")

# Info-rich CON filtro de cap
info_rich = df.filter(pl.col("info_rich"))

# Verificar que NO hay tickers con cap > $2B
max_cap = info_rich["market_cap_d"].max()
print(f"Max market cap en info-rich: ${max_cap:,.0f}")  # Debe ser < $2B
```

---

## ⏭️ Alternativa: Skip re-generación de caché

Si **NO quieres re-generar todo el caché** (6-7 horas), puedes:

**Opción A**: Aplicar filtro de cap **solo en lectura** (en `build_dynamic_universe_optimized.py`):
- Hacer join temporal con `market_cap_dim` al leer el caché
- No modifica el caché existente
- Más lento (join por cada ejecución)

**Opción B**: Crear script de **enriquecimiento in-place**:
```bash
python scripts/fase_C_ingesta_tiks/enrich_cache_with_market_cap.py \
  --cache processed/daily_cache \
  --cap-dim processed/ref/market_cap_dim/market_cap_dim.parquet \
  --parallel 8
```
(Script por crear - modifica parquets existentes añadiendo market_cap_d)

---

## 📈 Impacto Esperado

**Sin filtro de cap** (estado actual):
- Universo info-rich: ~200-500 tickers/día (según RVOL, %chg, $vol, precio)

**Con filtro de cap <$2B**:
- Universo info-rich: ~100-300 tickers/día (excluye large caps volátiles como AAPL, TSLA, NVDA)
- Más enfocado en **small caps** (tu objetivo)

**Ejemplo**:
- Ticker: AAPL (market_cap ~$3T) → **EXCLUIDO** ✅
- Ticker: RIOT (market_cap ~$1.5B) → incluido si cumple RVOL/precio/etc.

---

## 🐛 Troubleshooting

### Error: "No se encontraron snapshots de ticker_details"

**Causa**: No existe `raw/polygon/reference/ticker_details/as_of_date=*/`

**Solución**: Descargar snapshots de ticker_details desde Polygon API:
```bash
# (script por crear - descarga ticker_details del día)
python scripts/download_ticker_details.py --date 2025-10-22
```

---

### Warning: "Cobertura de market_cap baja (<80%)"

**Causa**: Muchos tickers no tienen `market_cap` en ticker_details (common en OTC/penny stocks)

**Solución**: Ejecutar con `--impute` para calcular cap desde `close_d × shares`

---

### Error: "Daily cache no encontrado para imputación"

**Causa**: `--daily-cache` no existe o está vacío

**Solución**: Generar caché primero con `build_daily_cache.py` (sin cap), luego ejecutar `build_market_cap_dim.py --impute`

---

## ✅ Resumen del Pipeline Completo

```bash
# 1. Generar caché SIN cap (6-7 horas) - EN PROGRESO
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2020-01-01 --to 2025-10-21 \
  --parallel 8

# 2. Validar universo dinámico SIN cap (<30 min)
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2025-10-15 --to 2025-10-21 \
  --config configs/universe_config.yaml

# 3. (DESPUÉS) Generar dimensión market_cap (<1 min)
python scripts/fase_C_ingesta_tiks/build_market_cap_dim.py \
  --details-root raw/polygon/reference/ticker_details \
  --outdir processed/ref/market_cap_dim \
  --daily-cache processed/daily_cache \
  --impute

# 4. Re-generar caché CON cap (6-7 horas) - OPCIONAL
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2020-01-01 --to 2025-10-21 \
  --cap-filter-parquet processed/ref/market_cap_dim/market_cap_dim.parquet \
  --parallel 8

# 5. Re-ejecutar universo CON cap (<30 min)
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2020-01-01 --to 2025-10-21 \
  --config configs/universe_config.yaml
```

---

**Documento creado**: 2025-10-22
**Autor**: Claude (Anthropic)
**Status**: Script listo - Pendiente de ejecutar después del caché diario
