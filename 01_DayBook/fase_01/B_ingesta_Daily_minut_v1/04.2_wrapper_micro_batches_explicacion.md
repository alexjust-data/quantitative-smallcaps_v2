# Wrapper Micro-Batches: Explicación Completa

## ¿Qué es "wrapper micro-batches"?

El "wrapper micro-batches" es un **patrón de arquitectura** que resuelve los problemas de memoria y estabilidad cuando descargas datos masivos. En lugar de tener procesos de larga duración que pueden acumular memoria y colgarse, usas **procesos desechables** que viven poco tiempo y mueren al terminar.

---

## Comparación Visual: Launcher vs Wrapper

### LAUNCHER (launch_intraday_windows.py)

```
┌─────────────────────────────────────────────────────────┐
│ LAUNCHER                                                 │
│ divide 3,107 tickers en 12 shards → 12 procesos         │
└─────────────────────────────────────────────────────────┘
                        ↓
    ┌──────────────────┬──────────────────┬──────────────────┐
    │ Worker 0         │ Worker 1         │ ...Worker 11     │
    │ 259 tickers      │ 259 tickers      │ 259 tickers      │
    │ PROCESO VIVO     │ PROCESO VIVO     │ PROCESO VIVO     │
    │ DURANTE HORAS    │ DURANTE HORAS    │ DURANTE HORAS    │
    └──────────────────┴──────────────────┴──────────────────┘
           ↓                    ↓                    ↓
      Procesa              Procesa              Procesa
      secuencialmente      secuencialmente      secuencialmente
      los 259 tickers      los 259 tickers      los 259 tickers

      SI FALLA en ticker 50 → puede que muera sin procesar los 209 restantes
      Acumula RAM durante horas → puede quedarse sin memoria
      Conexiones TLS abiertas durante horas → pueden corromperse
```

**Problemas del Launcher:**
- ✗ Procesos viven demasiado tiempo (horas)
- ✗ Acumulan memoria gradualmente
- ✗ Si un ticker problemático mata el proceso, pierdes todos los pendientes
- ✗ Difícil diagnosticar qué ticker causó el problema
- ✗ Conexiones TLS pueden corromperse con el tiempo

---

### WRAPPER (batch_intraday_wrapper.py)

```
┌─────────────────────────────────────────────────────────┐
│ WRAPPER                                                  │
│ divide 3,107 tickers en ~124 batches de 25 cada uno     │
│ ejecuta MÁXIMO 6 batches en paralelo                    │
└─────────────────────────────────────────────────────────┘
                        ↓
    ┌──────────────────┬──────────────────┬──────────────────┐
    │ Batch 0          │ Batch 1          │ ... Batch 5      │
    │ 25 tickers       │ 25 tickers       │ 25 tickers       │
    │ PROCESO          │ PROCESO          │ PROCESO          │
    │ DESECHABLE       │ DESECHABLE       │ DESECHABLE       │
    │ vive ~10-30 min  │ vive ~10-30 min  │ vive ~10-30 min  │
    └──────────────────┴──────────────────┴──────────────────┘
           ↓                    ↓                    ↓
      Termina → MUERE     Termina → MUERE     Termina → MUERE
      Libera RAM          Libera RAM          Libera RAM
      Cierra sockets      Cierra sockets      Cierra sockets
                        ↓
    ┌──────────────────┬──────────────────┬──────────────────┐
    │ Batch 6          │ Batch 7          │ ... Batch 11     │
    │ NUEVO PROCESO    │ NUEVO PROCESO    │ NUEVO PROCESO    │
    │ RAM LIMPIA       │ RAM LIMPIA       │ RAM LIMPIA       │
    └──────────────────┴──────────────────┴──────────────────┘
```

**Ventajas del Wrapper:**
- ✓ Procesos viven poco (~10-30 min)
- ✓ Al morir, liberan TODA la RAM automáticamente
- ✓ Si falla un batch, solo pierdes 25 tickers (no 259)
- ✓ Cada batch tiene su propio log → fácil diagnóstico
- ✓ Conexiones TLS frescas en cada batch
- ✓ Reintento automático por batch (hasta 2 intentos)
- ✓ Control de concurrencia (solo 6 batches a la vez)

---

## ¿Cómo Funciona el Wrapper en Detalle?

### 1. Dividir tickers en batches

```python
# Universo: 3,107 tickers
# batch_size = 25
# → Resultado: 124 batches

batches = chunk_list(tickers, args.batch_size)
# batch[0]   = [AAPL, MSFT, ..., TSLA]     (25 tickers)
# batch[1]   = [NVDA, AMD,  ..., INTC]     (25 tickers)
# ...
# batch[123] = [ZZZ, YYY, ...]             (7 tickers) ← último batch puede ser menor
```

### 2. Ejecutar batches con paralelismo controlado

```python
# max_concurrent = 6  →  solo 6 procesos simultáneos
with ThreadPoolExecutor(max_workers=6) as ex:
    # Lanza los 124 batches, pero solo 6 corren a la vez
    futs = {ex.submit(run_batch, i, b, args, ...): i for i, b in enumerate(batches)}
```

**Flujo de ejecución:**
```
[Batch 0] [Batch 1] [Batch 2] [Batch 3] [Batch 4] [Batch 5]  ← 6 corriendo

Batch 2 termina → MUERE
                ↓
[Batch 0] [Batch 1] [Batch 6] [Batch 3] [Batch 4] [Batch 5]  ← Batch 6 toma su lugar

Batch 0 termina → MUERE
    ↓
[Batch 7] [Batch 1] [Batch 6] [Batch 3] [Batch 4] [Batch 5]  ← Batch 7 toma su lugar

... y así hasta completar los 124 batches
```

### 3. Cada batch = 1 subproceso del ingestor

```python
def run_batch(batch_id, tickers, ...):
    # 1. Crea CSV temporal con los 25 tickers de este batch
    csv_path = temp_dir / f"batch_{batch_id:04d}.csv"
    pl.DataFrame({"ticker": tickers}).write_csv(csv_path)

    # 2. Lanza subproceso del ingestor
    cmd = [
        sys.executable, "ingest_ohlcv_intraday_minute.py",
        "--tickers-csv", str(csv_path),
        "--outdir", args.outdir,
        "--from", args.date_from,
        "--to", args.date_to,
        "--rate-limit", str(args.rate_limit),
        "--max-tickers-per-process", str(len(tickers)),  # ← CLAVE: 25
    ]

    # 3. Ejecuta y captura log
    log_path = temp_dir / f"batch_{batch_id:04d}.log"
    proc = subprocess.run(cmd, stdout=log_file, stderr=subprocess.STDOUT)

    # 4. Proceso termina → muere → RAM liberada
    # 5. Retorna código de salida
    return (batch_id, "success" if proc.returncode == 0 else "failed", elapsed)
```

### 4. El ingestor procesa su batch y MUERE

Dentro de `ingest_ohlcv_intraday_minute.py`:

```python
# args.max_tickers_per_process = 25
tickers = ["AAPL", "MSFT", ..., "TSLA"]  # 25 tickers del CSV

for t in tickers:
    fetch_and_stream_write(session, api_key, t, ...)
    processed += 1

    # Checkpoint cada 25 tickers → en este caso, al finalizar
    if processed % 25 == 0:
        log(f"Progreso {processed}/{len(tickers)}")

    # Cuando procesó todos sus tickers, sale limpio
    if args.max_tickers_per_process and processed >= args.max_tickers_per_process:
        log(f"Alcanzado --max-tickers-per-process={args.max_tickers_per_process}. Saliendo.")
        break  # ← SALE DEL SCRIPT

# Script termina → proceso muere → Python garbage collector libera TODA la RAM
```

---

## Reintentos Automáticos y Manejo de Errores

### ¿Qué pasa si un batch falla?

El wrapper implementa **reintentos automáticos a nivel de batch**:

```python
def run_batch(batch_id, tickers, ..., tries: int = 2):
    """
    Reintenta hasta 'tries' veces si el exit code != 0.
    """
    attempt = 0
    rc = 1  # código de retorno (0 = éxito, != 0 = error)

    while attempt < tries:
        attempt += 1
        with open(log_path, "a") as lf:
            lf.write(f"== BATCH {batch_id:04d} attempt {attempt}/{tries} ==\n")
            proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT)
            rc = proc.returncode

        if rc == 0:
            break  # ✓ Éxito → sale del loop

        time.sleep(3)  # Espera 3s antes de reintentar

    # Si después de 2 intentos sigue fallando → marca como failed
    status = "success" if rc == 0 else f"failed(rc={rc})"
    return (batch_id, status, elapsed)
```

### Escenarios concretos:

#### ✓ Escenario 1: Batch exitoso al primer intento
```
Batch 0 (25 tickers): AAPL, MSFT, ..., TSLA
  Attempt 1/2: Descarga OK → exit code 0
  ✓ Marcado como SUCCESS
  → Continúa con Batch 1
```

#### ✓ Escenario 2: Batch falla por SSL, reintenta y tiene éxito
```
Batch 5 (25 tickers): NVDA, AMD, ..., INTC
  Attempt 1/2: SSL error → exit code 1
  (espera 3s)
  Attempt 2/2: Descarga OK → exit code 0
  ✓ Marcado como SUCCESS
  → Continúa con siguiente batch
```

#### ✗ Escenario 3: Batch falla ambos intentos
```
Batch 12 (25 tickers): XYZ, ABC, ..., DEF
  Attempt 1/2: Timeout → exit code 1
  (espera 3s)
  Attempt 2/2: Timeout → exit code 1
  ✗ Marcado como FAILED(rc=1)
  → Log guardado en batch_0012.log
  → Continúa con siguiente batch (no detiene todo el proceso)
```

### ¿Qué pasa si un ticker se cuelga indefinidamente?

**Dentro del ingestor** (`ingest_ohlcv_intraday_minute.py`), cada request tiene timeout:

```python
TIMEOUT = 40  # segundos
r = session.get(url, params=params, headers=headers, timeout=TIMEOUT)
```

Si un ticker se cuelga:
1. Después de 40 segundos → `requests.exceptions.Timeout`
2. El ingestor **captura la excepción** y continúa:
   ```python
   for t in tickers:
       try:
           res = fetch_and_stream_write(session, api_key, t, ...)
           results.append(res)
       except Exception as e:
           results.append(f"{t}: ERROR {e}")  # ← Marca como error pero CONTINÚA
       processed += 1
   ```
3. El batch **no se cuelga** → procesa los 24 tickers restantes
4. Al final, el batch sale con exit code 0 (éxito parcial)

**Pero:** Si el ticker tiene un bug que causa un **hang total** (no timeout, sino freeze del proceso):
- El batch se quedaría colgado indefinidamente
- El wrapper **no tiene timeout a nivel de batch** actualmente
- Ese batch ocuparía 1 de los 6 slots de concurrencia
- Los otros 5 slots seguirían procesando normalmente

**Solución recomendada** (no implementada aún):
```python
# En run_batch(), usar subprocess con timeout
proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT,
                     text=True, timeout=3600)  # ← 1 hora max por batch
```

---

## ¿Se auto-ejecuta hasta completar el 100% de tickers?

### Respuesta corta: NO automáticamente, pero casi.

El wrapper garantiza:
- ✓ Procesa **todos** los 124 batches (no se detiene si uno falla)
- ✓ Cada batch reintenta hasta 2 veces automáticamente
- ✗ Si un batch falla 2 veces → esos 25 tickers quedan como FAILED
- ✗ **No** reintenta infinitamente (evita loops eternos)

### Ejemplo de ejecución completa:

```
Total batches: 124
Ejecutando...

Batch 0000: success (45.3s) | Progreso 1/124 = 0.8%
Batch 0001: success (52.1s) | Progreso 2/124 = 1.6%
...
Batch 0012: failed(rc=1) (180.5s) | Progreso 13/124 = 10.5%  ← Falló después de 2 intentos
...
Batch 0123: success (48.7s) | Progreso 124/124 = 100.0%

================================================================
✓ COMPLETADO: 122/124 batches OK | 2 fallidos
⏱️ Tiempo total: 8.45 h
🧾 Logs por batch: raw/polygon/ohlcv_intraday_1m/_batch_temp/
================================================================
```

**Resultado:**
- 122 batches × 25 tickers = 3,050 tickers ✓ completados
- 2 batches × 25 tickers = 50 tickers ✗ fallidos
- **Total procesado: 98.4%** (no 100%, pero cercano)

### Para alcanzar el 100%:

**Opción 1: Reintentar manualmente los batches fallidos**
```bash
# Revisar logs de batches fallidos
cat raw/polygon/ohlcv_intraday_1m/_batch_temp/batch_0012.log

# Crear CSV con solo esos 25 tickers problemáticos
# Re-ejecutar el wrapper solo con ese CSV
python batch_intraday_wrapper.py \
  --tickers-csv failed_tickers.csv \
  --batch-size 5 \  # ← batches más pequeños para tickers problemáticos
  ...
```

**Opción 2: Usar --resume para completar faltantes**

El wrapper tiene lógica de resume:
```python
if args.resume:
    completed = get_completed_tickers(outdir)  # Revisa qué tickers YA tienen datos
    tickers = [t for t in all_tickers if t not in completed]
    log(f"--resume: {len(completed):,} tickers ya con datos | pendientes: {len(tickers):,}")
```

Entonces puedes re-ejecutar:
```bash
python batch_intraday_wrapper.py \
  --tickers-csv processed/universe/cs_xnas_xnys_under2b_2025-10-21.csv \
  --resume \  # ← Excluye los que ya tienen datos
  ...
```

Solo procesará los 50 tickers que quedaron pendientes.

---

## ¿Qué pasa si hay errores internos (SSL, memoria, etc.)?

El **ingestor** maneja errores con **reintentos inteligentes**:

### Sistema de reintentos dentro del ingestor

```python
def http_get_json(session, url, params, headers):
    last_error = None
    for k in range(1, RETRY_MAX + 1):  # RETRY_MAX = 8
        try:
            r = session.get(url, params=params, headers=headers, timeout=TIMEOUT)

            if r.status_code == 429:  # Rate limit
                sl = int(r.headers.get("Retry-After", "2"))
                log(f"429 Rate Limit -> sleep {sl}s")
                time.sleep(sl)
                continue

            if 500 <= r.status_code < 600:  # Server error
                sl = min(30, BACKOFF ** k)
                log(f"{r.status_code} Server Error -> backoff {sl:.1f}s")
                time.sleep(sl)
                continue

            r.raise_for_status()
            return r.json()

        except Exception as e:
            last_error = e
            msg = str(e).lower()

            # Reintentos inteligentes según tipo de error
            if "certificate" in msg or "ssl" in msg:
                sl = 2  # Retry rápido para SSL/TLS
            elif "allocate" in msg or "buffer" in msg or "decompress" in msg:
                sl = min(60, BACKOFF ** (k + 2))  # Más lento para memoria
            else:
                sl = min(30, BACKOFF ** k)

            log(f"GET error {e} -> backoff {sl:.1f}s")
            time.sleep(sl)

    # Después de 8 intentos → levanta excepción
    raise RuntimeError(f"Failed after {RETRY_MAX} attempts: {last_error}")
```

### Flujo con errores:

```
Ticker AAPL, página 1:
  Intento 1: SSL error → espera 2s → reintenta
  Intento 2: SSL error → espera 2s → reintenta
  Intento 3: ✓ OK → descarga página 1

Ticker AAPL, página 2:
  Intento 1: ✓ OK → descarga página 2

Ticker AAPL, página 3:
  Intento 1: 429 Rate Limit → espera 5s (según Retry-After header) → reintenta
  Intento 2: ✓ OK → descarga página 3

... (AAPL completado)

Ticker MSFT, página 1:
  Intento 1: Memory allocation error → espera 2.6s → reintenta
  Intento 2: Memory allocation error → espera 4.1s → reintenta
  Intento 3: Memory allocation error → espera 6.6s → reintenta
  Intento 4: ✓ OK → descarga página 1

... (MSFT completado)

Ticker XYZ (ticker problemático), página 1:
  Intento 1: Timeout → espera 1.6s
  Intento 2: Timeout → espera 2.6s
  Intento 3: Timeout → espera 4.1s
  ...
  Intento 8: Timeout → espera 51.2s
  → RuntimeError: "Failed after 8 attempts"
  → Capturado por try/except → se marca como "XYZ: ERROR ..."
  → Batch CONTINÚA con siguiente ticker
```

**Resultado:**
- AAPL: ✓ completado (con 2 reintentos SSL)
- MSFT: ✓ completado (con 3 reintentos memoria)
- XYZ: ✗ error (después de 8 intentos)
- Batch termina con exit code 0 (éxito parcial: 24/25 tickers OK)

---

## Ventajas del Wrapper vs Launcher

| Aspecto | Launcher | Wrapper |
|---------|----------|---------|
| **Duración proceso** | Horas | Minutos |
| **Memoria** | Acumulativa | Liberada al morir |
| **Fallo catastrófico** | Pierdes 259 tickers | Pierdes 25 tickers |
| **Diagnóstico** | Log único de 259 tickers | Log separado por batch |
| **Reintentos** | Manual | Automático (2 intentos) |
| **Conexiones TLS** | Reutilizadas (pueden corromperse) | Frescas por batch |
| **Control concurrencia** | Todos los workers a la vez | Solo 6 batches simultáneos |
| **Resume** | Por carpeta ticker | Por carpeta ticker |
| **Rate limiting** | Compartido entre workers | Individual por batch |

---

## Código Completo del Wrapper

### Función principal: run_batch()

```python
def run_batch(batch_id: int, tickers: List[str], args, script_path: Path,
              temp_dir: Path, tries: int = 2) -> Tuple[int, str, float]:
    """
    Lanza un subproceso del ingestor "streaming" procesando este batch.
    Reintenta hasta 'tries' veces si el exit code != 0.
    """
    start = time.time()

    # 1. Crear CSV temporal con los tickers de este batch
    csv_path = temp_dir / f"batch_{batch_id:04d}.csv"
    pl.DataFrame({"ticker": tickers}).write_csv(csv_path)

    # 2. Preparar comando del subproceso
    log_path = temp_dir / f"batch_{batch_id:04d}.log"
    cmd = [
        sys.executable, str(script_path),
        "--tickers-csv", str(csv_path),
        "--outdir", args.outdir,
        "--from", args.date_from,
        "--to", args.date_to,
        "--rate-limit", str(args.rate_limit),
        "--max-tickers-per-process", str(len(tickers)),  # ← CLAVE
        "--max-workers", "1",  # ignorado por ingestor streaming
    ]

    # 3. Heredar variables de entorno (API key, SSL config)
    env = os.environ.copy()

    # 4. Ejecutar con reintentos
    attempt = 0
    rc = 1
    while attempt < tries:
        attempt += 1
        with open(log_path, "a", encoding="utf-8") as lf:
            lf.write(f"== BATCH {batch_id:04d} attempt {attempt}/{tries} ==\n")
            lf.flush()
            proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT, text=True)
            rc = proc.returncode

        if rc == 0:
            break  # Éxito

        time.sleep(3)  # Espera antes de reintentar

    elapsed = time.time() - start

    # 5. Limpiar CSV temporal (conservar log para diagnóstico)
    try:
        csv_path.unlink(missing_ok=True)
    except Exception:
        pass

    status = "success" if rc == 0 else f"failed(rc={rc})"
    return (batch_id, status, elapsed)
```

### Ejecución paralela de batches

```python
def main():
    # ... (parsear argumentos, leer tickers, aplicar --resume) ...

    # Dividir en batches
    batches = chunk_list(tickers, args.batch_size)

    log("== Config ==")
    log(f"  Universo pendiente: {len(tickers):,} tickers")
    log(f"  Batches: {len(batches)} × {args.batch_size} tickers")
    log(f"  Concurrencia: {args.max_concurrent} batches a la vez")

    start = time.time()
    results = []

    # ThreadPoolExecutor para lanzar SUBPROCESOS (IO-bound)
    with ThreadPoolExecutor(max_workers=args.max_concurrent) as ex:
        # Enviar todos los batches (124), pero solo 6 corren simultáneamente
        futs = {ex.submit(run_batch, i, b, args, script_path, temp_dir): i
                for i, b in enumerate(batches)}

        # Recoger resultados conforme terminan
        for fut in as_completed(futs):
            bid, status, elapsed = fut.result()
            results.append((bid, status, elapsed))

            done = len(results)
            pct = done / len(batches) * 100
            log(f"📦 Batch {bid:04d}: {status} ({elapsed:.1f}s) | "
                f"Progreso {done}/{len(batches)} = {pct:.1f}%")

    # Reporte final
    ok = sum(1 for _, s, _ in results if s == "success")
    fail = len(results) - ok
    elapsed_all = time.time() - start

    log("\n" + "="*60)
    log(f"✓ COMPLETADO: {ok}/{len(results)} batches OK | {fail} fallidos")
    log(f"⏱️ Tiempo total: {elapsed_all/3600:.2f} h")
    log(f"🧾 Logs por batch: {temp_dir}/")
```

---

## Uso Práctico

### Comando completo:

```bash
export POLYGON_API_KEY=tu_api_key_aqui

python scripts/fase_1_Bloque_B/tools/batch_intraday_wrapper.py \
  --tickers-csv processed/universe/cs_xnas_xnys_under2b_2025-10-21.csv \
  --outdir raw/polygon/ohlcv_intraday_1m \
  --from 2004-01-01 \
  --to 2010-12-31 \
  --batch-size 25 \
  --max-concurrent 6 \
  --rate-limit 0.20 \
  --ingest-script scripts/fase_1_Bloque_B/ingest_ohlcv_intraday_minute.py \
  --resume
```

### Parámetros clave:

- `--batch-size 25`: Cada batch procesa 25 tickers → 124 batches total
- `--max-concurrent 6`: Solo 6 batches corriendo a la vez
- `--rate-limit 0.20`: Espera 0.2s entre páginas (5 páginas/segundo)
- `--resume`: Excluye tickers que ya tienen datos descargados
- `--ingest-script`: Ruta al ingestor "streaming" (sin hilos internos)

### Monitoreo durante ejecución:

```bash
# Ver progreso en tiempo real
tail -f raw/polygon/ohlcv_intraday_1m/_batch_temp/batch_0001.log

# Contar batches completados
ls raw/polygon/ohlcv_intraday_1m/_batch_temp/*.log | wc -l

# Ver últimas líneas de todos los logs
for log in raw/polygon/ohlcv_intraday_1m/_batch_temp/*.log; do
    echo "=== $log ==="
    tail -n 3 "$log"
done
```

---

## Resumen Final

### El wrapper micro-batches es:

1. **Divide y vencerás**: 3,107 tickers → 124 batches pequeños
2. **Procesos desechables**: Cada batch vive ~10-30 min y muere → libera RAM
3. **Paralelismo controlado**: Solo 6 batches simultáneos → no saturar CPU/red
4. **Reintentos automáticos**: 2 intentos por batch si falla
5. **Diagnóstico sencillo**: Log separado por batch
6. **Resiliente a errores**: Si 1 batch falla → continúa con los otros 123

### ¿Completa el 100%?

**No automáticamente**, pero:
- ✓ Procesa todos los batches (no se detiene si uno falla)
- ✓ Cada batch reintenta 2 veces
- ✓ Errores internos (SSL, memoria) se manejan con hasta 8 reintentos por página
- ✗ Si un batch falla 2 veces → esos 25 tickers quedan pendientes
- ✓ Puedes usar `--resume` para re-ejecutar solo los faltantes

**Resultado típico: 98-99% completado** en primera ejecución, 100% después de 1-2 re-ejecuciones con `--resume`.

### ¿Por qué es mejor que el launcher?

| Problema del Launcher | Solución del Wrapper |
|----------------------|---------------------|
| Procesos viven horas → acumulan memoria | Procesos viven minutos → mueren y liberan |
| Si falla worker → pierdes 259 tickers | Si falla batch → pierdes 25 tickers |
| Log único gigante difícil de diagnosticar | Log separado por batch, fácil de revisar |
| Sin reintentos automáticos | 2 reintentos automáticos por batch |
| Conexiones TLS pueden corromperse | Conexiones frescas en cada batch |
| Difícil controlar concurrencia | `--max-concurrent` controla cuántos a la vez |

---

## Próximos Pasos Recomendados

1. **Ejecutar el wrapper** en lugar del launcher para la descarga 2004-2010
2. **Monitorear logs** de batches para detectar problemas
3. **Usar --resume** para completar tickers faltantes después de primera ejecución
4. **Ajustar parámetros** según tu máquina:
   - `--batch-size`: Más pequeño si hay muchos errores (ej. 15)
   - `--max-concurrent`: Más alto si tienes buena conexión (ej. 10)
   - `--rate-limit`: Más bajo si tienes plan Premium de Polygon (ej. 0.10)

---

**Fecha de creación**: 2025-10-21
**Versión del ingestor**: Streaming (sin hilos internos)
**Versión del wrapper**: Micro-batches con reintentos automáticos
