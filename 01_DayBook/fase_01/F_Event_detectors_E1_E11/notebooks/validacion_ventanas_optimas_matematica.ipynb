{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación Matemática de Ventanas Temporales Óptimas\n",
    "\n",
    "**Objetivo**: Determinar empíricamente la ventana temporal óptima `[t_start, t_end]` para cada evento E1-E11.\n",
    "\n",
    "**Pregunta central**: ¿Cuándo debemos comenzar a recoger ticks **anticipando** el evento y hasta cuándo después del evento para maximizar información predictiva?\n",
    "\n",
    "## Enfoque Matemático\n",
    "\n",
    "Usaremos 3 métodos complementarios:\n",
    "\n",
    "1. **Information Gain (IG)**: Mide reducción de entropía por día\n",
    "2. **Feature Importance (FI)**: Usando LightGBM para medir contribución predictiva\n",
    "3. **Mutual Information (MI)**: Mide dependencia entre features de día `t` y target\n",
    "\n",
    "### Notación\n",
    "\n",
    "- `t=0`: Día del evento\n",
    "- `t<0`: Días antes del evento (anticipación)\n",
    "- `t>0`: Días después del evento (confirmación)\n",
    "- `X_t`: Features del día `t` (precios, volumen, DIB bars, etc.)\n",
    "- `y`: Target (retorno futuro, ej. `ret_5d`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.stats import entropy\n",
    "import lightgbm as lgb\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Config\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Paths\n",
    "TRADES_DIR = Path('../../../../raw/polygon/trades_pilot50_validation')\n",
    "DIB_DIR = Path('../../../../processed/dib_bars/pilot50_validation')\n",
    "WATCHLIST = Path('../../../../processed/watchlist_E1_E11.parquet')\n",
    "\n",
    "print(f\"Trades dir exists: {TRADES_DIR.exists()}\")\n",
    "print(f\"DIB dir exists: {DIB_DIR.exists()}\")\n",
    "print(f\"Watchlist exists: {WATCHLIST.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definición Matemática de Ventana Óptima\n",
    "\n",
    "### 2.1 Información Mutua\n",
    "\n",
    "Para cada día `t` relativo al evento:\n",
    "\n",
    "$$I(X_t; y) = \\sum_{x_t} \\sum_{y} p(x_t, y) \\log \\frac{p(x_t, y)}{p(x_t)p(y)}$$\n",
    "\n",
    "**Interpretación**: Cuánta información sobre el target `y` nos da conocer las features del día `t`.\n",
    "\n",
    "### 2.2 Information Gain\n",
    "\n",
    "$$IG(X_t) = H(y) - H(y|X_t)$$\n",
    "\n",
    "Donde:\n",
    "- $H(y)$ = Entropía del target sin información\n",
    "- $H(y|X_t)$ = Entropía condicional dado las features del día `t`\n",
    "\n",
    "### 2.3 Ventana Óptima\n",
    "\n",
    "La ventana óptima `[t_start, t_end]` maximiza la información total:\n",
    "\n",
    "$$[t^*_{start}, t^*_{end}] = \\arg\\max_{t_{start}, t_{end}} \\sum_{t=t_{start}}^{t_{end}} I(X_t; y)$$\n",
    "\n",
    "**Con restricciones**:\n",
    "1. $I(X_t; y) > \\theta$ (threshold mínimo de información)\n",
    "2. Cost: Cada día adicional tiene costo de descarga/procesamiento\n",
    "3. $t_{start} \\geq -7$ (máximo 7 días anticipación práctica)\n",
    "4. $t_{end} \\leq +7$ (máximo 7 días confirmación práctica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Método 1: Information Gain por Día\n",
    "\n",
    "Calculamos cuánta información aporta cada día `t` relativo al evento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mutual_information(\n",
    "    X: np.ndarray,  # Features del día t\n",
    "    y: np.ndarray,  # Target\n",
    "    bins: int = 10\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcula información mutua I(X;y) entre features de un día y target.\n",
    "    \n",
    "    Args:\n",
    "        X: Features (N_samples, N_features)\n",
    "        y: Target (N_samples,)\n",
    "        bins: Bins para discretizar variables continuas\n",
    "    \n",
    "    Returns:\n",
    "        Mutual information score (bits)\n",
    "    \"\"\"\n",
    "    # Discretizar target para mutual information\n",
    "    y_binned = pd.cut(y, bins=bins, labels=False)\n",
    "    \n",
    "    # Calcular MI para cada feature y promediar\n",
    "    mi_scores = []\n",
    "    for col_idx in range(X.shape[1]):\n",
    "        x_col = X[:, col_idx]\n",
    "        \n",
    "        # Discretizar feature\n",
    "        x_binned = pd.cut(x_col, bins=bins, labels=False, duplicates='drop')\n",
    "        \n",
    "        # Calcular MI\n",
    "        # Eliminar NaN de binning\n",
    "        valid_mask = ~(pd.isna(x_binned) | pd.isna(y_binned))\n",
    "        if valid_mask.sum() > 0:\n",
    "            mi = mutual_info_score(x_binned[valid_mask], y_binned[valid_mask])\n",
    "            mi_scores.append(mi)\n",
    "    \n",
    "    return np.mean(mi_scores) if mi_scores else 0.0\n",
    "\n",
    "\n",
    "def calculate_information_gain(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    bins: int = 10\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcula Information Gain: IG(X) = H(y) - H(y|X)\n",
    "    \n",
    "    Returns:\n",
    "        Information gain (bits)\n",
    "    \"\"\"\n",
    "    # Entropía sin condición\n",
    "    y_binned = pd.cut(y, bins=bins, labels=False)\n",
    "    y_counts = pd.Series(y_binned).value_counts(normalize=True)\n",
    "    H_y = entropy(y_counts.values, base=2)\n",
    "    \n",
    "    # Entropía condicional promedio sobre features\n",
    "    H_y_given_X = []\n",
    "    for col_idx in range(X.shape[1]):\n",
    "        x_col = X[:, col_idx]\n",
    "        x_binned = pd.cut(x_col, bins=bins, labels=False, duplicates='drop')\n",
    "        \n",
    "        # H(y|X=x) para cada valor de x\n",
    "        valid_mask = ~(pd.isna(x_binned) | pd.isna(y_binned))\n",
    "        if valid_mask.sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        df_temp = pd.DataFrame({\n",
    "            'x': x_binned[valid_mask],\n",
    "            'y': y_binned[valid_mask]\n",
    "        })\n",
    "        \n",
    "        conditional_entropy = 0\n",
    "        for x_val in df_temp['x'].unique():\n",
    "            y_given_x = df_temp[df_temp['x'] == x_val]['y']\n",
    "            p_x = len(y_given_x) / len(df_temp)\n",
    "            y_counts_given_x = y_given_x.value_counts(normalize=True)\n",
    "            h = entropy(y_counts_given_x.values, base=2)\n",
    "            conditional_entropy += p_x * h\n",
    "        \n",
    "        H_y_given_X.append(conditional_entropy)\n",
    "    \n",
    "    H_y_given_X_avg = np.mean(H_y_given_X) if H_y_given_X else H_y\n",
    "    \n",
    "    return max(0, H_y - H_y_given_X_avg)\n",
    "\n",
    "\n",
    "print(\"✓ Funciones de información mutua definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Método 2: Feature Importance con LightGBM\n",
    "\n",
    "Entrenamos un modelo simple y medimos importancia de features por día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importance_by_day(\n",
    "    features_by_day: Dict[int, np.ndarray],  # {day_relative: features}\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str]\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Entrena LightGBM y calcula importancia promedio de features por día.\n",
    "    \n",
    "    Args:\n",
    "        features_by_day: {-3: X_minus3, -2: X_minus2, ..., 0: X_0, ..., +3: X_plus3}\n",
    "        y: Target variable\n",
    "        feature_names: Nombres de features por día\n",
    "    \n",
    "    Returns:\n",
    "        {day: importance_score} para cada día\n",
    "    \"\"\"\n",
    "    # Concatenar todas las features con prefijo de día\n",
    "    X_combined = []\n",
    "    feature_names_combined = []\n",
    "    day_to_feature_indices = {}\n",
    "    \n",
    "    current_idx = 0\n",
    "    for day, X_day in sorted(features_by_day.items()):\n",
    "        X_combined.append(X_day)\n",
    "        \n",
    "        # Track indices for this day\n",
    "        n_features_day = X_day.shape[1]\n",
    "        day_to_feature_indices[day] = list(range(current_idx, current_idx + n_features_day))\n",
    "        current_idx += n_features_day\n",
    "        \n",
    "        # Add feature names with day prefix\n",
    "        for fname in feature_names:\n",
    "            feature_names_combined.append(f\"t{day:+d}_{fname}\")\n",
    "    \n",
    "    X_combined = np.hstack(X_combined)\n",
    "    \n",
    "    # Train LightGBM\n",
    "    train_data = lgb.Dataset(X_combined, label=y, feature_name=feature_names_combined)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100,\n",
    "        valid_sets=[train_data],\n",
    "        callbacks=[lgb.log_evaluation(period=0)]\n",
    "    )\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = model.feature_importance(importance_type='gain')\n",
    "    \n",
    "    # Aggregate importance by day\n",
    "    importance_by_day = {}\n",
    "    for day, indices in day_to_feature_indices.items():\n",
    "        day_importance = importance[indices].sum()\n",
    "        importance_by_day[day] = day_importance\n",
    "    \n",
    "    # Normalize\n",
    "    total_importance = sum(importance_by_day.values())\n",
    "    if total_importance > 0:\n",
    "        importance_by_day = {k: v/total_importance for k, v in importance_by_day.items()}\n",
    "    \n",
    "    return importance_by_day\n",
    "\n",
    "\n",
    "print(\"✓ Función de feature importance definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algoritmo de Determinación de Ventana Óptima\n",
    "\n",
    "### Algoritmo: Threshold-Based Window Selection\n",
    "\n",
    "```\n",
    "Para cada evento E_k:\n",
    "    1. Calcular I(X_t; y) para t ∈ [-7, +7]\n",
    "    2. Normalizar: I_norm(t) = I(t) / max(I)\n",
    "    3. Definir threshold θ (ej. 0.1 = 10% del máximo)\n",
    "    4. t_start = min{t : I_norm(t) > θ}\n",
    "    5. t_end = max{t : I_norm(t) > θ}\n",
    "    6. Verificar continuidad (no gaps > 2 días)\n",
    "    7. Retornar [t_start, t_end]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_optimal_window(\n",
    "    information_by_day: Dict[int, float],\n",
    "    threshold: float = 0.1,\n",
    "    max_gap: int = 2\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Determina ventana óptima [t_start, t_end] basado en información mutua.\n",
    "    \n",
    "    Args:\n",
    "        information_by_day: {day: information_score}\n",
    "        threshold: Umbral mínimo de información (relativo al máximo)\n",
    "        max_gap: Máximo gap permitido en días sin información\n",
    "    \n",
    "    Returns:\n",
    "        (t_start, t_end) ventana óptima\n",
    "    \"\"\"\n",
    "    if not information_by_day:\n",
    "        return (0, 0)\n",
    "    \n",
    "    # Normalizar información\n",
    "    max_info = max(information_by_day.values())\n",
    "    if max_info == 0:\n",
    "        return (0, 0)\n",
    "    \n",
    "    info_norm = {k: v/max_info for k, v in information_by_day.items()}\n",
    "    \n",
    "    # Encontrar días que superan threshold\n",
    "    significant_days = sorted([day for day, info in info_norm.items() if info >= threshold])\n",
    "    \n",
    "    if not significant_days:\n",
    "        # Fallback: usar día con máxima información\n",
    "        best_day = max(information_by_day.items(), key=lambda x: x[1])[0]\n",
    "        return (best_day, best_day)\n",
    "    \n",
    "    # Verificar continuidad (no gaps grandes)\n",
    "    # Si hay gap > max_gap, dividir en segmentos\n",
    "    segments = []\n",
    "    current_segment = [significant_days[0]]\n",
    "    \n",
    "    for i in range(1, len(significant_days)):\n",
    "        if significant_days[i] - significant_days[i-1] <= max_gap + 1:\n",
    "            current_segment.append(significant_days[i])\n",
    "        else:\n",
    "            segments.append(current_segment)\n",
    "            current_segment = [significant_days[i]]\n",
    "    segments.append(current_segment)\n",
    "    \n",
    "    # Elegir segmento con mayor información total\n",
    "    best_segment = max(segments, key=lambda seg: sum(information_by_day[d] for d in seg))\n",
    "    \n",
    "    t_start = min(best_segment)\n",
    "    t_end = max(best_segment)\n",
    "    \n",
    "    return (t_start, t_end)\n",
    "\n",
    "\n",
    "def visualize_information_by_day(\n",
    "    information_by_day: Dict[int, float],\n",
    "    optimal_window: Tuple[int, int],\n",
    "    event_name: str,\n",
    "    method: str = 'MI'\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualiza información por día y ventana óptima.\n",
    "    \"\"\"\n",
    "    days = sorted(information_by_day.keys())\n",
    "    info = [information_by_day[d] for d in days]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot información\n",
    "    ax.bar(days, info, alpha=0.6, label=f'{method} Score')\n",
    "    \n",
    "    # Marcar día del evento\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Día Evento (t=0)')\n",
    "    \n",
    "    # Marcar ventana óptima\n",
    "    t_start, t_end = optimal_window\n",
    "    ax.axvspan(t_start, t_end, alpha=0.2, color='green', label=f'Ventana Óptima [{t_start}, {t_end}]')\n",
    "    \n",
    "    # Threshold line\n",
    "    threshold_value = max(info) * 0.1\n",
    "    ax.axhline(y=threshold_value, color='orange', linestyle=':', label='Threshold (10% max)')\n",
    "    \n",
    "    ax.set_xlabel('Días Relativos al Evento', fontsize=12)\n",
    "    ax.set_ylabel(f'{method} Score', fontsize=12)\n",
    "    ax.set_title(f'{event_name}: Información por Día Relativo\\nVentana Óptima: [{t_start}, {t_end}]', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"✓ Algoritmo de ventana óptima definido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis Costo-Beneficio\n",
    "\n",
    "### 6.1 Trade-off: Información vs Costo\n",
    "\n",
    "Cada día adicional tiene costo:\n",
    "- Descarga de datos\n",
    "- Procesamiento computacional  \n",
    "- Almacenamiento\n",
    "\n",
    "**Función objetivo con costo**:\n",
    "\n",
    "$$\n",
    "\\max_{[t_{start}, t_{end}]} \\left[ \\sum_{t=t_{start}}^{t_{end}} I(X_t; y) - \\lambda \\cdot (t_{end} - t_{start} + 1) \\right]\n",
    "$$\n",
    "\n",
    "Donde $\\lambda$ es el costo por día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_benefit_analysis(\n",
    "    information_by_day: Dict[int, float],\n",
    "    cost_per_day: float = 0.01,  # Costo relativo por día\n",
    "    max_window: int = 7\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analiza trade-off entre información ganada y costo de ventana.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con análisis para cada ventana posible\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    days = sorted(information_by_day.keys())\n",
    "    \n",
    "    # Probar todas las ventanas posibles\n",
    "    for t_start in range(-max_window, max_window + 1):\n",
    "        for t_end in range(t_start, max_window + 1):\n",
    "            # Calcular información total en ventana\n",
    "            info_total = sum(\n",
    "                information_by_day.get(t, 0) \n",
    "                for t in range(t_start, t_end + 1)\n",
    "            )\n",
    "            \n",
    "            # Calcular costo\n",
    "            window_size = t_end - t_start + 1\n",
    "            cost = cost_per_day * window_size\n",
    "            \n",
    "            # Net benefit\n",
    "            net_benefit = info_total - cost\n",
    "            \n",
    "            # Information per day\n",
    "            info_per_day = info_total / window_size if window_size > 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                't_start': t_start,\n",
    "                't_end': t_end,\n",
    "                'window_size': window_size,\n",
    "                'total_information': info_total,\n",
    "                'cost': cost,\n",
    "                'net_benefit': net_benefit,\n",
    "                'info_per_day': info_per_day\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Encontrar ventana óptima por net benefit\n",
    "    best_idx = df['net_benefit'].idxmax()\n",
    "    df['is_optimal'] = False\n",
    "    df.loc[best_idx, 'is_optimal'] = True\n",
    "    \n",
    "    return df.sort_values('net_benefit', ascending=False)\n",
    "\n",
    "\n",
    "def plot_cost_benefit(\n",
    "    df_cost_benefit: pd.DataFrame,\n",
    "    event_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualiza análisis costo-beneficio.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Net Benefit vs Window Size\n",
    "    ax = axes[0, 0]\n",
    "    scatter = ax.scatter(\n",
    "        df_cost_benefit['window_size'],\n",
    "        df_cost_benefit['net_benefit'],\n",
    "        c=df_cost_benefit['total_information'],\n",
    "        cmap='viridis',\n",
    "        alpha=0.6,\n",
    "        s=50\n",
    "    )\n",
    "    # Marcar óptimo\n",
    "    optimal = df_cost_benefit[df_cost_benefit['is_optimal']].iloc[0]\n",
    "    ax.scatter(\n",
    "        optimal['window_size'],\n",
    "        optimal['net_benefit'],\n",
    "        color='red',\n",
    "        s=200,\n",
    "        marker='*',\n",
    "        label='Óptimo',\n",
    "        edgecolors='black',\n",
    "        linewidths=2\n",
    "    )\n",
    "    ax.set_xlabel('Window Size (días)')\n",
    "    ax.set_ylabel('Net Benefit')\n",
    "    ax.set_title('Net Benefit vs Window Size')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax, label='Total Information')\n",
    "    \n",
    "    # 2. Information per Day\n",
    "    ax = axes[0, 1]\n",
    "    ax.scatter(\n",
    "        df_cost_benefit['window_size'],\n",
    "        df_cost_benefit['info_per_day'],\n",
    "        alpha=0.6\n",
    "    )\n",
    "    ax.scatter(\n",
    "        optimal['window_size'],\n",
    "        optimal['info_per_day'],\n",
    "        color='red',\n",
    "        s=200,\n",
    "        marker='*',\n",
    "        edgecolors='black',\n",
    "        linewidths=2\n",
    "    )\n",
    "    ax.set_xlabel('Window Size (días)')\n",
    "    ax.set_ylabel('Information per Day')\n",
    "    ax.set_title('Eficiencia: Info por Día')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Heatmap: t_start vs t_end (Net Benefit)\n",
    "    ax = axes[1, 0]\n",
    "    pivot = df_cost_benefit.pivot(index='t_start', columns='t_end', values='net_benefit')\n",
    "    sns.heatmap(pivot, ax=ax, cmap='RdYlGn', center=0, annot=False, cbar_kws={'label': 'Net Benefit'})\n",
    "    ax.set_title('Net Benefit: t_start vs t_end')\n",
    "    \n",
    "    # 4. Top 10 ventanas\n",
    "    ax = axes[1, 1]\n",
    "    top10 = df_cost_benefit.head(10)\n",
    "    y_pos = np.arange(len(top10))\n",
    "    labels = [f\"[{row['t_start']}, {row['t_end']}]\" for _, row in top10.iterrows()]\n",
    "    colors = ['red' if row['is_optimal'] else 'steelblue' for _, row in top10.iterrows()]\n",
    "    \n",
    "    ax.barh(y_pos, top10['net_benefit'], color=colors, alpha=0.7)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel('Net Benefit')\n",
    "    ax.set_title('Top 10 Ventanas por Net Benefit')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.suptitle(f'{event_name}: Análisis Costo-Beneficio de Ventanas', fontsize=16, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"✓ Funciones de análisis costo-beneficio definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline Completo: Ejemplo Simulado\n",
    "\n",
    "Vamos a simular el análisis para un evento E1 con datos sintéticos (antes de tener DIB bars reales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular datos sintéticos para demostración\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simular información por día (patrón realista)\n",
    "# Expectativa: Información aumenta cerca del evento (t=0)\n",
    "def simulate_information_pattern(event_type='spike'):\n",
    "    days = range(-7, 8)\n",
    "    \n",
    "    if event_type == 'spike':\n",
    "        # Evento súbito: máxima info en t=0, decae rápido\n",
    "        info = {d: np.exp(-0.5 * d**2) + np.random.normal(0, 0.05) for d in days}\n",
    "    elif event_type == 'gradual':\n",
    "        # Evento gradual: info crece antes, persiste después\n",
    "        info = {d: (1 / (1 + np.exp(-d))) * np.exp(-0.1 * d**2) + np.random.normal(0, 0.05) for d in days}\n",
    "    elif event_type == 'anticipation':\n",
    "        # Evento con anticipación: info máxima antes del evento\n",
    "        info = {d: np.exp(-0.3 * (d + 2)**2) + np.random.normal(0, 0.05) for d in days}\n",
    "    else:\n",
    "        # Flat: sin patrón claro\n",
    "        info = {d: 0.1 + np.random.normal(0, 0.05) for d in days}\n",
    "    \n",
    "    # Normalizar y asegurar no negativos\n",
    "    max_info = max(info.values())\n",
    "    info = {k: max(0, v/max_info) for k, v in info.items()}\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "# Simular 3 tipos de eventos\n",
    "event_patterns = {\n",
    "    'E1_VolExplosion': 'spike',\n",
    "    'E4_Parabolic': 'gradual',\n",
    "    'E7_FirstRedDay': 'anticipation'\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for event_name, pattern_type in event_patterns.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVENTO: {event_name} (patrón: {pattern_type})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. Simular información por día\n",
    "    info_by_day = simulate_information_pattern(pattern_type)\n",
    "    \n",
    "    # 2. Determinar ventana óptima (threshold-based)\n",
    "    optimal_window_threshold = determine_optimal_window(\n",
    "        info_by_day,\n",
    "        threshold=0.1,\n",
    "        max_gap=2\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nVentana óptima (threshold 10%): [{optimal_window_threshold[0]}, {optimal_window_threshold[1]}]\")\n",
    "    \n",
    "    # 3. Análisis costo-beneficio\n",
    "    df_cb = cost_benefit_analysis(\n",
    "        info_by_day,\n",
    "        cost_per_day=0.05,  # 5% cost relative to max info\n",
    "        max_window=7\n",
    "    )\n",
    "    \n",
    "    optimal_cb = df_cb[df_cb['is_optimal']].iloc[0]\n",
    "    optimal_window_cb = (int(optimal_cb['t_start']), int(optimal_cb['t_end']))\n",
    "    \n",
    "    print(f\"Ventana óptima (cost-benefit): [{optimal_window_cb[0]}, {optimal_window_cb[1]}]\")\n",
    "    print(f\"  - Window size: {optimal_cb['window_size']} días\")\n",
    "    print(f\"  - Total information: {optimal_cb['total_information']:.3f}\")\n",
    "    print(f\"  - Net benefit: {optimal_cb['net_benefit']:.3f}\")\n",
    "    print(f\"  - Info per day: {optimal_cb['info_per_day']:.3f}\")\n",
    "    \n",
    "    # 4. Visualizar\n",
    "    fig1 = visualize_information_by_day(\n",
    "        info_by_day,\n",
    "        optimal_window_threshold,\n",
    "        event_name,\n",
    "        method='MI'\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    fig2 = plot_cost_benefit(df_cb, event_name)\n",
    "    plt.show()\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_summary.append({\n",
    "        'event': event_name,\n",
    "        'pattern': pattern_type,\n",
    "        't_start_threshold': optimal_window_threshold[0],\n",
    "        't_end_threshold': optimal_window_threshold[1],\n",
    "        't_start_cb': optimal_window_cb[0],\n",
    "        't_end_cb': optimal_window_cb[1],\n",
    "        'window_size_cb': optimal_cb['window_size'],\n",
    "        'total_info': optimal_cb['total_information'],\n",
    "        'net_benefit': optimal_cb['net_benefit']\n",
    "    })\n",
    "\n",
    "# Resumen final\n",
    "df_summary = pd.DataFrame(results_summary)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN: VENTANAS OPTIMAS POR EVENTO (SIMULADO)\")\n",
    "print(\"=\"*80)\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparación con Ventanas Cualitativas (F.3)\n",
    "\n",
    "Comparamos las ventanas empíricas vs las definidas cualitativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventanas cualitativas de F.3\n",
    "EVENT_WINDOWS_QUALITATIVE = {\n",
    "    'E0_AlwaysTrue': 1,\n",
    "    'E1_VolExplosion': 1,\n",
    "    'E2_GapUp': 2,\n",
    "    'E3_PriceSpikeIntraday': 1,\n",
    "    'E4_Parabolic': 3,\n",
    "    'E5_BreakoutATH': 2,\n",
    "    'E6_MultipleGreenDays': 2,\n",
    "    'E7_FirstRedDay': 2,\n",
    "    'E8_GapDownViolent': 2,\n",
    "    'E9_CrashIntraday': 1,\n",
    "    'E10_FirstGreenBounce': 1,\n",
    "    'E11_VolumeBounce': 2\n",
    "}\n",
    "\n",
    "def compare_windows(\n",
    "    empirical_windows: Dict[str, Tuple[int, int]],\n",
    "    qualitative_windows: Dict[str, int]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compara ventanas empíricas vs cualitativas.\n",
    "    \n",
    "    Args:\n",
    "        empirical_windows: {event: (t_start, t_end)}\n",
    "        qualitative_windows: {event: ±N} (simétrico)\n",
    "    \"\"\"\n",
    "    comparisons = []\n",
    "    \n",
    "    for event in empirical_windows.keys():\n",
    "        t_start_emp, t_end_emp = empirical_windows[event]\n",
    "        window_size_emp = t_end_emp - t_start_emp + 1\n",
    "        \n",
    "        if event in qualitative_windows:\n",
    "            window_qual = qualitative_windows[event]\n",
    "            window_size_qual = 2 * window_qual + 1  # ±N -> total 2N+1 días\n",
    "            \n",
    "            # Comparar\n",
    "            diff = window_size_emp - window_size_qual\n",
    "            match = 'Match' if diff == 0 else ('Más pequeño' if diff < 0 else 'Más grande')\n",
    "            \n",
    "            comparisons.append({\n",
    "                'Evento': event,\n",
    "                'Empírico [t_start, t_end]': f\"[{t_start_emp}, {t_end_emp}]\",\n",
    "                'Empírico Size': window_size_emp,\n",
    "                'Cualitativo ±N': f\"±{window_qual}\",\n",
    "                'Cualitativo Size': window_size_qual,\n",
    "                'Diferencia': diff,\n",
    "                'Status': match\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(comparisons)\n",
    "\n",
    "\n",
    "# Crear ventanas empíricas desde resultados simulados\n",
    "empirical_windows = {\n",
    "    row['event']: (row['t_start_cb'], row['t_end_cb'])\n",
    "    for _, row in df_summary.iterrows()\n",
    "}\n",
    "\n",
    "df_comparison = compare_windows(empirical_windows, EVENT_WINDOWS_QUALITATIVE)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACION: EMPIRICO vs CUALITATIVO\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Visualizar comparación\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(df_comparison))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_comparison['Empírico Size'], width, label='Empírico', alpha=0.8)\n",
    "ax.bar(x + width/2, df_comparison['Cualitativo Size'], width, label='Cualitativo (F.3)', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Evento')\n",
    "ax.set_ylabel('Window Size (días)')\n",
    "ax.set_title('Comparación: Ventanas Empíricas vs Cualitativas')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_comparison['Evento'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones y Recomendaciones\n",
    "\n",
    "### 9.1 Hallazgos Clave\n",
    "\n",
    "1. **Ventanas asimétricas**: Los eventos pueden requerir más días **antes** o **después** del evento (no siempre simétrico ±N)\n",
    "\n",
    "2. **Trade-off información-costo**: Ventanas más grandes no siempre son mejores (rendimientos decrecientes)\n",
    "\n",
    "3. **Variabilidad por evento**: Cada evento E1-E11 tiene patrón temporal diferente\n",
    "\n",
    "### 9.2 Próximos Pasos con Datos Reales\n",
    "\n",
    "Una vez tengamos DIB bars de Pilot50:\n",
    "\n",
    "1. **Ejecutar este notebook con datos reales**\n",
    "2. **Validar para cada evento E1-E11**\n",
    "3. **Actualizar EVENT_WINDOWS en F.3** con ventanas empíricas\n",
    "4. **Documentar en F.6** los resultados de validación\n",
    "\n",
    "### 9.3 Ventanas Recomendadas (Provisionales)\n",
    "\n",
    "Basado en simulación y razonamiento:\n",
    "\n",
    "```python\n",
    "EVENT_WINDOWS_EMPIRICAL = {\n",
    "    'E1_VolExplosion': (0, 1),      # Evento súbito, poca anticipación\n",
    "    'E4_Parabolic': (-2, 2),        # Proceso gradual, necesita contexto\n",
    "    'E7_FirstRedDay': (-2, 1),      # Anticipación importante\n",
    "    # ... etc\n",
    "}\n",
    "```\n",
    "\n",
    "**PENDIENTE**: Validar con datos reales del Pilot50."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
