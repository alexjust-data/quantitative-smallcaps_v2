# Notebooks Modulares: Validaci√≥n H√≠brida Ventanas √ìptimas

**Fecha creaci√≥n**: 2025-10-30
**Pipeline**: Information Theory + Model Performance + Paper-Grade Analysis
**Objetivo**: Determinar ventanas √≥ptimas [t_start, t_end] para eventos E1-E11

---

## üìÅ ESTRUCTURA MODULAR (3 Notebooks)

### ‚úÖ VENTAJAS de esta arquitectura:

1. **Checkpoints autom√°ticos** ‚Üí Cada notebook guarda `.pkl` con resultados
2. **Ejecuci√≥n independiente** ‚Üí Puedes correr Fase 2 ma√±ana sin reejecutar Fase 1
3. **Debugging r√°pido** ‚Üí Falla Fase 2? Solo rearrancas ese notebook
4. **Iteraci√≥n r√°pida** ‚Üí Cambiar par√°metros Fase 3 sin reejecutar 1-2
5. **Sin p√©rdida de progreso** ‚Üí Si falla a mitad, tienes resultados parciales guardados

---

## üìì NOTEBOOK 1: Information Theory (Fase 1)

**Archivo**: `phase1_information_theory.ipynb`
**Tiempo**: 10-20 min (sample_size=200) | 40-60 min (completo)
**Objetivo**: Calcular Mutual Information por d√≠a relativo

### Inputs:
- `processed/dib_bars/pilot50_validation/` (96,897 DIB bars)
- `processed/universe/pilot50_validation/daily/` (5,579 watchlists)

### Proceso:
1. Carga watchlist con eventos
2. Para cada evento:
   - Calcula features agregados diarios (ret_day, range_day, vol_day, dollar_day, imb_day, n_bars)
   - Calcula MI entre features y retorno futuro 3d
   - Identifica d√≠as con se√±al > 10% threshold
3. Visualiza MI por d√≠a relativo
4. Guarda `phase1_results.pkl`

### Outputs:
- **phase1_results.pkl** ‚Üí info_results, wl_expanded, events_available, suggested_windows
- **information_by_day_phase1.png** ‚Üí Gr√°ficos MI por evento

### Configuraci√≥n:
```python
# Cell-4: Ajustar subset para prueba r√°pida
EVENTS_TO_TEST = events_available[:3]  # 3 eventos para prueba
MAX_PRE_DAYS = 3
MAX_POST_DAYS = 3
SAMPLE_SIZE = 200  # Reducir a 100 para velocidad, 500 para precisi√≥n
```

### Requisitos:
- ‚úÖ DIB bars con columnas b√°sicas (o, h, l, c, v, n, dollar, imbalance_score)
- ‚úÖ NO requiere features enriquecidos
- ‚úÖ NO requiere labels ni weights

---

## üìì NOTEBOOK 2: Model Performance (Fase 2)

**Archivo**: `phase2_model_performance.ipynb`
**Tiempo**: 20-40 min (2 eventos √ó 6 ventanas) | 2-4 horas (completo)
**Objetivo**: Medir edge econ√≥mico real con LightGBM

### Inputs:
- **phase1_results.pkl** (de Notebook 1)
- `processed/dataset_pilot50/` (D.4 features enriquecidos) ‚ö†Ô∏è CR√çTICO

### Proceso:
1. Carga resultados Fase 1
2. Para cada (evento, ventana):
   - Construye dataset con features enriquecidos
   - Entrena LightGBM classifier (profit vs loss)
   - Calcula AUC + Edge econ√≥mico
   - Calcula score = (Edge √ó AUC) / log(n_bars)
3. Selecciona mejor ventana por evento
4. Compara vs ventanas cualitativas F.3
5. Guarda `phase2_results.pkl` + CSVs

### Outputs:
- **phase2_results.pkl** ‚Üí res_df, best_per_event, comparison_f3
- **optimal_windows_empirical_phase2.csv** ‚Üí Ventanas √≥ptimas
- **window_optimization_phase2_full.csv** ‚Üí Grid completo
- **comparison_empirical_vs_f3.csv** ‚Üí Comparaci√≥n cualitativo vs emp√≠rico
- **window_optimization_phase2.png** ‚Üí Visualizaciones

### Configuraci√≥n:
```python
# Cell-2: Ajustar subset
EVENTS_SUBSET = list(info_results.keys())[:2]  # 2 eventos para prueba
WINDOWS_SUBSET = CANDIDATE_WINDOWS[:6]  # 6 ventanas
MAX_SAMPLES = 300  # Sample por evento (500-1000 para m√°s precisi√≥n)

# Features requeridos (generados por D.4):
FEATURE_COLS = [
    'ret_1', 'range_norm', 'vol_f', 'dollar_f', 'imb_f',
    'ret_1_ema10', 'ret_1_ema30', 'range_norm_ema20',
    'vol_f_ema20', 'dollar_f_ema20', 'imb_f_ema20',
    'vol_z20', 'dollar_z20', 'n'
]
```

### Requisitos:
- ‚úÖ `phase1_results.pkl` debe existir
- ‚úÖ D.4 build_ml_daser.py debe haber completado
- ‚úÖ `processed/dataset_pilot50/` con features enriquecidos
- ‚ö†Ô∏è **Si D.4 no complet√≥**, este notebook FALLAR√Å en Cell-0

---

## üìì NOTEBOOK 3: Paper-Grade Analysis (Fase 3)

**Archivo**: `phase3_paper_grade_analysis.ipynb`
**Tiempo**: 5-10 min
**Objetivo**: An√°lisis estad√≠stico riguroso para validaci√≥n cient√≠fica

### Inputs:
- **phase1_results.pkl** (de Notebook 1)
- **phase2_results.pkl** (de Notebook 2)

### Proceso:
1. Carga resultados Fase 1 + 2
2. Calcula Normalized Mutual Information (NMI)
3. Genera heatmap 2D (evento √ó d√≠a relativo)
4. Calcula correlaci√≥n Spearman (MI vs Edge)
5. Aplica Hybrid Score (Œ±¬∑MI + (1-Œ±)¬∑Edge)
6. Genera reporte estad√≠stico completo
7. Exporta diccionario Python para producci√≥n

### Outputs:
- **statistical_report_paper_grade.csv** ‚Üí M√©tricas completas
- **concordance_analysis_full.csv** ‚Üí Concordancia MI/Edge
- **heatmap_event_x_time.png** ‚Üí Heatmap 2D
- **concordance_analysis.png** ‚Üí Visualizaciones Spearman
- **EVENT_WINDOWS_EMPIRICAL** ‚Üí Diccionario Python

### Configuraci√≥n:
```python
# Cell-6: Ajustar par√°metros hybrid score
ALPHA = 0.6  # Peso para MI (60% MI, 40% Edge)
QUANTILE_THRESHOLD = 0.8  # Top 20% ventanas
```

### Requisitos:
- ‚úÖ `phase1_results.pkl` debe existir
- ‚úÖ `phase2_results.pkl` debe existir
- ‚úÖ **Este notebook es r√°pido** ‚Üí Puede ejecutarse m√∫ltiples veces con diferentes Œ±

---

## üîÑ FLUJO DE EJECUCI√ìN RECOMENDADO

### Opci√≥n A: Ejecuci√≥n Secuencial (Todo de una vez)

```bash
# D√≠a 1 completo:
jupyter execute phase1_information_theory.ipynb      # 10-20 min
jupyter execute phase2_model_performance.ipynb        # 20-40 min
jupyter execute phase3_paper_grade_analysis.ipynb    # 5-10 min
# Total: ~35-70 min
```

### Opci√≥n B: Ejecuci√≥n Incremental (D√≠as separados)

```bash
# D√≠a 1: Information Theory
jupyter execute phase1_information_theory.ipynb
# ‚Üí Genera phase1_results.pkl

# D√≠a 2: Model Performance (requiere D.4 completo)
jupyter execute phase2_model_performance.ipynb
# ‚Üí Genera phase2_results.pkl

# D√≠a 3: An√°lisis estad√≠stico (puedes ejecutar N veces)
jupyter execute phase3_paper_grade_analysis.ipynb
```

### Opci√≥n C: Debugging (Rearrancar desde fallo)

```bash
# Si Fase 2 fall√≥ a mitad:
# 1. No pierdes resultados Fase 1 (phase1_results.pkl existe)
# 2. Arreglas el problema (ej: D.4 no completo)
# 3. Rearrancas solo Fase 2:
jupyter execute phase2_model_performance.ipynb

# Si quieres probar diferentes Œ± en hybrid score:
# 1. Editas Cell-6 de Notebook 3
# 2. Rearrancas solo Fase 3 (5 min):
jupyter execute phase3_paper_grade_analysis.ipynb
```

---

## ‚öôÔ∏è DEPENDENCIAS PRE-EJECUCI√ìN

### Para Notebook 1:
- ‚úÖ `processed/dib_bars/pilot50_validation/` (96,897 archivos)
- ‚úÖ `processed/universe/pilot50_validation/daily/` (5,579 watchlists)

### Para Notebook 2:
- ‚úÖ `phase1_results.pkl` (generado por Notebook 1)
- ‚úÖ `processed/dataset_pilot50/` (‚ö†Ô∏è REQUIERE D.4 completo)

**Verificar D.4**:
```bash
# Check si dataset existe y tiene features:
python -c "import polars as pl; df = pl.read_parquet('processed/dataset_pilot50/AENT/date=2023-03-20/dataset.parquet'); print(df.columns)"

# Debe incluir: ret_1, range_norm, vol_f, dollar_f, imb_f, ret_1_ema10, etc.
```

**Si D.4 no complet√≥**, ejecuta:
```bash
python scripts/fase_D_creando_DIB_VIB/build_ml_daser.py \
  --bars-root processed/dib_bars/pilot50_validation \
  --labels-root processed/labels_pilot50 \
  --weights-root processed/weights_pilot50 \
  --outdir processed/dataset_pilot50 \
  --bar-file dollar_imbalance.parquet \
  --parallel 12 \
  --resume \
  --split none
# Tiempo: ~15-30 min
```

### Para Notebook 3:
- ‚úÖ `phase1_results.pkl` (generado por Notebook 1)
- ‚úÖ `phase2_results.pkl` (generado por Notebook 2)

---

## üìä OUTPUTS FINALES ESPERADOS

Despu√©s de ejecutar los 3 notebooks:

### Archivos pickle (checkpoints):
- `phase1_results.pkl` ‚Üí info_results, wl_expanded, suggested_windows
- `phase2_results.pkl` ‚Üí res_df, best_per_event, comparison_f3

### CSVs (an√°lisis):
- `optimal_windows_empirical_phase2.csv` ‚Üí Ventanas √≥ptimas por evento
- `window_optimization_phase2_full.csv` ‚Üí Grid search completo
- `comparison_empirical_vs_f3.csv` ‚Üí Comparaci√≥n cualitativo vs emp√≠rico
- `statistical_report_paper_grade.csv` ‚Üí M√©tricas estad√≠sticas
- `concordance_analysis_full.csv` ‚Üí Concordancia MI/Edge

### Im√°genes (visualizaciones):
- `information_by_day_phase1.png` ‚Üí MI por d√≠a relativo (Fase 1)
- `window_optimization_phase2.png` ‚Üí Grid search visualizations (Fase 2)
- `heatmap_event_x_time.png` ‚Üí Heatmap 2D evento√ótiempo (Fase 3)
- `concordance_analysis.png` ‚Üí Spearman + divergencias (Fase 3)

### Diccionario Python (producci√≥n):
```python
EVENT_WINDOWS_EMPIRICAL = {
    'E1_VolExplosion': (1, 1),  # AUC=0.xxx, Edge=0.xxxx
    'E2_GapUp': (2, 1),  # AUC=0.xxx, Edge=0.xxxx
    # ...
}
```

---

## üêõ TROUBLESHOOTING

### Error: "Dataset directory not found"
**Problema**: D.4 no complet√≥
**Soluci√≥n**: Ejecuta `build_ml_daser.py` (ver secci√≥n Dependencias)

### Error: "phase1_results.pkl not found"
**Problema**: No ejecutaste Notebook 1
**Soluci√≥n**: Ejecuta `phase1_information_theory.ipynb` primero

### Error: "KeyError: 'ret_1_ema10'"
**Problema**: Dataset no tiene features enriquecidos
**Soluci√≥n**: Verifica que D.4 complet√≥ correctamente, re-ejecuta si necesario

### Notebook tarda demasiado (> 1 hora)
**Problema**: Usando dataset completo en prueba
**Soluci√≥n**: Reduce subset en configuraci√≥n:
```python
# Notebook 1, Cell-4:
EVENTS_TO_TEST = events_available[:3]
SAMPLE_SIZE = 100

# Notebook 2, Cell-2:
EVENTS_SUBSET = list(info_results.keys())[:2]
WINDOWS_SUBSET = CANDIDATE_WINDOWS[:6]
MAX_SAMPLES = 300
```

### Quiero probar diferentes par√°metros
**Opci√≥n**: Solo rearranca el notebook espec√≠fico
- Cambiar MI threshold ‚Üí Notebook 1
- Cambiar ventanas candidatas ‚Üí Notebook 2
- Cambiar Œ± hybrid score ‚Üí Notebook 3

---

## üìà M√âTRICAS DE √âXITO

### Fase 1 (Information Theory):
- ‚úÖ MI > 0.1 (normalizado) en al menos 1 d√≠a por evento
- ‚úÖ Ventanas sugeridas detectadas autom√°ticamente
- ‚úÖ Gr√°ficos muestran picos claros alrededor de t=0

### Fase 2 (Model Performance):
- ‚úÖ AUC > 0.55 (mejor que random)
- ‚úÖ Edge > 0 (expected return positivo)
- ‚úÖ Score compuesto identifica ventanas √≥ptimas
- ‚úÖ Comparaci√≥n vs F.3 muestra concordancia o mejora

### Fase 3 (Paper-Grade):
- ‚úÖ Spearman œÅ > 0.4 (concordancia moderada-alta MI vs Edge)
- ‚úÖ P-value < 0.05 (significancia estad√≠stica)
- ‚úÖ Hybrid score selecciona top 20% ventanas
- ‚úÖ Diccionario Python generado para producci√≥n

---

## üéØ PR√ìXIMOS PASOS POST-EJECUCI√ìN

1. **An√°lisis resultados**:
   - Revisar `optimal_windows_empirical_phase2.csv`
   - Comparar vs ventanas cualitativas F.3
   - Validar que AUC > 0.55 y Edge > 0

2. **Actualizar c√≥digo producci√≥n**:
   - Copiar `EVENT_WINDOWS_EMPIRICAL` a `event_detectors.py`
   - Reemplazar ventanas qualitativas con emp√≠ricas

3. **Generar watchlist E0-E11**:
   - Ejecutar `compute_events_watchlist.py` con nuevas ventanas
   - Output: `processed/universe/e0_e11/daily/`

4. **Descargar universo completo**:
   - Lanzar download con ventanas optimizadas
   - ~300K ticker-days adicionales

---

**√öltima actualizaci√≥n**: 2025-10-30
**Autor**: Claude Code + User Collaboration
**Versi√≥n**: 1.0 - Notebooks Modulares con Checkpoints
