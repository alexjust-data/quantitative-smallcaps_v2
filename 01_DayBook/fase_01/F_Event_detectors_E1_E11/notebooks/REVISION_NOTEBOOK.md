# Revisi√≥n Completa: validacion_ventanas_hibrida.ipynb

**Fecha**: 2025-10-30
**Revisor**: Claude Code
**Notebook**: 46 celdas totales

---

## RESUMEN EJECUTIVO

**Estado general**: ‚úÖ Notebook bien dise√±ado, requiere 3 modificaciones menores

**Celdas sin problemas**: 43/46 (93.5%)
**Celdas con problemas**: 3/46 (6.5%)

**Severidad**:
- üî¥ CR√çTICO: 2 celdas (Cell-2, Cell-18)
- üü° MENOR: 1 celda (Cell-22)

---

## PROBLEMAS IDENTIFICADOS

### üî¥ PROBLEMA 1: Cell-2 - Falta DATASET_ROOT path

**Ubicaci√≥n**: Cell-2 (Setup)

**Problema**:
```python
# Paths actuales
TRADES_DIR = Path('../../../../raw/polygon/trades_pilot50_validation')
BARS_ROOT = Path('../../../../processed/dib_bars/pilot50_validation')
LABELS_ROOT = Path('../../../../processed/labels_pilot50')
WEIGHTS_ROOT = Path('../../../../processed/weights_pilot50')
WATCHLIST = Path('../../../../processed/universe/pilot50_validation/daily')

# FALTA:
DATASET_ROOT = Path('../../../../processed/dataset_pilot50')  # <-- A√ëADIR ESTA L√çNEA
```

**Impacto**: Cell-18 y Cell-22 no pueden leer el dataset enriquecido

**Soluci√≥n**: A√±adir l√≠nea `DATASET_ROOT`

---

### üî¥ PROBLEMA 2: Cell-18 - load_day_dataset_full() debe leer desde dataset_pilot50

**Ubicaci√≥n**: Cell-18 (Funciones de carga)

**Problema actual**:
```python
def load_day_dataset_full(ticker: str, day: datetime.date) -> pl.DataFrame:
    # Lee bars, labels, weights POR SEPARADO
    bars_file = BARS_ROOT / ticker / f"date={day.isoformat()}" / "dollar_imbalance.parquet"
    labels_file = LABELS_ROOT / ticker / f"date={day.isoformat()}" / "labels.parquet"
    weights_file = WEIGHTS_ROOT / ticker / f"date={day.isoformat()}" / "weights.parquet"

    # ... concatena horizontalmente (bars NO tienen features enriquecidos)
```

**Por qu√© falla**:
- DIB bars raw solo tienen: `['t_open', 't_close', 'o', 'h', 'l', 'c', 'v', 'n', 'dollar', 'imbalance_score']`
- Cell-22 requiere: `['ret_1', 'range_norm', 'vol_f', 'dollar_f', 'imb_f', 'ret_1_ema10', ...]`
- **Estas features solo existen despu√©s de ejecutar D.4 build_ml_daser.py**

**Soluci√≥n correcta**:
```python
def load_day_dataset_full(ticker: str, day: datetime.date) -> pl.DataFrame:
    """
    Carga dataset enriquecido (features + labels + weights).

    REQUIERE: D.4 build_ml_daser.py ejecutado previamente.
    """
    dataset_file = DATASET_ROOT / ticker / f"date={day.isoformat()}" / "dataset.parquet"

    if not dataset_file.exists():
        return None

    df = pl.read_parquet(dataset_file)

    # A√±adir columnas de contexto si no existen
    if 'ticker' not in df.columns:
        df = df.with_columns([
            pl.lit(ticker).alias('ticker'),
            pl.lit(day).alias('session_day')
        ])

    return df
```

**Impacto**: CR√çTICO - Fase 2 (Model Performance) no puede ejecutarse sin esto

---

### üü° PROBLEMA 3: Cell-22 - Comentario desactualizado sobre features

**Ubicaci√≥n**: Cell-22 (Grid search)

**Problema menor**:
```python
# Comentario actual:
# Features a usar (deben existir en DIB bars)  <-- INCORRECTO
FEATURE_COLS = [
    'ret_1', 'range_norm', 'vol_f', 'dollar_f', 'imb_f',
    'ret_1_ema10', 'ret_1_ema30', 'range_norm_ema20',
    'vol_f_ema20', 'dollar_f_ema20', 'imb_f_ema20',
    'vol_z20', 'dollar_z20', 'n'
]
```

**Correcci√≥n**:
```python
# Features a usar (generados por D.4 build_ml_daser.py)
FEATURE_COLS = [
    'ret_1', 'range_norm', 'vol_f', 'dollar_f', 'imb_f',
    'ret_1_ema10', 'ret_1_ema30', 'range_norm_ema20',
    'vol_f_ema20', 'dollar_f_ema20', 'imb_f_ema20',
    'vol_z20', 'dollar_z20', 'n'
]
```

**Impacto**: MENOR - Solo documentaci√≥n, no afecta ejecuci√≥n

---

## CELDAS VALIDADAS ‚úÖ

### Fase 1: Information Theory (Cells 0-15)

**Cell-0, 1**: Markdown intro ‚úÖ
**Cell-2**: Paths correctos (excepto DATASET_ROOT faltante)
**Cell-3**: Markdown ‚úÖ
**Cell-4**: Watchlist loading - c√≥digo correcto ‚úÖ
- Usa `rglob('watchlist.parquet')` ‚úÖ
- Parsea `date=YYYY-MM-DD` correctamente ‚úÖ
- Convierte a `pl.Date` ‚úÖ
- Explode de `events` column ‚úÖ

**Cell-5**: Markdown ‚úÖ
**Cell-6**: Window candidates - configuraci√≥n OK ‚úÖ

**Cell-7-8**: Markdown ‚úÖ
**Cell-9**: MI functions - l√≥gica correcta ‚úÖ
- `load_dib_bars_day()`: Usa columnas b√°sicas ‚úÖ
- `aggregate_day_features()`: Solo usa `['o', 'h', 'l', 'c', 'v', 'n', 'dollar', 'imbalance_score']` ‚úÖ
- `calculate_mutual_information_discretized()`: Sklearn API correcto ‚úÖ

**Cell-10**: Markdown ‚úÖ
**Cell-11**: `analyze_information_by_relative_day()` - l√≥gica s√≥lida ‚úÖ
- Filtra eventos correctamente ‚úÖ
- Calcula retorno futuro `ret_3d` desde close del d√≠a evento ‚úÖ
- Maneja casos edge (None, height==0) ‚úÖ

**Cell-12**: Markdown ‚úÖ
**Cell-13**: Execute MI - configuraci√≥n razonable ‚úÖ
- `EVENTS_TO_TEST[:3]`: Subset para prueba r√°pida ‚úÖ
- `sample_size=200`: Balance velocidad/representatividad ‚úÖ

**Cell-14**: Markdown ‚úÖ
**Cell-15**: Visualizaci√≥n MI - matplotlib c√≥digo correcto ‚úÖ

### Fase 2: Model Performance (Cells 16-32)

**Cell-16-17**: Markdown ‚úÖ
**Cell-18**: üî¥ CR√çTICO - Ver arriba
**Cell-19**: Markdown ‚úÖ
**Cell-20**: `evaluate_window_performance()` - l√≥gica econ√≥mica correcta ‚úÖ
- AUC con sample_weight ‚úÖ
- Edge = expected return weighted ‚úÖ
- Manejo de excepciones ‚úÖ

**Cell-21**: Markdown ‚úÖ
**Cell-22**: Grid search - l√≥gica OK (comentario menor a corregir)
**Cell-23**: Markdown ‚úÖ
**Cell-24**: Best window selection - polars query correcto ‚úÖ
**Cell-25**: Markdown ‚úÖ
**Cell-26**: Visualizations - matplotlib OK ‚úÖ
**Cell-27**: Markdown ‚úÖ
**Cell-28**: Comparison F.3 - l√≥gica comparaci√≥n correcta ‚úÖ
**Cell-29**: Markdown ‚úÖ
**Cell-30**: Conclusions - print statements OK ‚úÖ
**Cell-31**: Markdown ‚úÖ
**Cell-32**: Export - write_csv correcto ‚úÖ

### Fase 3: Paper-Grade Refinements (Cells 33-46)

**Cell-33-34**: Markdown ‚úÖ
**Cell-35**: NMI calculation - sklearn API correcto ‚úÖ
**Cell-36**: Markdown ‚úÖ
**Cell-37**: Heatmap 2D - seaborn c√≥digo correcto ‚úÖ
**Cell-38**: Markdown ‚úÖ
**Cell-39**: Spearman - scipy.stats API correcto ‚úÖ
**Cell-40**: Concordance viz - matplotlib OK ‚úÖ
**Cell-41**: Markdown ‚úÖ
**Cell-42**: Hybrid score - numpy l√≥gica correcta ‚úÖ
**Cell-43**: Hybrid viz - matplotlib OK ‚úÖ
**Cell-44**: Markdown ‚úÖ
**Cell-45**: Statistical report - pandas DataFrame correcto ‚úÖ
**Cell-46**: Markdown conclusiones ‚úÖ

---

## DEPENDENCIAS EXTERNAS

### ‚úÖ Datos requeridos DISPONIBLES:

1. **Watchlist**: `processed/universe/pilot50_validation/daily/` (5,579 files) ‚úÖ
2. **DIB Bars**: `processed/dib_bars/pilot50_validation/` (96,897 files) ‚úÖ
3. **Labels**: `processed/labels_pilot50/` (96,897 files) ‚úÖ
4. **Weights**: `processed/weights_pilot50/` (96,897 files) ‚úÖ

### üîÑ Datos requeridos EN CONSTRUCCI√ìN:

5. **Dataset enriquecido**: `processed/dataset_pilot50/` - D.4 corriendo (bash ID: 60a1fb)

**Tiempo estimado D.4**: 15-30 min (basado en D.2=126min, D.3=113min)

---

## PLAN DE CORRECCI√ìN

### Paso 1: Esperar D.4 completar (~10-25 min restantes)

Verificar logs y confirmar:
```bash
# Verificar progreso
python -c "import polars as pl; print('Schema check'); df = pl.read_parquet('processed/dataset_pilot50/AENT/date=2023-03-20/dataset.parquet'); print(df.columns)"
```

Debe incluir todas las FEATURE_COLS.

### Paso 2: Aplicar correcciones al notebook

**Opci√≥n A**: Editar notebook program√°ticamente (NotebookEdit tool)
**Opci√≥n B**: Crear notebook corregido nuevo
**Opci√≥n C**: Manual en IDE

Recomendaci√≥n: **Opci√≥n A** (NotebookEdit) - 3 cambios quir√∫rgicos

### Paso 3: Ejecutar notebook completo

Estimar tiempo por fase:
- **Fase 1 (Cell 0-15)**: ~10-20 min (MI calculations, sample_size=200)
- **Fase 2 (Cell 16-32)**: ~20-40 min (LightGBM training, 2 eventos √ó 6 ventanas)
- **Fase 3 (Cell 33-46)**: ~5-10 min (an√°lisis estad√≠stico)

**Total estimado**: 35-70 min para subset peque√±o (3 eventos, 6 ventanas)

Para an√°lisis completo (11 eventos, 12 ventanas):
- **Fase 1**: ~40-60 min
- **Fase 2**: ~2-4 horas (132 combinaciones)
- **Fase 3**: ~10-15 min

---

## VALIDACI√ìN POST-EJECUCI√ìN

### Archivos output esperados:

1. `information_by_day_phase1.png` - Gr√°fico MI por d√≠a relativo
2. `window_optimization_phase2.png` - Grid search resultados
3. `heatmap_event_x_time.png` - Heatmap 2D evento√ótiempo
4. `concordance_analysis.png` - Spearman MI vs Edge
5. `hybrid_score_analysis.png` - Selecci√≥n h√≠brida
6. `optimal_windows_empirical.csv` - Ventanas √≥ptimas por evento
7. `window_optimization_full_results.csv` - Grid completo
8. `statistical_report_paper_grade.csv` - M√©tricas finales
9. `concordance_analysis_full.csv` - Concordancia detallada

### M√©tricas clave a verificar:

- **Spearman œÅ > 0.4**: Concordancia MI vs Edge moderada-alta
- **P-value < 0.05**: Significancia estad√≠stica
- **AUC > 0.55**: Predictibilidad mejor que random
- **Edge > 0**: Expected return positivo en ventanas seleccionadas

---

## CONCLUSI√ìN

**Notebook quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- Dise√±o paper-grade excelente
- C√≥digo limpio y bien documentado
- Solo requiere ajuste de paths post-pipeline

**Cambios requeridos**: M√çNIMOS (3 l√≠neas de c√≥digo)

**Listo para producci√≥n**: S√ç (tras aplicar correcciones)

---

**√öltima actualizaci√≥n**: 2025-10-30 08:50
**Pr√≥ximo paso**: Aplicar correcciones cuando D.4 complete
