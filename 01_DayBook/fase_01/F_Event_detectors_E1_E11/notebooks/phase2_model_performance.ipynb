{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2: Model Performance - Validación Híbrida Ventanas\n",
    "\n",
    "**Objetivo**: Medir edge económico real de ventanas candidatas usando LightGBM.\n",
    "\n",
    "**Método**: Model Performance (económicamente relevante)\n",
    "- LightGBM classifier para predecir profit/loss\n",
    "- Métricas: AUC + Edge (expected weighted return)\n",
    "- Score compuesto: (Edge × AUC) / log(n_bars)\n",
    "\n",
    "**Inputs**: \n",
    "- `phase1_results.pkl` (info_results)\n",
    "- `processed/dataset_pilot50/` (D.4 features enriquecidos)\n",
    "\n",
    "**Output**: `phase2_results.pkl` con ventanas óptimas\n",
    "\n",
    "**Tiempo estimado**: 20-40 min (2 eventos × 6 ventanas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from typing import Dict, List\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Paths (CORREGIDO: usa dataset_pilot50 con features enriquecidos)\n",
    "DATASET_ROOT = Path('../../../../processed/dataset_pilot50')\n",
    "OUTPUT_DIR = Path('.')\n",
    "\n",
    "print(f\"Dataset dir exists: {DATASET_ROOT.exists()}\")\n",
    "if not DATASET_ROOT.exists():\n",
    "    print(\"\\n⚠️  WARNING: Dataset directory not found!\")\n",
    "    print(\"   Ejecuta D.4 build_ml_daser.py primero:\")\n",
    "    print(\"   python scripts/fase_D_creando_DIB_VIB/build_ml_daser.py \\\\\")\n",
    "    print(\"     --bars-root processed/dib_bars/pilot50_validation \\\\\")\n",
    "    print(\"     --labels-root processed/labels_pilot50 \\\\\")\n",
    "    print(\"     --weights-root processed/weights_pilot50 \\\\\")\n",
    "    print(\"     --outdir processed/dataset_pilot50 \\\\\")\n",
    "    print(\"     --bar-file dollar_imbalance.parquet --parallel 12 --resume --split none\")\n",
    "    raise FileNotFoundError(\"Dataset enriquecido no encontrado\")\n",
    "\n",
    "print(f\"Output dir: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar Resultados Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados de Information Theory\n",
    "phase1_file = OUTPUT_DIR / 'phase1_results.pkl'\n",
    "\n",
    "if not phase1_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontró {phase1_file}. \"\n",
    "        \"Ejecuta phase1_information_theory.ipynb primero.\"\n",
    "    )\n",
    "\n",
    "with open(phase1_file, 'rb') as f:\n",
    "    phase1 = pickle.load(f)\n",
    "\n",
    "# Extraer datos\n",
    "info_results = phase1['info_results']\n",
    "wl_expanded = phase1['wl_expanded']\n",
    "events_available = phase1['events_available']\n",
    "suggested_windows = phase1['suggested_windows']\n",
    "\n",
    "print(\"✓ Resultados Fase 1 cargados correctamente\")\n",
    "print(f\"  - Eventos con MI: {len(info_results)}\")\n",
    "print(f\"  - Event occurrences: {wl_expanded.height:,}\")\n",
    "print(f\"  - Ventanas sugeridas: {len([w for w in suggested_windows.values() if w])}\")\n",
    "print(f\"\\nEventos disponibles: {list(info_results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuración Ventanas Candidatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventanas candidatas (pre_days, post_days)\n",
    "CANDIDATE_WINDOWS = [\n",
    "    (0, 0),  # Solo día evento\n",
    "    (1, 0),  # 1 día antes\n",
    "    (0, 1),  # 1 día después\n",
    "    (1, 1),  # ±1 simétrico\n",
    "    (2, 1),  # Más anticipación\n",
    "    (1, 2),  # Más confirmación\n",
    "    (2, 2),  # ±2 simétrico\n",
    "    (3, 1),  # Build-up largo, poco post\n",
    "    (1, 3),  # Poco pre, unwind largo\n",
    "    (3, 2),  # Asimétrico amplio\n",
    "    (2, 3),  # Inverso\n",
    "    (3, 3),  # ±3 completo (baseline)\n",
    "]\n",
    "\n",
    "# CONFIGURACIÓN: Subset para prueba rápida\n",
    "EVENTS_SUBSET = list(info_results.keys())[:2]  # Cambiar a list(info_results.keys()) para todos\n",
    "WINDOWS_SUBSET = CANDIDATE_WINDOWS[:6]  # Cambiar a CANDIDATE_WINDOWS para todas\n",
    "\n",
    "print(f\"Ventanas candidatas: {len(WINDOWS_SUBSET)}\")\n",
    "print(f\"Eventos a testear: {len(EVENTS_SUBSET)}\")\n",
    "print(f\"Total combinaciones: {len(WINDOWS_SUBSET) * len(EVENTS_SUBSET)}\")\n",
    "print(f\"\\nEventos: {EVENTS_SUBSET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funciones de Carga Dataset (CORREGIDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_day_dataset_full(ticker: str, day: datetime.date) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga dataset enriquecido (features + labels + weights).\n",
    "    \n",
    "    REQUIERE: D.4 build_ml_daser.py ejecutado previamente.\n",
    "    Lee desde processed/dataset_pilot50/ con features enriquecidos.\n",
    "    \"\"\"\n",
    "    dataset_file = DATASET_ROOT / ticker / f\"date={day.isoformat()}\" / \"dataset.parquet\"\n",
    "    \n",
    "    if not dataset_file.exists():\n",
    "        return None\n",
    "    \n",
    "    df = pl.read_parquet(dataset_file)\n",
    "    \n",
    "    # Añadir columnas de contexto si no existen\n",
    "    if 'ticker' not in df.columns:\n",
    "        df = df.with_columns([\n",
    "            pl.lit(ticker).alias('ticker'),\n",
    "            pl.lit(day).alias('session_day')\n",
    "        ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def build_dataset_for_window(\n",
    "    event_code: str,\n",
    "    pre_days: int,\n",
    "    post_days: int,\n",
    "    max_samples: int = 1000\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Construye dataset completo para una ventana específica.\n",
    "    \"\"\"\n",
    "    subset = wl_expanded.filter(pl.col('event_code') == event_code)\n",
    "    \n",
    "    if subset.height > max_samples:\n",
    "        subset = subset.sample(max_samples, seed=42)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for row in subset.iter_rows(named=True):\n",
    "        ticker = row['ticker']\n",
    "        t0 = row['date']\n",
    "        \n",
    "        for offset in range(-pre_days, post_days + 1):\n",
    "            d = t0 + timedelta(days=offset)\n",
    "            df_day = load_day_dataset_full(ticker, d)\n",
    "            \n",
    "            if df_day is not None:\n",
    "                df_day = df_day.with_columns([\n",
    "                    pl.lit(event_code).alias('event_code'),\n",
    "                    pl.lit(offset).alias('rel_day'),\n",
    "                    pl.lit(t0).alias('event_day')\n",
    "                ])\n",
    "                rows.append(df_day)\n",
    "    \n",
    "    if not rows:\n",
    "        return None\n",
    "    \n",
    "    return pl.concat(rows)\n",
    "\n",
    "\n",
    "print(\"✓ Funciones de dataset completo definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Función de Evaluación Económica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_window_performance(\n",
    "    df: pl.DataFrame,\n",
    "    feature_cols: List[str]\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evalúa performance económico de una ventana.\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            'auc': float,\n",
    "            'edge': float (expected weighted return),\n",
    "            'n_bars': int,\n",
    "            'n_days': int\n",
    "        }\n",
    "    \"\"\"\n",
    "    if df is None or df.height < 100:\n",
    "        return {\n",
    "            'auc': None,\n",
    "            'edge': None,\n",
    "            'n_bars': 0,\n",
    "            'n_days': 0\n",
    "        }\n",
    "    \n",
    "    # Filtrar filas válidas\n",
    "    required_cols = feature_cols + ['label', 'weight', 'ret_at_outcome']\n",
    "    base = df.drop_nulls(required_cols)\n",
    "    \n",
    "    if base.height < 100:\n",
    "        return {'auc': None, 'edge': None, 'n_bars': base.height, 'n_days': 0}\n",
    "    \n",
    "    # Preparar datos\n",
    "    X = np.column_stack([base[col].to_numpy() for col in feature_cols])\n",
    "    y = (base['label'].to_numpy() > 0).astype(int)  # Binary: profit vs no-profit\n",
    "    w = base['weight'].to_numpy()\n",
    "    returns = base['ret_at_outcome'].to_numpy()\n",
    "    \n",
    "    # Entrenar modelo simple\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(X, y, sample_weight=w)\n",
    "    except Exception as e:\n",
    "        print(f\"Error training model: {e}\")\n",
    "        return {'auc': None, 'edge': None, 'n_bars': base.height, 'n_days': 0}\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Métrica 1: AUC\n",
    "    try:\n",
    "        auc = roc_auc_score(y, y_pred, sample_weight=w)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    \n",
    "    # Métrica 2: Edge económico\n",
    "    # Expected return si tradeamos cuando pred > 0.5\n",
    "    trade_mask = (y_pred >= 0.5)\n",
    "    \n",
    "    if trade_mask.sum() == 0:\n",
    "        edge = 0.0\n",
    "    else:\n",
    "        edge = (\n",
    "            (returns[trade_mask] * w[trade_mask]).sum() /\n",
    "            w[trade_mask].sum()\n",
    "        )\n",
    "    \n",
    "    # Métricas de coste\n",
    "    n_days = base['session_day'].n_unique()\n",
    "    \n",
    "    return {\n",
    "        'auc': float(auc),\n",
    "        'edge': float(edge),\n",
    "        'n_bars': int(base.height),\n",
    "        'n_days': int(n_days)\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✓ Función de evaluación económica definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grid Search: Ventanas × Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features a usar (generados por D.4 build_ml_daser.py)\n",
    "FEATURE_COLS = [\n",
    "    'ret_1', 'range_norm', 'vol_f', 'dollar_f', 'imb_f',\n",
    "    'ret_1_ema10', 'ret_1_ema30', 'range_norm_ema20',\n",
    "    'vol_f_ema20', 'dollar_f_ema20', 'imb_f_ema20',\n",
    "    'vol_z20', 'dollar_z20', 'n'\n",
    "]\n",
    "\n",
    "MAX_SAMPLES = 300  # Sample por evento (aumentar a 500-1000 para más precisión)\n",
    "\n",
    "phase2_results = []\n",
    "\n",
    "print(f\"\\nEjecutando grid search: {len(EVENTS_SUBSET)} eventos × {len(WINDOWS_SUBSET)} ventanas\")\n",
    "print(f\"Total combinaciones: {len(EVENTS_SUBSET) * len(WINDOWS_SUBSET)}\")\n",
    "print(f\"Max samples por evento: {MAX_SAMPLES}\\n\")\n",
    "\n",
    "for event in EVENTS_SUBSET:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evento: {event}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for pre, post in WINDOWS_SUBSET:\n",
    "        print(f\"\\n  Ventana [{pre}, {post}]...\", end=' ')\n",
    "        \n",
    "        # Construir dataset\n",
    "        ds = build_dataset_for_window(event, pre, post, max_samples=MAX_SAMPLES)\n",
    "        \n",
    "        # Evaluar\n",
    "        if ds is None:\n",
    "            metrics = {'auc': None, 'edge': None, 'n_bars': 0, 'n_days': 0}\n",
    "        else:\n",
    "            metrics = evaluate_window_performance(ds, FEATURE_COLS)\n",
    "        \n",
    "        print(f\"AUC={metrics['auc']:.3f if metrics['auc'] else 'N/A'}, \"\n",
    "              f\"Edge={metrics['edge']:.4f if metrics['edge'] else 'N/A'}, \"\n",
    "              f\"n_bars={metrics['n_bars']:,}\")\n",
    "        \n",
    "        phase2_results.append({\n",
    "            'event': event,\n",
    "            'pre_days': pre,\n",
    "            'post_days': post,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "res_df = pl.DataFrame(phase2_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Grid search completado\")\n",
    "print(f\"Total resultados: {len(phase2_results)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Selección Ventana Óptima por Evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular score compuesto: (edge × AUC) / log(n_bars)\n",
    "res_df = res_df.with_columns([\n",
    "    (\n",
    "        (pl.col('edge').fill_null(0.0).abs() * pl.col('auc').fill_null(0.5)) /\n",
    "        (pl.col('n_bars').cast(pl.Float64).log().fill_null(1.0))\n",
    "    ).alias('score')\n",
    "])\n",
    "\n",
    "# Mejor ventana por evento\n",
    "best_per_event = (\n",
    "    res_df\n",
    "    .sort(['event', 'score'], descending=[False, True])\n",
    "    .group_by('event')\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VENTANAS ÓPTIMAS POR EVENTO (Fase 2: Model Performance)\")\n",
    "print(\"=\"*80)\n",
    "print(best_per_event.select([\n",
    "    'event', 'pre_days', 'post_days', 'auc', 'edge', 'n_bars', 'score'\n",
    "]).to_pandas().to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_per_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualización Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Convertir a pandas para plotting\n",
    "res_pd = res_df.to_pandas()\n",
    "res_pd['window_size'] = res_pd['pre_days'] + res_pd['post_days'] + 1\n",
    "\n",
    "# 1. AUC vs Window Size\n",
    "ax = axes[0, 0]\n",
    "for event in EVENTS_SUBSET:\n",
    "    subset = res_pd[res_pd['event'] == event]\n",
    "    ax.scatter(subset['window_size'], subset['auc'], label=event, alpha=0.7, s=100)\n",
    "\n",
    "ax.set_xlabel('Window Size (días)')\n",
    "ax.set_ylabel('AUC')\n",
    "ax.set_title('AUC vs Tamaño de Ventana')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Edge vs Window Size\n",
    "ax = axes[0, 1]\n",
    "for event in EVENTS_SUBSET:\n",
    "    subset = res_pd[res_pd['event'] == event]\n",
    "    ax.scatter(subset['window_size'], subset['edge'], label=event, alpha=0.7, s=100)\n",
    "\n",
    "ax.set_xlabel('Window Size (días)')\n",
    "ax.set_ylabel('Edge (Expected Return)')\n",
    "ax.set_title('Edge Económico vs Tamaño de Ventana')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 3. Score vs Window Size\n",
    "ax = axes[1, 0]\n",
    "for event in EVENTS_SUBSET:\n",
    "    subset = res_pd[res_pd['event'] == event]\n",
    "    ax.scatter(subset['window_size'], subset['score'], label=event, alpha=0.7, s=100)\n",
    "    # Marcar mejor\n",
    "    best = subset.loc[subset['score'].idxmax()]\n",
    "    ax.scatter(best['window_size'], best['score'], \n",
    "               color='red', s=300, marker='*', edgecolors='black', linewidths=2)\n",
    "\n",
    "ax.set_xlabel('Window Size (días)')\n",
    "ax.set_ylabel('Score Compuesto')\n",
    "ax.set_title('Score (Edge×AUC/log(n)) vs Tamaño')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Ventanas óptimas (pre vs post)\n",
    "ax = axes[1, 1]\n",
    "best_pd = best_per_event.to_pandas()\n",
    "scatter = ax.scatter(best_pd['pre_days'], best_pd['post_days'], s=200, alpha=0.7, \n",
    "                     c=best_pd['score'], cmap='viridis', edgecolors='black', linewidths=1)\n",
    "plt.colorbar(scatter, ax=ax, label='Score')\n",
    "\n",
    "for _, row in best_pd.iterrows():\n",
    "    ax.annotate(row['event'], (row['pre_days'], row['post_days']), \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.plot([0, 3], [0, 3], 'k--', alpha=0.3, label='Simétrico')\n",
    "ax.set_xlabel('Pre Days (anticipación)')\n",
    "ax.set_ylabel('Post Days (confirmación)')\n",
    "ax.set_title('Ventanas Óptimas: Pre vs Post')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('window_optimization_phase2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Gráfico guardado: window_optimization_phase2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparación con Ventanas Cualitativas (F.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventanas cualitativas de F.3\n",
    "EVENT_WINDOWS_QUALITATIVE = {\n",
    "    'E1_VolExplosion': 1,\n",
    "    'E2_GapUp': 2,\n",
    "    'E3_PriceSpikeIntraday': 1,\n",
    "    'E4_Parabolic': 3,\n",
    "    'E5_BreakoutATH': 2,\n",
    "    'E6_MultipleGreenDays': 2,\n",
    "    'E7_FirstRedDay': 2,\n",
    "    'E8_GapDownViolent': 2,\n",
    "    'E9_CrashIntraday': 1,\n",
    "    'E10_FirstGreenBounce': 1,\n",
    "    'E11_VolumeBounce': 2\n",
    "}\n",
    "\n",
    "comparison = []\n",
    "for _, row in best_per_event.to_pandas().iterrows():\n",
    "    event = row['event']\n",
    "    pre_emp = row['pre_days']\n",
    "    post_emp = row['post_days']\n",
    "    size_emp = pre_emp + post_emp + 1\n",
    "    \n",
    "    if event in EVENT_WINDOWS_QUALITATIVE:\n",
    "        qual_window = EVENT_WINDOWS_QUALITATIVE[event]\n",
    "        size_qual = 2 * qual_window + 1\n",
    "        diff = size_emp - size_qual\n",
    "        \n",
    "        comparison.append({\n",
    "            'Evento': event,\n",
    "            'Empírico [pre,post]': f\"[{pre_emp},{post_emp}]\",\n",
    "            'Empírico Size': size_emp,\n",
    "            'Cualitativo ±N': f\"±{qual_window}\",\n",
    "            'Cualitativo Size': size_qual,\n",
    "            'Diferencia': diff,\n",
    "            'Status': 'Match' if diff == 0 else ('Más pequeño' if diff < 0 else 'Más grande')\n",
    "        })\n",
    "\n",
    "comp_df = pd.DataFrame(comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACIÓN: VENTANAS EMPÍRICAS vs CUALITATIVAS (F.3)\")\n",
    "print(\"=\"*80)\n",
    "if len(comp_df) > 0:\n",
    "    print(comp_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No hay eventos en común con F.3 en el subset actual\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar Resultados Fase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empaquetar resultados\n",
    "results_phase2 = {\n",
    "    'res_df': res_df,\n",
    "    'best_per_event': best_per_event,\n",
    "    'events_subset': EVENTS_SUBSET,\n",
    "    'windows_subset': WINDOWS_SUBSET,\n",
    "    'comparison_f3': comp_df if len(comp_df) > 0 else None,\n",
    "    'config': {\n",
    "        'max_samples': MAX_SAMPLES,\n",
    "        'feature_cols': FEATURE_COLS\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar a disco\n",
    "output_file = OUTPUT_DIR / 'phase2_results.pkl'\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(results_phase2, f)\n",
    "\n",
    "# Guardar CSVs también\n",
    "best_per_event.write_csv('optimal_windows_empirical_phase2.csv')\n",
    "res_df.write_csv('window_optimization_phase2_full.csv')\n",
    "if len(comp_df) > 0:\n",
    "    comp_df.to_csv('comparison_empirical_vs_f3.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ FASE 2 COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Resultados guardados en: {output_file.absolute()}\")\n",
    "print(f\"\\nContenido:\")\n",
    "print(f\"  - res_df: {len(res_df)} combinaciones evaluadas\")\n",
    "print(f\"  - best_per_event: {len(best_per_event)} ventanas óptimas\")\n",
    "print(f\"  - CSVs exportados:\")\n",
    "print(f\"    • optimal_windows_empirical_phase2.csv\")\n",
    "print(f\"    • window_optimization_phase2_full.csv\")\n",
    "if len(comp_df) > 0:\n",
    "    print(f\"    • comparison_empirical_vs_f3.csv\")\n",
    "print(f\"\\nPróximo paso: Ejecutar phase3_paper_grade_analysis.ipynb\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
