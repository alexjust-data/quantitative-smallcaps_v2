{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Intraday: Hora Exacta del Trigger E0 (OPTIMIZADO)\n",
    "\n",
    "**Objetivo**: Encontrar la hora exacta (HH:MM) en que se disparó el evento E0 para cada ticker+fecha\n",
    "\n",
    "**Optimizaciones aplicadas**:\n",
    "- `imap_unordered` + `chunksize=100` → Procesamiento en batches\n",
    "- `tqdm` progress bar → Seguimiento en tiempo real\n",
    "- `lazy()` en Polars → Optimización de queries\n",
    "- Solo carga columnas necesarias → Reduce I/O\n",
    "- 12 workers (reducido vs 16 para evitar saturación Windows)\n",
    "\n",
    "**Tiempo estimado**: 15-30 minutos para ~29K eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(r\"D:\\04_TRADING_SMALLCAPS\")\n",
    "WATCHLISTS = PROJECT_ROOT / \"processed\" / \"universe\" / \"info_rich\" / \"daily\"\n",
    "TRADES_DIR = PROJECT_ROOT / \"raw\" / \"polygon\" / \"trades\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"01_DayBook\" / \"fase_01\" / \"C_v2_ingesta_tiks_2004_2025\" / \"notebooks\"\n",
    "\n",
    "print(\"✅ Setup completo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar eventos E0\n",
    "print(\"Cargando eventos E0...\")\n",
    "df_all = pl.scan_parquet(WATCHLISTS / \"date=*\" / \"watchlist.parquet\").collect()\n",
    "print(f\"✅ Cargados {len(df_all):,} registros totales\")\n",
    "\n",
    "# Evaluar filtros E0\n",
    "df_all = df_all.with_columns([\n",
    "    (pl.col('rvol30') >= 2.0).fill_null(False).alias('f1_rvol'),\n",
    "    (pl.col('pctchg_d').abs() >= 0.15).fill_null(False).alias('f2_pctchg'),\n",
    "    (pl.col('dollar_vol_d') >= 5_000_000).fill_null(False).alias('f3_dvol'),\n",
    "    ((pl.col('close_d') >= 0.20) & (pl.col('close_d') <= 20.0)).fill_null(False).alias('f4_price')\n",
    "])\n",
    "\n",
    "df_all = df_all.with_columns([\n",
    "    (pl.col('f1_rvol').cast(pl.Int8) +\n",
    "     pl.col('f2_pctchg').cast(pl.Int8) +\n",
    "     pl.col('f3_dvol').cast(pl.Int8) +\n",
    "     pl.col('f4_price').cast(pl.Int8)).alias('num_filtros')\n",
    "])\n",
    "\n",
    "df_e0 = df_all.filter(pl.col('num_filtros') == 4)\n",
    "print(f\"✅ Eventos E0 (4 filtros): {len(df_e0):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función optimizada para detectar trigger\n",
    "def detectar_trigger_intraday(ticker, date, trades_dir):\n",
    "    \"\"\"Analiza trades tick-by-tick y encuentra la hora exacta del trigger E0.\"\"\"\n",
    "    import polars as pl\n",
    "    from pathlib import Path\n",
    "\n",
    "    date_str = date if isinstance(date, str) else str(date)\n",
    "    trades_file = Path(trades_dir) / ticker / f\"date={date_str}\" / \"trades.parquet\"\n",
    "\n",
    "    if not trades_file.exists():\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Cargar solo columnas necesarias\n",
    "        df_trades = pl.read_parquet(trades_file, columns=['t_raw', 't_unit', 'p', 's'])\n",
    "\n",
    "        if len(df_trades) == 0:\n",
    "            return None\n",
    "\n",
    "        # Convertir timestamps\n",
    "        time_unit = df_trades['t_unit'][0]\n",
    "\n",
    "        if time_unit == 'ns':\n",
    "            df_trades = df_trades.with_columns([\n",
    "                pl.col('t_raw').cast(pl.Datetime(time_unit='ns')).alias('timestamp')\n",
    "            ])\n",
    "        elif time_unit == 'us':\n",
    "            df_trades = df_trades.with_columns([\n",
    "                pl.col('t_raw').cast(pl.Datetime(time_unit='us')).alias('timestamp')\n",
    "            ])\n",
    "        else:\n",
    "            df_trades = df_trades.with_columns([\n",
    "                pl.col('t_raw').cast(pl.Datetime(time_unit='ms')).alias('timestamp')\n",
    "            ])\n",
    "\n",
    "        # Filtrar RTH (9:30-16:00 ET)\n",
    "        df_trades = df_trades.with_columns([\n",
    "            pl.col('timestamp').dt.hour().alias('hour'),\n",
    "            pl.col('timestamp').dt.minute().alias('minute')\n",
    "        ]).filter(\n",
    "            ((pl.col('hour') == 9) & (pl.col('minute') >= 30)) |\n",
    "            ((pl.col('hour') >= 10) & (pl.col('hour') < 16)) |\n",
    "            ((pl.col('hour') == 16) & (pl.col('minute') == 0))\n",
    "        )\n",
    "\n",
    "        if len(df_trades) == 0:\n",
    "            return None\n",
    "\n",
    "        # Construir barras 1-min con lazy evaluation\n",
    "        df_1min = (df_trades\n",
    "                   .lazy()\n",
    "                   .with_columns([\n",
    "                       pl.col('timestamp').dt.truncate('1m').alias('bar_time')\n",
    "                   ])\n",
    "                   .group_by('bar_time')\n",
    "                   .agg([\n",
    "                       pl.col('p').first().alias('open'),\n",
    "                       pl.col('p').max().alias('high'),\n",
    "                       pl.col('p').min().alias('low'),\n",
    "                       pl.col('p').last().alias('close'),\n",
    "                       pl.col('s').sum().alias('volume'),\n",
    "                       ((pl.col('p') * pl.col('s')).sum() / pl.col('s').sum()).alias('vwap')\n",
    "                   ])\n",
    "                   .sort('bar_time')\n",
    "                   .collect())\n",
    "\n",
    "        if len(df_1min) == 0:\n",
    "            return None\n",
    "\n",
    "        # Calcular features acumulativos\n",
    "        open_price = df_1min['open'][0]\n",
    "\n",
    "        df_1min = df_1min.with_columns([\n",
    "            ((pl.col('close') / pl.lit(open_price)) - 1.0).alias('pctchg_from_open'),\n",
    "            pl.col('volume').cum_sum().alias('vol_cumsum'),\n",
    "            (pl.col('volume') * pl.col('vwap')).cum_sum().alias('dvol_cumsum')\n",
    "        ])\n",
    "\n",
    "        # Buscar primera barra con F2+F3+F4\n",
    "        df_trigger = df_1min.filter(\n",
    "            (pl.col('pctchg_from_open').abs() >= 0.15) &\n",
    "            (pl.col('dvol_cumsum') >= 5_000_000) &\n",
    "            (pl.col('close') >= 0.20) & (pl.col('close') <= 20.0)\n",
    "        )\n",
    "\n",
    "        if len(df_trigger) == 0:\n",
    "            return None\n",
    "\n",
    "        trigger_bar = df_trigger[0]\n",
    "\n",
    "        return {\n",
    "            'ticker': ticker,\n",
    "            'date': date_str,\n",
    "            'trigger_time': trigger_bar['bar_time'][0],\n",
    "            'trigger_hour': trigger_bar['bar_time'][0].hour,\n",
    "            'trigger_minute': trigger_bar['bar_time'][0].minute,\n",
    "            'pctchg_trigger': trigger_bar['pctchg_from_open'][0],\n",
    "            'dvol_trigger': trigger_bar['dvol_cumsum'][0],\n",
    "            'close_trigger': trigger_bar['close'][0]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"✅ Función definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento paralelo OPTIMIZADO\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISIS INTRADAY: HORA EXACTA DEL TRIGGER E0\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "N_WORKERS = min(12, cpu_count())  # ✅ Reducido a 12 para Windows\n",
    "print(f\"\\n🚀 Procesamiento paralelo con {N_WORKERS} workers...\")\n",
    "print(f\"   Eventos a analizar: {len(df_e0):,}\")\n",
    "\n",
    "# Preparar lista de eventos\n",
    "eventos_list = [(row['ticker'], row['trading_day'], TRADES_DIR) for row in df_e0.iter_rows(named=True)]\n",
    "\n",
    "def process_evento(args):\n",
    "    return detectar_trigger_intraday(*args)\n",
    "\n",
    "# Procesar CON BARRA DE PROGRESO\n",
    "triggers = []\n",
    "with Pool(N_WORKERS) as pool:\n",
    "    results = list(tqdm(\n",
    "        pool.imap_unordered(process_evento, eventos_list, chunksize=50),  # ✅ chunksize reducido\n",
    "        total=len(eventos_list),\n",
    "        desc=\"Procesando eventos\",\n",
    "        unit=\"evento\"\n",
    "    ))\n",
    "\n",
    "    triggers = [r for r in results if r is not None]\n",
    "\n",
    "processed = len(results)\n",
    "found = len(triggers)\n",
    "\n",
    "print(f\"\\n✅ Análisis completado:\")\n",
    "print(f\"   Eventos analizados: {processed:,}\")\n",
    "print(f\"   Triggers encontrados: {found:,}\")\n",
    "print(f\"   % con trades disponibles: {found/processed*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis y visualización de resultados\n",
    "if len(triggers) > 0:\n",
    "    df_triggers = pl.DataFrame(triggers)\n",
    "\n",
    "    print(\"\\n📊 ESTADÍSTICAS DE TRIGGERS:\")\n",
    "    print(f\"   Hora promedio trigger: {df_triggers['trigger_hour'].mean():.1f}:{df_triggers['trigger_minute'].mean():.0f}\")\n",
    "    print(f\"   Hora más temprana: {df_triggers['trigger_hour'].min()}:{df_triggers['trigger_minute'].min():02d}\")\n",
    "    print(f\"   Hora más tardía: {df_triggers['trigger_hour'].max()}:{df_triggers['trigger_minute'].max():02d}\")\n",
    "\n",
    "    # Distribución por hora\n",
    "    by_hour_trigger = df_triggers.group_by('trigger_hour').agg(pl.count().alias('count')).sort('trigger_hour')\n",
    "\n",
    "    print(\"\\n📊 DISTRIBUCIÓN POR HORA DEL DÍA:\")\n",
    "    for row in by_hour_trigger.iter_rows(named=True):\n",
    "        hour = row['trigger_hour']\n",
    "        count = row['count']\n",
    "        pct = count / len(df_triggers) * 100\n",
    "        print(f\"   {hour:02d}:00 - {hour:02d}:59: {count:>6,} triggers ({pct:>5.1f}%)\")\n",
    "\n",
    "    # Gráfico\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    by_hour_pd = by_hour_trigger.to_pandas()\n",
    "\n",
    "    ax.bar(by_hour_pd['trigger_hour'], by_hour_pd['count'], color='orange', alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Hora del Día (ET)', fontsize=12)\n",
    "    ax.set_ylabel('Número de Triggers E0', fontsize=12)\n",
    "    ax.set_title(f'Distribución de Triggers E0 por Hora del Día ({len(df_triggers):,} eventos)',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(9, 17))\n",
    "    ax.set_xticklabels([f'{h:02d}:00' for h in range(9, 17)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    for i, (hour, count) in enumerate(zip(by_hour_pd['trigger_hour'], by_hour_pd['count'])):\n",
    "        ax.text(hour, count + max(by_hour_pd['count'])*0.01, f'{count:,}',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'e0_triggers_por_hora_COMPLETO.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n✅ Gráfico guardado: e0_triggers_por_hora_COMPLETO.png\")\n",
    "\n",
    "    # Exportar CSV para TradingView\n",
    "    df_export_triggers = df_triggers.select([\n",
    "        'ticker',\n",
    "        'date',\n",
    "        'trigger_time',\n",
    "        'trigger_hour',\n",
    "        'trigger_minute',\n",
    "        'pctchg_trigger',\n",
    "        'dvol_trigger',\n",
    "        'close_trigger'\n",
    "    ]).sort(['date', 'trigger_time'])\n",
    "\n",
    "    csv_triggers = OUTPUT_DIR / 'eventos_E0_CON_HORA_EXACTA_COMPLETO_TRADINGVIEW.csv'\n",
    "    df_export_triggers.write_csv(csv_triggers)\n",
    "\n",
    "    print(f\"\\n✅ CSV exportado: {csv_triggers.name}\")\n",
    "    print(f\"   Total triggers: {len(df_export_triggers):,}\")\n",
    "    print(f\"\\n📋 Sample (primeros 10):\")\n",
    "    print(df_export_triggers.head(10))\n",
    "\n",
    "    print(f\"\\n💡 USO EN TRADINGVIEW:\")\n",
    "    print(f\"   1. Abrir TradingView\")\n",
    "    print(f\"   2. Buscar ticker + fecha del CSV\")\n",
    "    print(f\"   3. Ir a la hora exacta (trigger_hour:trigger_minute)\")\n",
    "    print(f\"   4. Verificar patrón E0 en ese momento\")\n",
    "\n",
    "    best_hour = by_hour_pd.loc[by_hour_pd['count'].idxmax()]\n",
    "    print(f\"\\n🏆 MEJOR HORA: {best_hour['trigger_hour']:02d}:00 con {best_hour['count']:,} triggers ({best_hour['count']/len(df_triggers)*100:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️  No se encontraron triggers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-smallcap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
