# C.5 - Plan de Ejecuci√≥n E0: Descarga Ticks 2004-2025

**Fecha**: 2025-10-26  
**Versi√≥n**: 1.1.0 (actualizado post-error SCD-2)  
**Basado en**: Contrato_E0.md v2.0.0  
**Prerequisito**: C.4 - Descarga OHLCV Daily/Intraday completada (8,620 tickers raw intraday)  
**Ver tambi√©n**: C.7_ERROR_SCD2_Y_SOLUCION.md para contexto del error cr√≠tico y fix aplicado    



## 1. PIPELINE DE EJECUCI√ìN (5 PASOS)

### PASO 0: ~~Generaci√≥n Dimensi√≥n SCD-2 Market Cap~~ (DEPRECADO)

**‚ö†Ô∏è IMPORTANTE**: Este paso fue deprecado debido a error cr√≠tico detectado el 2025-10-26.

**Problema identificado**:
- La dimensi√≥n SCD-2 generada solo conten√≠a UN per√≠odo por ticker
- Rango temporal: `2025-10-19 ‚Üí 2099-12-31` (solo 7 d√≠as hist√≥ricos)
- Faltaban datos hist√≥ricos 2004-2025
- Caus√≥ que PASO 1 solo generara 2 d√≠as por ticker en lugar de 21 a√±os

**Impacto**:
```
Ejecuci√≥n CON market_cap (2025-10-25 23:40):
- 8,617 tickers procesados
- PERO solo 2 d√≠as por ticker (2025-10-20, 2025-10-21)
- Total days: 5,524 (deber√≠a ser ~5M = 8,617 √ó 600)
```

**Causa ra√≠z**:
El join temporal en `build_daily_cache.py`:
```python
.filter(
    (pl.col("effective_from") <= pl.col("trading_day")) &
    (pl.col("trading_day") < pl.col("effective_to"))
)
```
Filtr√≥ el 99.9% de datos hist√≥ricos porque SCD-2 solo cubr√≠a desde 2025-10-19.

**Soluci√≥n aplicada**:
- ‚úÖ Re-ejecutar PASO 1 **SIN** `--cap-filter-parquet`
- ‚úÖ `market_cap_d` ser√° NULL en daily_cache
- ‚úÖ PASO 3 (filtrado E0) modificado para NO usar filtro market_cap

**Pendiente futuro** (post-MVP E0):
- Construir SCD-2 hist√≥rico real (m√∫ltiples per√≠odos por ticker)
- Requiere fuente de datos con history (Polygon solo tiene snapshot actual)
- Proxy alternativo: `market_cap_d = close_d √ó shares_outstanding_d`

---

### PASO 1: Generaci√≥n Cach√© Diario 2004-2025

* **Objetivo**: Agregar OHLCV 1-min ‚Üí diario con features (rvol30, pctchg_d)
* **Tiempo real**: ~4.8 horas (8,620 tickers, 67.6% vac√≠os sin datos raw)
* **Script**: `build_daily_cache.py`

**Comando CORRECTO** (actualizado 2025-10-26 08:05):
```bash
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2004-01-01 --to 2025-10-21 \
  --parallel 8
  # SIN --cap-filter-parquet
  # market_cap_d quedar√° NULL temporalmente (corregir en PASO 0 v2)
```

**¬øQu√© hace?**:
1. Lee barras 1-min de `raw/polygon/ohlcv_intraday_1m/`
2. Agrega a diario por ticker-fecha: `close_d`, `vol_d`, `dollar_vol_d`, `vwap_d`, `session_rows`, `has_gaps`
3. Calcula features: `pctchg_d`, `return_d`, `rvol30` (rolling 30 sesiones, min_periods=1)
4. ~~Join temporal con SCD-2~~ **DEPRECADO**: `market_cap_d` = NULL

**Output esperado**:
```
processed/daily_cache/
‚îú‚îÄ‚îÄ ticker=BCRX/
‚îÇ   ‚îú‚îÄ‚îÄ daily.parquet               (schema: 12 columnas, ZSTD)
‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îú‚îÄ‚îÄ ticker=GERN/
‚îÇ   ‚îú‚îÄ‚îÄ daily.parquet
‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îú‚îÄ‚îÄ ... (8,617 tickers)
‚îú‚îÄ‚îÄ MANIFEST.json                   (metadata global)
‚îî‚îÄ‚îÄ _SUCCESS
```

**Schema output**:
```
ticker: Utf8
trading_day: Date
close_d: Float64
vol_d: Int64
dollar_vol_d: Float64
vwap_d: Float64
pctchg_d: Float64
return_d: Float64
rvol30: Float64
session_rows: Int64
has_gaps: Boolean
market_cap_d: Float64               ‚Üê NULL (SCD-2 deprecado)
```

**M√©tricas REALES** (ejecuci√≥n 2025-10-26 08:05):
- Tickers encontrados: 8,620
- Tickers con datos: ~2,795 (32.4%)
- Tickers vac√≠os (0 d√≠as): 5,825 (67.6%) - sin datos raw intraday
- Ticker-d√≠as reales: Pendiente completar ejecuci√≥n
- Tiempo: ~4-5 horas
- Tama√±o: ~15 MB (comprimido ZSTD)

**Validaci√≥n** (ejecutar ANTES de PASO 3):
```bash
python scripts/audit_paso1_complete.py
```

Verificar:
- TOP 20 tickers tienen >100 d√≠as (NO solo 2)
- market_cap_d es 100% NULL (esperado)
- rvol30, pctchg_d, dollar_vol_d calculados correctamente

**Criterio de √©xito**:
- ‚úÖ 8,617+ tickers procesados (success + no_data)
- ‚úÖ Tickers con datos tienen rango completo 2004-2025 (NO solo 2025-10-20/21)
- ‚úÖ rvol30 calculado correctamente
- ‚úÖ market_cap_d = NULL (aceptable, sin filtro cap en PASO 3)

---

> ...  
> **Resultados** : mira este link [PASO 1: Generaci√≥n Cach√© Diario 2004-2025](./C.5.0_resultados_paso_1.md)  
>  
> üìä **Archivo JSON Generado**
> El archivo `stats_daily_cache.json` contiene:
> * Estad√≠sticas detalladas de cada ticker
> * Distribuci√≥n de d√≠as E0
> * M√©tricas por columna (min, max, mean, median, std)
> * Conteo de NULLs
> ¬øQuieres ver el contenido del JSON de alg√∫n ticker espec√≠fico? Por ejemplo:  
> `python -c "import json; data=json.load(open('stats_daily_cache.json')); ticker=[t for t in data['tickers'] if t['ticker']=='BCRX'][0]; import pprint; pprint.pprint(ticker)`
> ...  


### PASO 2: Actualizar Configuraci√≥n Umbrales E0

**Objetivo**: Configurar umbrales E0 **SIN** filtro market_cap

**Tiempo**: 1 minuto

**Archivo**: `configs/universe_config.yaml`

**Contenido ACTUALIZADO** (2025-10-26):
```yaml
# E0/C_v2 (2004-2025) - Contrato v2.0.0 - market_cap removido
thresholds:
  rvol: 2.0                   # Volumen relativo m√≠nimo
  pctchg: 0.15                # |% change| m√≠nimo (15%)
  dvol: 5_000_000             # Dollar volume m√≠nimo ($5M)
  min_price: 0.2              # Precio m√≠nimo $0.20 (proxy small cap)
  max_price: 20.0             # Precio m√°ximo $20.00 (proxy small cap)
  # cap_max: REMOVIDO (market_cap_d es NULL)
```

**Justificaci√≥n**:
- Filtro de precio ($0.20-$20.00) ya elimina mayor√≠a de large caps
- Filtro de volumen ($5M) asegura liquidez
- Market cap era redundante con precio para small caps

---

### PASO 3: Generaci√≥n Universo Din√°mico E0 (2004-2025)

* **Objetivo**: Identificar d√≠as info-rich seg√∫n filtros E0 y generar watchlists diarias
* **Tiempo REAL**: ~11 minutos (2025-10-26 20:42-20:54)
* **Script**: `build_dynamic_universe_optimized.py`

**Comando**:
```bash
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2004-01-01 --to 2025-10-21 \
  --config configs/universe_config.yaml
```

**¬øQu√© hace?**:
1. Lee cach√© diario completo (8,617 tickers, 14,763,368 ticker-d√≠as)
2. Aplica filtros E0:

   ```python
   r_rvol = (rvol30 >= 2.0)
   r_chg = (|pctchg_d| >= 0.15)
   r_dvol = (dollar_vol_d >= 5_000_000)
   r_px = (0.20 <= close_d <= 20.00)
   r_cap = (market_cap_d < 2_000_000_000) OR (market_cap_d IS NULL)

   info_rich = r_rvol AND r_chg AND r_dvol AND r_px AND r_cap
   ```
3. Genera watchlists diarias (una por fecha)
4. Guarda en estructura particionada por d√≠a

**Output generado**:
```
processed/universe/info_rich/
‚îú‚îÄ‚îÄ daily/
‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-02/watchlist.parquet    (0 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-06/watchlist.parquet    (3 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ date=2015-06-15/watchlist.parquet    (1,389 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ date=2024-10-15/watchlist.parquet    (2,236 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ ... (5,934 archivos, uno por d√≠a de trading)
‚îÇ   ‚îî‚îÄ‚îÄ date=2025-10-21/watchlist.parquet
‚îî‚îÄ‚îÄ _SUCCESS
```

**Schema watchlist.parquet**:
```
ticker: Utf8
trading_day: Date
close_d: Float64
pctchg_d: Float64
rvol30: Float64
dollar_vol_d: Float64
session_rows: UInt32
has_gaps: Boolean
```

**M√©tricas REALES** (ejecuci√≥n 2025-10-26 20:42-20:54):
- **D√≠as procesados**: 5,934 (2004-01-02 a 2025-10-21)
- **Total eventos E0**: ~29,555 ticker-d√≠as
- **Promedio E0/d√≠a**: 4.98 tickers (~5 por d√≠a)
- **Watchlists generadas**: 5,934 archivos
- **Tiempo ejecuci√≥n**: ~11 minutos
  - Carga cache (8,617 tickers): 15s
  - Carga registros (14.7M rows): 64s
  - Generaci√≥n watchlists: ~10 min
- **Exit code**: 0 (SUCCESS)

**Validaci√≥n REAL** (ejemplos verificados):
```python
import polars as pl

# D√≠a 2004-01-06 (inicio hist√≥rico)
df = pl.read_parquet("processed/universe/info_rich/daily/date=2004-01-06/watchlist.parquet")
print(f"Tickers E0: {len(df)}")  # 3 tickers

# D√≠a 2015-06-15 (per√≠odo intermedio)
df = pl.read_parquet("processed/universe/info_rich/daily/date=2015-06-15/watchlist.parquet")
print(f"Tickers E0: {len(df)}")  # 1,389 tickers
print(f"RVOL min: {df['rvol30'].min():.2f}")  # ‚â•2.0
print(f"|%chg| min: {df['pctchg_d'].abs().min():.2%}")  # ‚â•15%
print(f"$vol min: ${df['dollar_vol_d'].min():,.0f}")  # ‚â•$5M

# D√≠a 2024-10-15 (reciente)
df = pl.read_parquet("processed/universe/info_rich/daily/date=2024-10-15/watchlist.parquet")
print(f"Tickers E0: {len(df)}")  # 2,236 tickers
print(f"Precio min: ${df['close_d'].min():.2f}")  # ‚â•$0.20
print(f"Precio max: ${df['close_d'].max():.2f}")  # ‚â§$20.00
```

**An√°lisis completo**: Ver notebook [analysis_watchlists_paso3.ipynb](notebooks/analysis_watchlists_paso3.ipynb)

**Resultados detallados**: Ver [C.5.2_resultados_paso_3.md](C.5.2_resultados_paso_3.md)

**Criterio de √©xito**:
- ‚úÖ 5,934 watchlists generadas (uno por d√≠a de trading)
- ‚úÖ ~29,555 eventos E0 identificados (21 a√±os)
- ‚úÖ Todos los tickers E0 cumplen TODOS los umbrales
- ‚úÖ Exit code 0 (sin errores)

---

### PASO 4: An√°lisis Caracter√≠sticas E0 (2004-2025)

**Objetivo**: Documentar caracter√≠sticas de eventos E0 identificados

**Tiempo REAL**: ~2 minutos (2025-10-26)

**Script ejecutado**: `analyze_e0_characteristics.py`

**Comando**:
```bash
python scripts/fase_C_ingesta_tiks/analyze_e0_characteristics.py
```

**NOTA IMPORTANTE**: Este paso fue **SIMPLIFICADO** porque no existen watchlists C_v1 para comparar.
En su lugar, se documentaron las caracter√≠sticas de E0 para verificar cumplimiento del Contrato v2.0.0.

**¬øQu√© hace?**:
1. Lee todos los watchlists E0 (2004-2025)
2. Filtra solo eventos con `info_rich=True`
3. Analiza distribuci√≥n temporal por a√±o
4. Verifica rangos de precio ($0.20-$20.00)
5. Valida caracter√≠sticas E0 (RVOL‚â•2, |%chg|‚â•15%, $vol‚â•$5M)
6. Identifica TOP tickers m√°s frecuentes

**Output generado**:
```
01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/audits/
‚îú‚îÄ‚îÄ CARACTERISTICAS_E0.json         (an√°lisis completo)
‚îî‚îÄ‚îÄ top_e0_tickers.csv              (TOP 20 tickers)
```

**M√©tricas REALES** (ejecuci√≥n 2025-10-26):
```json
{
  "periodo": "2004-01-02 ‚Üí 2025-10-21",
  "total_eventos_e0": 29555,
  "tickers_unicos": 4898,
  "dias_con_e0": 4949,

  "caracteristicas_e0": {
    "rvol30": {"mean": 9.13, "median": 5.94, "umbral_min": 2.0},
    "pctchg_abs": {"mean": 0.4175, "median": 0.2377, "umbral_min": 0.15},
    "dollar_vol": {"mean": 82792984, "median": 22094051, "umbral_min": 5000000}
  },

  "distribucion_precio": {
    "$1-$5": "35.6%",
    "$10-$20": "30.4%",
    "$5-$10": "28.2%",
    "$0.50-$1": "3.8%",
    "$0.20-$0.50 (penny)": "2.1%"
  },

  "top_5_tickers": [
    {"ticker": "BCRX", "dias_e0": 63},
    {"ticker": "GERN", "dias_e0": 53},
    {"ticker": "VXRT", "dias_e0": 51},
    {"ticker": "SRNE", "dias_e0": 50},
    {"ticker": "BLDP", "dias_e0": 43}
  ],

  "conclusion": "E0 cumple con Contrato v2.0.0: small/micro caps ($0.20-$20.00), info-rich (RVOL‚â•2, |%chg|‚â•15%, $vol‚â•$5M)"
}
```

**Eventos E0 por a√±o**:
- 2004-2007: ~400 eventos/a√±o (inicio hist√≥rico)
- 2008-2009: ~1,000 eventos/a√±o (crisis financiera)
- 2010-2019: ~500-1,300 eventos/a√±o (estable)
- 2020-2021: ~3,300 eventos/a√±o (pandemia, alta volatilidad)
- 2022-2024: ~2,200-3,500 eventos/a√±o (normalizaci√≥n)
- 2025: ~4,200 eventos (parcial, hasta Oct 21)

**Validaci√≥n cumplimiento filtros E0**:
```python
# Todos los eventos E0 cumplen:
RVOL30: mean=9.13, median=5.94    ‚úÖ (‚â•2.0)
|%chg|: mean=41.75%, median=23.77% ‚úÖ (‚â•15%)
$vol: mean=$82.8M, median=$22.1M   ‚úÖ (‚â•$5M)
Precio: min=$0.20, max=$20.00      ‚úÖ (rango correcto)
```

**An√°lisis completo**: Ver notebook [analysis_caracteristicas_paso4_executed.ipynb](notebooks/analysis_caracteristicas_paso4_executed.ipynb)

**Resultados detallados**: Ver [C.5.4_resultados_paso_4.md](C.5.4_resultados_paso_4.md)

**Archivos de auditor√≠a**: Ver [audits/CARACTERISTICAS_E0.json](audits/CARACTERISTICAS_E0.json)

**Criterio de √©xito**:
- ‚úÖ 29,555 eventos E0 identificados (2004-2025)
- ‚úÖ 4,898 tickers √∫nicos con eventos E0
- ‚úÖ TODOS los eventos cumplen filtros E0
- ‚úÖ Distribuci√≥n de precio coherente con small/micro caps
- ‚úÖ Documentaci√≥n completa generada

**IMPORTANTE**: No se compar√≥ con C_v1 porque no existen watchlists v1 guardadas.
Esta auditor√≠a verifica que E0 cumple con el Contrato v2.0.0 sin necesidad de comparaci√≥n.

---

### PASO 5: Descarga Ticks D√≠as Info-Rich E0

**Objetivo**: Descargar ticks de Polygon solo para d√≠as info-rich identificados

**Tiempo estimado**: Variable (depende de total ticker-d√≠as info-rich)

**Script**: `download_trades_optimized.py`

**Estrategia recomendada**: **Modo watchlists** (solo d√≠as info-rich)

**Comando**:
```bash
python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --tickers-csv processed/universe/info_rich/topN_12m.csv \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

**¬øQu√© hace?**:
1. Lee `topN_12m.csv` (lista de tickers a procesar)
2. Para cada ticker, lee watchlists diarias en `processed/universe/info_rich/daily/`
3. Identifica d√≠as donde `info_rich = True`
4. Descarga ticks SOLO de esos d√≠as usando Polygon API v3
5. Guarda en: `raw/polygon/trades/{TICKER}/date={YYYY-MM-DD}/trades.parquet`
6. Marca completados con `_SUCCESS`
7. Resume autom√°tico si se interrumpe

**Par√°metros clave**:
- `--mode watchlists`: Descarga solo d√≠as info-rich (eficiente)
- `--page-limit 50000`: Tama√±o de p√°gina Polygon (√≥ptimo para ticks)
- `--rate-limit 0.15`: 150ms entre requests (evita 429)
- `--workers 8`: Procesos concurrentes (ajustar seg√∫n RAM)
- `--resume`: Salta d√≠as ya descargados (_SUCCESS existe)

**Estimaci√≥n de volumen**:
```
Supuestos:
- Ticker-d√≠as info-rich: ~150,000 (21 a√±os)
- Ticks promedio/d√≠a: ~50,000
- Tama√±o promedio/ticker-d√≠a: ~30 MB (comprimido ZSTD)

Total estimado:
- Ticks totales: 150,000 √ó 50,000 = 7.5B ticks
- Storage: 150,000 √ó 30 MB = 4.5 TB
```

**Tiempo estimado**:
```
Supuestos:
- Rate limit: 0.15s/request ‚Üí ~400 requests/min ‚Üí 24,000/hora
- Requests/ticker-d√≠a: ~3 (promedio con paginaci√≥n)
- Total requests: 150,000 √ó 3 = 450,000

Tiempo descarga: 450,000 / 24,000 = ~18.75 horas (~1 d√≠a)
```

**Nota**: Esto es con 8 workers en paralelo. Con 1 worker ser√≠a ~150 horas (~6 d√≠as).

**Output esperado**:
```
raw/polygon/trades/
‚îú‚îÄ‚îÄ AAPL/
‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-05/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet          (ticks del d√≠a, schema: t, p, s, c)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îú‚îÄ‚îÄ date=2004-03-12/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ TSLA/
‚îÇ   ‚îú‚îÄ‚îÄ date=2020-08-31/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ... (2,000-2,500 tickers √∫nicos con d√≠as info-rich)
```

**Schema trades.parquet**:
```
t: Datetime (microseconds)      # sip_timestamp
p: Float64                       # price
s: Int64                         # size
c: List[Utf8]                   # conditions
```

**Validaci√≥n durante descarga**:
```python
import polars as pl
from pathlib import Path

# Verificar ticker-d√≠a ejemplo
df = pl.read_parquet("raw/polygon/trades/AAPL/date=2004-01-05/trades.parquet")
print(f"Ticks: {len(df):,}")
print(f"Rango tiempo: {df['t'].min()} ‚Üí {df['t'].max()}")
print(f"Precio min/max: ${df['p'].min():.2f} / ${df['p'].max():.2f}")
print(f"Tama√±o total: {sum(df['s']):,} shares")
print(df.head(10))
```

**Monitoreo progreso**:
```bash
# Ver logs en tiempo real
tail -f download_trades.log

# Contar d√≠as completados
find raw/polygon/trades -name "_SUCCESS" | wc -l

# Estimar tiempo restante (actualizar cada hora)
python scripts/fase_C_ingesta_tiks/estimate_remaining_time.py \
  --target-dir raw/polygon/trades \
  --total-expected 150000
```

**Criterio de √©xito**:
- ‚úÖ >95% ticker-d√≠as info-rich descargados
- ‚úÖ Ticks v√°lidos (timestamp, price, size coherentes)
- ‚úÖ `_SUCCESS` por cada ticker-d√≠a completado
- ‚úÖ Resume funciona correctamente si se interrumpe

---

## 2. CRONOGRAMA REAL vs ESTIMADO

| Paso | Tarea | Estimado | Real | Status |
|------|-------|----------|------|--------|
| 0 | ~~SCD-2 market cap~~ | 2 min | 2 min | ‚ùå DEPRECADO (datos solo 2025-10-19‚Üí) |
| 1 | Cach√© diario 2004-2025 | 6-8h | 4.8h √ó 2 = 9.6h | ‚úÖ COMPLETADO (2da ejecuci√≥n OK) |
| 2 | Config umbrales | 1 min | 1 min | ‚úÖ ACTUALIZADO (sin cap_max) |
| 3 | Universo din√°mico E0 | 30-45 min | 11 min | ‚úÖ COMPLETADO (5,934 watchlists, 29,555 E0) |
| 4 | An√°lisis caracter√≠sticas E0 | 10-15 min | 2 min | ‚úÖ COMPLETADO (simplificado, sin C_v1) |
| 5 | Descarga ticks | 18-24h | TBD | ‚è≥ PENDIENTE |

**Total real**: ~10-15 horas hasta aqu√≠ (incluyendo debugging y re-ejecuci√≥n)

**Nota**: El paso 5 (descarga ticks) es el cuello de botella. Considerar:
- Ejecutar en servidor/instancia cloud con buena conexi√≥n
- Monitorear rate limits de Polygon API
- Usar `--resume` para tolerancia a fallos
- Ejecutar en horario off-peak si es posible

---

## 3. ESTRATEGIA DE VALIDACI√ìN (CADA PASO)

### Antes de avanzar al siguiente paso, verificar:

**PASO 0 ‚Üí PASO 1**:
- ~~SCD-2 market_cap_dim~~ **DEPRECADO** (solo cubre 2025-10-19‚Üí)

**PASO 1 ‚Üí PASO 2**:
- ‚úÖ 8,617+ tickers procesados
- ‚úÖ Tickers con datos tienen >100 d√≠as (verificar NO solo 2)
- ‚úÖ `rvol30`, `pctchg_d`, `dollar_vol_d` calculados
- ‚úÖ `market_cap_d` = NULL (aceptable)

**PASO 2 ‚Üí PASO 3**:
- ‚úÖ `configs/universe_config.yaml` actualizado SIN `cap_max`
- ‚úÖ `min_price: 0.2`, `max_price: 20.0`

**PASO 3 ‚Üí PASO 4**:
- ‚úÖ 5,934 watchlists generadas (confirmado)
- ‚úÖ ~29,555 eventos E0 identificados
- ‚úÖ Tickers info-rich cumplen TODOS los umbrales
- ‚úÖ Exit code 0 (ejecuci√≥n exitosa)

**PASO 4 ‚Üí PASO 5**:
- ‚úÖ An√°lisis caracter√≠sticas E0 completado
- ‚úÖ 29,555 eventos E0 identificados (2004-2025)
- ‚úÖ TODOS los eventos cumplen filtros E0
- ‚úÖ Documentaci√≥n JSON y CSV generada

**PASO 5 ‚Üí FIN**:
- ‚úÖ >95% ticker-d√≠as info-rich con ticks descargados
- ‚úÖ `_SUCCESS` markers presentes
- ‚úÖ Ticks v√°lidos (sample verificado)

---

## 4. GESTI√ìN DE ERRORES Y CONTINGENCIAS

### Errores comunes y soluciones:

**SCD-2 con baja cobertura** (<80% market cap):
```bash
# Opci√≥n 1: Imputar con shares_outstanding √ó close_d
python scripts/fase_C_ingesta_tiks/build_market_cap_dim.py \
  --details-root raw/polygon/reference/ticker_details \
  --outdir processed/ref/market_cap_dim \
  --daily-cache processed/daily_cache \
  --impute
```

**Cach√© diario lento**:
- Aumentar `--parallel` (si tienes m√°s cores)
- Ejecutar en instancia con m√°s CPU/RAM
- Usar `--incremental` para procesar solo nuevos

**Descarga ticks interrumpida**:
- Usar `--resume` (autom√°tico)
- Verificar API key de Polygon activa
- Verificar rate limits no excedidos
- Ajustar `--rate-limit` si ves muchos 429

**Polygon API 429 (Too Many Requests)**:
- Aumentar `--rate-limit` (0.15 ‚Üí 0.20 ‚Üí 0.25)
- Reducir `--workers` (8 ‚Üí 4 ‚Üí 2)
- Pausar y reintentar m√°s tarde

**Storage lleno durante descarga ticks**:
- Estimar antes: ~4.5 TB para 21 a√±os
- Considerar descarga por ventanas (2004-2010, 2011-2015, etc.)
- Comprimir con ZSTD level 3-5 (m√°s agresivo)

---

## 5. ESTRUCTURA FINAL DE DATOS

```
D:\04_TRADING_SMALLCAPS\
‚îÇ
‚îú‚îÄ‚îÄ raw/polygon/
‚îÇ   ‚îú‚îÄ‚îÄ reference/ticker_details/          (snapshots market cap)
‚îÇ   ‚îî‚îÄ‚îÄ trades/                             (ticks E0)
‚îÇ       ‚îú‚îÄ‚îÄ AAPL/date=2004-01-05/trades.parquet
‚îÇ       ‚îî‚îÄ‚îÄ ... (~150,000 ticker-d√≠as)
‚îÇ
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ ref/market_cap_dim/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ market_cap_dim.parquet         (SCD-2 temporal)
‚îÇ   ‚îú‚îÄ‚îÄ daily_cache/                        (cach√© diario agregado)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ticker=AAPL/daily.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (3,107 tickers)
‚îÇ   ‚îî‚îÄ‚îÄ universe/info_rich/
‚îÇ       ‚îú‚îÄ‚îÄ daily/                          (watchlists E0)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-02/watchlist.parquet
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ... (~5,292 d√≠as)
‚îÇ       ‚îú‚îÄ‚îÄ topN_12m.parquet
‚îÇ       ‚îî‚îÄ‚îÄ topN_12m.csv
‚îÇ
‚îú‚îÄ‚îÄ audits/
‚îÇ   ‚îú‚îÄ‚îÄ AUDITORIA_INCLUSION_C_v1_vs_E0.json
‚îÇ   ‚îú‚îÄ‚îÄ only_C_v1_midcaps.parquet
‚îÇ   ‚îî‚îÄ‚îÄ only_E0_pennystocks.parquet
‚îÇ
‚îî‚îÄ‚îÄ 01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/
    ‚îú‚îÄ‚îÄ Contrato_E0.md                      (contrato inmutable v2.0.0)
    ‚îú‚îÄ‚îÄ C.4_anotacion_descarga_tiks_daily.md
    ‚îî‚îÄ‚îÄ C.5_plan_ejecucion_E0_descarga_ticks.md  (este documento)
```

---

## 6. PR√ìXIMOS PASOS POST-DESCARGA

Una vez completada la descarga de ticks E0:

1. **Construcci√≥n de Barras Informativas** (DIB/VIB):
   - Dollar Imbalance Bars
   - Volume Imbalance Bars
   - Tick Imbalance Bars

2. **Triple Barrier Labeling**:
   - Profit target / stop loss
   - Time-based exit
   - Meta-labeling

3. **Feature Engineering**:
   - Microestructura (spread, VWAP deviation, order flow)
   - Volume Profile
   - Tick-level features

4. **Sample Weighting**:
   - Bootstrap weights
   - Sequential bootstrap
   - Time decay

5. **Incorporaci√≥n eventos E1-E13**:
   - Parabolic (E4)
   - First Red Day (E7)
   - Dilution (E9)
   - etc.

6. **Dataset Maestro 2004-2025**:
   - Unificaci√≥n E0 ‚à™ E1 ‚à™ ... ‚à™ E13
   - Particionado por r√©gimen
   - Versionado para ML

---

## 7. COMANDOS R√ÅPIDOS (RESUMEN)

```bash
# PASO 0: SCD-2 - DEPRECADO (solo cubre 2025-10-19‚Üí)
# NO ejecutar

# PASO 1: Cach√© diario (SIN market_cap)
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2004-01-01 --to 2025-10-21 \
  --parallel 8
  # SIN --cap-filter-parquet

# PASO 2: Actualizar config (remover cap_max)
# Editar: configs/universe_config.yaml
# Comentar o eliminar: cap_max: 2_000_000_000

# PASO 3: Universo E0 (sin filtro market_cap)
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2004-01-01 --to 2025-10-21 \
  --config configs/universe_config.yaml

# PASO 4: Verificaci√≥n (script a crear)
python scripts/fase_C_ingesta_tiks/verify_inclusion_C_v1_vs_E0.py \
  --c_v1-watchlists processed/universe/info_rich_v1/daily \
  --e0-watchlists processed/universe/info_rich/daily \
  --from 2020-01-01 --to 2025-10-21 \
  --outdir audits

# PASO 5: Descarga ticks
python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --tickers-csv processed/universe/info_rich/topN_12m.csv \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

---

## 8. NOTAS FINALES

### Validaci√≥n conceptual
Este plan ejecuta la estrategia documentada en Contrato_E0.md v2.0.0:
- ‚úÖ E0 como "pegamento legal" entre C_v1 y C_v2
- ‚úÖ Filtros coherentes con mandato Small/MicroCap
- ‚úÖ Documentaci√≥n de diferencias C_v1 vs E0
- ‚úÖ Trazabilidad completa de exclusiones/inclusiones

### Garant√≠a de coherencia
- Pipeline √∫nico unificado (no C_v1 + C_v2 separados)
- Versionado formal (Contrato v2.0.0)
- Auditor√≠a emp√≠rica de inclusi√≥n
- Justificaci√≥n documentada de diferencias

### Escalabilidad a 21 a√±os
- SCD-2 para market cap hist√≥rico correcto
- Join temporal evita survivorship bias
- Watchlists por d√≠a permiten descarga selectiva
- Resume tolerance para ejecuciones largas

### Listo para ML
- Features pre-calculadas (rvol30, pctchg_d)
- Ticks listos para barras informativas
- Etiquetas por evento (E0, E1, ..., E13)
- Particionado por r√©gimen macro

---

**Documento creado**: 2025-10-25
**Autor**:  Alex Just Rodriguez
**Versi√≥n**: 1.0.0
**Basado en**: Contrato_E0.md v2.0.0
**Status**: LISTO PARA EJECUCI√ìN

**FIN DEL PLAN DE EJECUCI√ìN**
