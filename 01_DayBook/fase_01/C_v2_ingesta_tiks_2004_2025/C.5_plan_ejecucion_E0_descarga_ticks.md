# C.5 - Plan de Ejecuci√≥n E0: Descarga Ticks 2004-2025

**Fecha**: 2025-10-27
**Versi√≥n**: 1.2.0 (refactor post-PASO 5 completado)
**Basado en**: Contrato_E0.md v2.0.0
**Prerequisito**: C.4 - Descarga OHLCV Daily/Intraday completada (8,620 tickers raw intraday)
**Ver tambi√©n**: C.7_ERROR_SCD2_Y_SOLUCION.md para contexto del error cr√≠tico y fix aplicado

---

## √çNDICE

1. [Pipeline de Ejecuci√≥n (5 PASOS)](#1-pipeline-de-ejecuci√≥n-5-pasos)
   - [PASO 0: Generaci√≥n Dimensi√≥n SCD-2 (DEPRECADO)](#paso-0-generaci√≥n-dimensi√≥n-scd-2-market-cap-deprecado)
   - [PASO 1: Generaci√≥n Cach√© Diario 2004-2025](#paso-1-generaci√≥n-cach√©-diario-2004-2025)
   - [PASO 2: Actualizar Configuraci√≥n Umbrales E0](#paso-2-actualizar-configuraci√≥n-umbrales-e0)
   - [PASO 3: Generaci√≥n Universo Din√°mico E0](#paso-3-generaci√≥n-universo-din√°mico-e0-2004-2025)
   - [PASO 4: An√°lisis Caracter√≠sticas E0](#paso-4-an√°lisis-caracter√≠sticas-e0-2004-2025)
   - [PASO 5: Descarga Ticks D√≠as Info-Rich E0](#paso-5-descarga-ticks-d√≠as-info-rich-e0)
2. [Estructura Final de Datos (PASO 5 Completado)](#2-estructura-final-de-datos-paso-5-completado)
3. [Especificaci√≥n T√©cnica Multi-Evento](#3-especificaci√≥n-t√©cnica-multi-evento-e0--e1-e17-futuros)
4. [Comandos R√°pidos (Resumen)](#4-comandos-r√°pidos-resumen)
5. [Notas Finales](#5-notas-finales)

**Roadmaps de Implementaci√≥n Multi-Evento**:
- [C.6 - Roadmap Ejecutivo Multi-Evento](C.6_roadmap_multi_evento.md) - Estrategia, decisiones, timeline
- [C.7 - Especificaci√≥n T√©cnica Detallada](C.7_roadmap_post_paso5.md) - C√≥digo ejecutable, algoritmos completos

---

## 1. PIPELINE DE EJECUCI√ìN (5 PASOS)

### PASO 0: ~~Generaci√≥n Dimensi√≥n SCD-2 Market Cap~~ (DEPRECADO)

**‚ö†Ô∏è IMPORTANTE**: Este paso fue deprecado debido a error cr√≠tico detectado el 2025-10-26.

**Problema identificado**:
- La dimensi√≥n SCD-2 generada solo conten√≠a UN per√≠odo por ticker
- Rango temporal: `2025-10-19 ‚Üí 2099-12-31` (solo 7 d√≠as hist√≥ricos)
- Faltaban datos hist√≥ricos 2004-2025
- Caus√≥ que PASO 1 solo generara 2 d√≠as por ticker en lugar de 21 a√±os

**Impacto**:
```
Ejecuci√≥n CON market_cap (2025-10-25 23:40):
- 8,617 tickers procesados
- PERO solo 2 d√≠as por ticker (2025-10-20, 2025-10-21)
- Total days: 5,524 (deber√≠a ser ~5M = 8,617 √ó 600)
```

**Causa ra√≠z**:
El join temporal en `build_daily_cache.py`:
```python
.filter(
    (pl.col("effective_from") <= pl.col("trading_day")) &
    (pl.col("trading_day") < pl.col("effective_to"))
)
```
Filtr√≥ el 99.9% de datos hist√≥ricos porque SCD-2 solo cubr√≠a desde 2025-10-19.

**Soluci√≥n aplicada**:
- ‚úÖ Re-ejecutar PASO 1 **SIN** `--cap-filter-parquet`
- ‚úÖ `market_cap_d` ser√° NULL en daily_cache
- ‚úÖ PASO 3 (filtrado E0) modificado para NO usar filtro market_cap

**Pendiente futuro** (post-MVP E0):
- Construir SCD-2 hist√≥rico real (m√∫ltiples per√≠odos por ticker)
- Requiere fuente de datos con history (Polygon solo tiene snapshot actual)
- Proxy alternativo: `market_cap_d = close_d √ó shares_outstanding_d`

---

### PASO 1: Generaci√≥n Cach√© Diario 2004-2025

* **Objetivo**: Agregar OHLCV 1-min ‚Üí diario con features (rvol30, pctchg_d)
* **Tiempo real**: ~4.8 horas (8,620 tickers, 67.6% vac√≠os sin datos raw)
* **Script**: `build_daily_cache.py`

**Comando CORRECTO** (actualizado 2025-10-26 08:05):
```bash
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2004-01-01 --to 2025-10-21 \
  --parallel 8
  # SIN --cap-filter-parquet
  # market_cap_d quedar√° NULL temporalmente (corregir en PASO 0 v2)
```

**¬øQu√© hace?**:
1. Lee barras 1-min de `raw/polygon/ohlcv_intraday_1m/`
2. Agrega a diario por ticker-fecha: `close_d`, `vol_d`, `dollar_vol_d`, `vwap_d`, `session_rows`, `has_gaps`
3. Calcula features: `pctchg_d`, `return_d`, `rvol30` (rolling 30 sesiones, min_periods=1)
4. ~~Join temporal con SCD-2~~ **DEPRECADO**: `market_cap_d` = NULL

**Output esperado**:
```
processed/daily_cache/
‚îú‚îÄ‚îÄ ticker=BCRX/
‚îÇ   ‚îú‚îÄ‚îÄ daily.parquet               (schema: 12 columnas, ZSTD)
‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îú‚îÄ‚îÄ ticker=GERN/
‚îÇ   ‚îú‚îÄ‚îÄ daily.parquet
‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îú‚îÄ‚îÄ ... (8,617 tickers)
‚îú‚îÄ‚îÄ MANIFEST.json                   (metadata global)
‚îî‚îÄ‚îÄ _SUCCESS
```

**Schema output**:
```
ticker: Utf8
trading_day: Date
close_d: Float64
vol_d: Int64
dollar_vol_d: Float64
vwap_d: Float64
pctchg_d: Float64
return_d: Float64
rvol30: Float64
session_rows: Int64
has_gaps: Boolean
market_cap_d: Float64               ‚Üê NULL (SCD-2 deprecado)
```

**M√©tricas REALES** (ejecuci√≥n 2025-10-26 08:05):
- Tickers encontrados: 8,620
- Tickers con datos: ~2,795 (32.4%)
- Tickers vac√≠os (0 d√≠as): 5,825 (67.6%) - sin datos raw intraday
- Ticker-d√≠as reales: Pendiente completar ejecuci√≥n
- Tiempo: ~4-5 horas
- Tama√±o: ~15 MB (comprimido ZSTD)

**Validaci√≥n** (ejecutar ANTES de PASO 3):
```bash
python scripts/audit_paso1_complete.py
```

Verificar:
- TOP 20 tickers tienen >100 d√≠as (NO solo 2)
- market_cap_d es 100% NULL (esperado)
- rvol30, pctchg_d, dollar_vol_d calculados correctamente

**Criterio de √©xito**:
- ‚úÖ 8,617+ tickers procesados (success + no_data)
- ‚úÖ Tickers con datos tienen rango completo 2004-2025 (NO solo 2025-10-20/21)
- ‚úÖ rvol30 calculado correctamente
- ‚úÖ market_cap_d = NULL (aceptable, sin filtro cap en PASO 3)

---

> ...  
> **Resultados** : mira este link [PASO 1: Generaci√≥n Cach√© Diario 2004-2025](./C.5.0_resultados_paso_1.md)  
>  
> üìä **Archivo JSON Generado**
> El archivo `stats_daily_cache.json` contiene:
> * Estad√≠sticas detalladas de cada ticker
> * Distribuci√≥n de d√≠as E0
> * M√©tricas por columna (min, max, mean, median, std)
> * Conteo de NULLs
> ¬øQuieres ver el contenido del JSON de alg√∫n ticker espec√≠fico? Por ejemplo:  
> `python -c "import json; data=json.load(open('stats_daily_cache.json')); ticker=[t for t in data['tickers'] if t['ticker']=='BCRX'][0]; import pprint; pprint.pprint(ticker)`
> ...  


### PASO 2: Actualizar Configuraci√≥n Umbrales E0

**Objetivo**: Configurar umbrales E0 **SIN** filtro market_cap

**Tiempo**: 1 minuto

**Archivo**: `configs/universe_config.yaml`

**Contenido ACTUALIZADO** (2025-10-26):
```yaml
# E0/C_v2 (2004-2025) - Contrato v2.0.0 - market_cap removido
thresholds:
  rvol: 2.0                   # Volumen relativo m√≠nimo
  pctchg: 0.15                # |% change| m√≠nimo (15%)
  dvol: 5_000_000             # Dollar volume m√≠nimo ($5M)
  min_price: 0.2              # Precio m√≠nimo $0.20 (proxy small cap)
  max_price: 20.0             # Precio m√°ximo $20.00 (proxy small cap)
  # cap_max: REMOVIDO (market_cap_d es NULL)
```

**Justificaci√≥n**:
- Filtro de precio ($0.20-$20.00) ya elimina mayor√≠a de large caps
- Filtro de volumen ($5M) asegura liquidez
- Market cap era redundante con precio para small caps

---

### PASO 3: Generaci√≥n Universo Din√°mico E0 (2004-2025)

* **Objetivo**: Identificar d√≠as info-rich seg√∫n filtros E0 y generar watchlists diarias
* **Tiempo REAL**: ~11 minutos (2025-10-26 20:42-20:54)
* **Script**: `build_dynamic_universe_optimized.py`

**Comando**:
```bash
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2004-01-01 --to 2025-10-21 \
  --config configs/universe_config.yaml
```

**¬øQu√© hace?**:
1. Lee cach√© diario completo (8,617 tickers, 14,763,368 ticker-d√≠as)
2. Aplica filtros E0:

   ```python
   r_rvol = (rvol30 >= 2.0)
   r_chg = (|pctchg_d| >= 0.15)
   r_dvol = (dollar_vol_d >= 5_000_000)
   r_px = (0.20 <= close_d <= 20.00)
   r_cap = (market_cap_d < 2_000_000_000) OR (market_cap_d IS NULL)

   info_rich = r_rvol AND r_chg AND r_dvol AND r_px AND r_cap
   ```
3. Genera watchlists diarias (una por fecha)
4. Guarda en estructura particionada por d√≠a

**Output generado**:
```
processed/universe/info_rich/
‚îú‚îÄ‚îÄ daily/
‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-02/watchlist.parquet    (0 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-06/watchlist.parquet    (3 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ date=2015-06-15/watchlist.parquet    (1,389 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ date=2024-10-15/watchlist.parquet    (2,236 tickers E0)
‚îÇ   ‚îú‚îÄ‚îÄ ... (5,934 archivos, uno por d√≠a de trading)
‚îÇ   ‚îî‚îÄ‚îÄ date=2025-10-21/watchlist.parquet
‚îî‚îÄ‚îÄ _SUCCESS
```

**Schema watchlist.parquet**:
```
ticker: Utf8
trading_day: Date
close_d: Float64
pctchg_d: Float64
rvol30: Float64
dollar_vol_d: Float64
session_rows: UInt32
has_gaps: Boolean
```

**M√©tricas REALES** (ejecuci√≥n 2025-10-26 20:42-20:54):
- **D√≠as procesados**: 5,934 (2004-01-02 a 2025-10-21)
- **Total eventos E0**: ~29,555 ticker-d√≠as
- **Promedio E0/d√≠a**: 4.98 tickers (~5 por d√≠a)
- **Watchlists generadas**: 5,934 archivos
- **Tiempo ejecuci√≥n**: ~11 minutos
  - Carga cache (8,617 tickers): 15s
  - Carga registros (14.7M rows): 64s
  - Generaci√≥n watchlists: ~10 min
- **Exit code**: 0 (SUCCESS)

**Validaci√≥n REAL** (ejemplos verificados):
```python
import polars as pl

# D√≠a 2004-01-06 (inicio hist√≥rico)
df = pl.read_parquet("processed/universe/info_rich/daily/date=2004-01-06/watchlist.parquet")
print(f"Tickers E0: {len(df)}")  # 3 tickers

# D√≠a 2015-06-15 (per√≠odo intermedio)
df = pl.read_parquet("processed/universe/info_rich/daily/date=2015-06-15/watchlist.parquet")
print(f"Tickers E0: {len(df)}")  # 1,389 tickers
print(f"RVOL min: {df['rvol30'].min():.2f}")  # ‚â•2.0
print(f"|%chg| min: {df['pctchg_d'].abs().min():.2%}")  # ‚â•15%
print(f"$vol min: ${df['dollar_vol_d'].min():,.0f}")  # ‚â•$5M

# D√≠a 2024-10-15 (reciente)
df = pl.read_parquet("processed/universe/info_rich/daily/date=2024-10-15/watchlist.parquet")
print(f"Tickers E0: {len(df)}")  # 2,236 tickers
print(f"Precio min: ${df['close_d'].min():.2f}")  # ‚â•$0.20
print(f"Precio max: ${df['close_d'].max():.2f}")  # ‚â§$20.00
```

**An√°lisis completo**: Ver notebook [analysis_watchlists_paso3.ipynb](notebooks/analysis_watchlists_paso3.ipynb)

**Resultados detallados**: Ver [C.5.2_resultados_paso_3.md](C.5.2_resultados_paso_3.md)

**Criterio de √©xito**:
- ‚úÖ 5,934 watchlists generadas (uno por d√≠a de trading)
- ‚úÖ ~29,555 eventos E0 identificados (21 a√±os)
- ‚úÖ Todos los tickers E0 cumplen TODOS los umbrales
- ‚úÖ Exit code 0 (sin errores)

---

### PASO 4: An√°lisis Caracter√≠sticas E0 (2004-2025)

* **Objetivo**: Documentar caracter√≠sticas de eventos E0 identificados

* **Tiempo REAL**: ~2 minutos (2025-10-26)

* **Script ejecutado**: `analyze_e0_characteristics.py`

**Comando**:
```bash
python scripts/fase_C_ingesta_tiks/analyze_e0_characteristics.py
```

**NOTA IMPORTANTE**: Este paso fue **SIMPLIFICADO** porque no existen watchlists C_v1 para comparar.
En su lugar, se documentaron las caracter√≠sticas de E0 para verificar cumplimiento del Contrato v2.0.0.

**¬øQu√© hace?**:
1. Lee todos los watchlists E0 (2004-2025)
2. Filtra solo eventos con `info_rich=True`
3. Analiza distribuci√≥n temporal por a√±o
4. Verifica rangos de precio ($0.20-$20.00)
5. Valida caracter√≠sticas E0 (RVOL‚â•2, |%chg|‚â•15%, $vol‚â•$5M)
6. Identifica TOP tickers m√°s frecuentes

**Output generado**:
```
01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/audits/
‚îú‚îÄ‚îÄ CARACTERISTICAS_E0.json         (an√°lisis completo)
‚îî‚îÄ‚îÄ top_e0_tickers.csv              (TOP 20 tickers)
```

**M√©tricas REALES** (ejecuci√≥n 2025-10-26):
```json
{
  "periodo": "2004-01-02 ‚Üí 2025-10-21",
  "total_eventos_e0": 29555,
  "tickers_unicos": 4898,
  "dias_con_e0": 4949,

  "caracteristicas_e0": {
    "rvol30": {"mean": 9.13, "median": 5.94, "umbral_min": 2.0},
    "pctchg_abs": {"mean": 0.4175, "median": 0.2377, "umbral_min": 0.15},
    "dollar_vol": {"mean": 82792984, "median": 22094051, "umbral_min": 5000000}
  },

  "distribucion_precio": {
    "$1-$5": "35.6%",
    "$10-$20": "30.4%",
    "$5-$10": "28.2%",
    "$0.50-$1": "3.8%",
    "$0.20-$0.50 (penny)": "2.1%"
  },

  "top_5_tickers": [
    {"ticker": "BCRX", "dias_e0": 63},
    {"ticker": "GERN", "dias_e0": 53},
    {"ticker": "VXRT", "dias_e0": 51},
    {"ticker": "SRNE", "dias_e0": 50},
    {"ticker": "BLDP", "dias_e0": 43}
  ],

  "conclusion": "E0 cumple con Contrato v2.0.0: small/micro caps ($0.20-$20.00), info-rich (RVOL‚â•2, |%chg|‚â•15%, $vol‚â•$5M)"
}
```

**Eventos E0 por a√±o**:
- 2004-2007: ~400 eventos/a√±o (inicio hist√≥rico)
- 2008-2009: ~1,000 eventos/a√±o (crisis financiera)
- 2010-2019: ~500-1,300 eventos/a√±o (estable)
- 2020-2021: ~3,300 eventos/a√±o (pandemia, alta volatilidad)
- 2022-2024: ~2,200-3,500 eventos/a√±o (normalizaci√≥n)
- 2025: ~4,200 eventos (parcial, hasta Oct 21)

**Validaci√≥n cumplimiento filtros E0**:
```python
# Todos los eventos E0 cumplen:
RVOL30: mean=9.13, median=5.94    ‚úÖ (‚â•2.0)
|%chg|: mean=41.75%, median=23.77% ‚úÖ (‚â•15%)
$vol: mean=$82.8M, median=$22.1M   ‚úÖ (‚â•$5M)
Precio: min=$0.20, max=$20.00      ‚úÖ (rango correcto)
```

* **An√°lisis completo**: Ver notebook [analysis_caracteristicas_paso4_executed.ipynb](notebooks/analysis_caracteristicas_paso4_executed.ipynb)

* **Resultados detallados**: Ver [C.5.4_resultados_paso_4.md](C.5.4_resultados_paso_4.md)

* **Archivos de auditor√≠a**: Ver [audits/CARACTERISTICAS_E0.json](audits/CARACTERISTICAS_E0.json)

**Criterio de √©xito**:
- ‚úÖ 29,555 eventos E0 identificados (2004-2025)
- ‚úÖ 4,898 tickers √∫nicos con eventos E0
- ‚úÖ TODOS los eventos cumplen filtros E0
- ‚úÖ Distribuci√≥n de precio coherente con small/micro caps
- ‚úÖ Documentaci√≥n completa generada

**IMPORTANTE**: No se compar√≥ con C_v1 porque no existen watchlists v1 guardadas.
Esta auditor√≠a verifica que E0 cumple con el Contrato v2.0.0 sin necesidad de comparaci√≥n.

---

### PASO 5: Descarga Ticks D√≠as Info-Rich E0

* **Objetivo**: Descargar ticks de Polygon solo para d√≠as info-rich identificados

  * **Status**: COMPLETADO (2025-10-27)  
  * **Tiempo real**: ~1 hora (paralelizaci√≥n eficiente)  
  * **Cobertura**: 92.2% (64,801 / 70,290 d√≠as trading)  
  * **Storage**: 16.58 GB (vs 2.6 TB estimado, -99.2%)  

* **Script**: `download_trades_optimized.py`

* **Estrategia**: **Modo watchlists** (lee autom√°ticamente todos los watchlists)

**Comando RECOMENDADO** (todos los tickers E0 + ventana ¬±1 d√≠a):
```bash
python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --event-window 1 \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

**Comando ALTERNATIVO** (solo d√≠a del evento, sin ventana):
```bash
python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --event-window 0 \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

**Comando ALTERNATIVO** (solo TOP 200 tickers m√°s activos):
```bash
python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --tickers-csv processed/universe/info_rich/topN_12m.csv \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

**¬øQu√© hace?** (MODO WATCHLISTS):
1. Lee todos los watchlists en `processed/universe/info_rich/daily/` (5,934 d√≠as)
2. Para cada watchlist, identifica tickers con `info_rich=True` (eventos E0)
3. **EXPANDE cada evento E0 con ventana temporal**: `--event-window N` descarga ¬±N d√≠as alrededor del evento
   - `event-window=0`: Solo el d√≠a del evento (29,555 d√≠as total)
   - `event-window=1` (DEFAULT): ¬±1 d√≠a ‚Üí [day-1, day, day+1] (~88,665 d√≠as total)
   - Ej: E0 el 2020-03-16 con window=1 descarga [2020-03-15, 2020-03-16, 2020-03-17]
   - **Rationale**: Triple barrier labeling, meta-labeling y microstructure analysis necesitan contexto pre/post evento
4. Descarga ticks de esos ticker-d√≠as usando Polygon API v3
5. **Si usas `--tickers-csv`**: Limita descarga SOLO a tickers en ese CSV (ej: TOP 200)
6. **Sin `--tickers-csv`**: Descarga TODOS los tickers E0 (4,898 √∫nicos, 29,555 eventos)
7. Guarda en: `raw/polygon/trades/{TICKER}/date={YYYY-MM-DD}/trades.parquet`
8. Marca completados con `_SUCCESS`
9. Resume autom√°tico si se interrumpe

**Par√°metros clave**:
- `--mode watchlists`: Descarga solo d√≠as con `info_rich=True` (eficiente)
- `--tickers-csv`: **OPCIONAL** - Limita a subset de tickers (ej: topN_12m.csv = TOP 200)
- `--event-window N`: **NUEVO** - D√≠as extra antes/despu√©s del evento E0 (default=1)
  - `0`: Solo d√≠a evento (29,555 d√≠as total)
  - `1`: ¬±1 d√≠a (window default, ~88,665 d√≠as, 3x volumen)
  - `2`: ¬±2 d√≠as (~147,775 d√≠as, 5x volumen)
- `--page-limit 50000`: Tama√±o de p√°gina Polygon (√≥ptimo para ticks)
- `--rate-limit 0.15`: 150ms entre requests (evita 429)
- `--workers 8`: Procesos concurrentes (ajustar seg√∫n RAM)
- `--resume`: Salta d√≠as ya descargados (_SUCCESS existe)

**M√©tricas REALES** (PASO 5 completado):
```
Eventos E0 identificados: 29,555 ticker-d√≠as (2004-2025)
Tickers √∫nicos E0: 4,898
Event window aplicado: ¬±1 d√≠a

DESCARGA COMPLETADA:
- D√≠as objetivo: 82,012 (incluye weekends/holidays)
- D√≠as trading reales: 70,290
- D√≠as descargados: 64,801 (92.2% cobertura)
- D√≠as faltantes: 7,039 (7.8% - Polygon gaps, delisted)

STORAGE Y TICKS:
- Storage total: 16.58 GB
- Proyecci√≥n 100%: ~20 GB (vs 2.6 TB estimado, -99.2%)
- Ticks promedio/d√≠a: ~12,234 (vs ~50K estimado)
- Total ticks: ~805M (vs ~4.4B estimado)
- Tama√±o promedio/d√≠a: ~258 KB (vs ~30 MB estimado)

RAZON DIFERENCIA:
- Small caps tienen 100x-1000x menos volumen que large caps
- Estimaci√≥n basada en tickers grandes (AAPL, TSLA)
- A√±os antiguos (2004-2010) tienen muy pocos ticks
```

**Ver resultados detallados**: `C.5.5_resultados_paso_5.md`

**Nota**: Con 8 workers en paralelo. Con 1 worker ser√≠a 8x m√°s lento.

**Output REAL generado**:
```
raw/polygon/trades/
‚îú‚îÄ‚îÄ BCRX/                            (63 d√≠as E0 - TOP 1 ticker)
‚îÇ   ‚îú‚îÄ‚îÄ date=2008-10-15/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet          (ticks del d√≠a)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îú‚îÄ‚îÄ date=2020-03-16/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îî‚îÄ‚îÄ ... (63 d√≠as con eventos E0)
‚îú‚îÄ‚îÄ GERN/                            (53 d√≠as E0 - TOP 2 ticker)
‚îÇ   ‚îú‚îÄ‚îÄ date=2009-01-22/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ VXRT/                            (51 d√≠as E0 - TOP 3 ticker)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ... (4,875 tickers con descarga, 67,439 archivos completados)
```

**Archivos REALES generados**:
- **Tickers con descarga**: 4,875 (de 4,898 tickers √∫nicos E0)
- **Archivos _SUCCESS**: 67,439
- **Archivos trades.parquet**: 67,439
- **Storage total**: 16.58 GB (~20 GB proyectado al 100%)

**Schema trades.parquet** (Polygon API v3):
```
t: Datetime(ns)                  # Timestamp nanosegundos
p: Float64                       # Precio
s: UInt64                        # Size (volumen)
c: List[UInt8]                   # Condiciones del trade
x: UInt8                         # Exchange ID
z: UInt8                         # Tape (A/B/C)
```

**Validaci√≥n durante descarga**:
```python
import polars as pl
from pathlib import Path

# Verificar ticker-d√≠a ejemplo
df = pl.read_parquet("raw/polygon/trades/AAPL/date=2004-01-05/trades.parquet")
print(f"Ticks: {len(df):,}")
print(f"Rango tiempo: {df['t'].min()} ‚Üí {df['t'].max()}")
print(f"Precio min/max: ${df['p'].min():.2f} / ${df['p'].max():.2f}")
print(f"Tama√±o total: {sum(df['s']):,} shares")
print(df.head(10))
```

**Monitoreo progreso**:
```bash
# Ver logs en tiempo real
tail -f download_trades.log

# Contar d√≠as completados
find raw/polygon/trades -name "_SUCCESS" | wc -l

# Estimar tiempo restante (actualizar cada hora)
python scripts/fase_C_ingesta_tiks/estimate_remaining_time.py \
  --target-dir raw/polygon/trades \
  --total-expected 150000
```

**Criterio de √©xito**:
- ‚úÖ >95% ticker-d√≠as info-rich descargados
- ‚úÖ Ticks v√°lidos (timestamp, price, size coherentes)
- ‚úÖ `_SUCCESS` por cada ticker-d√≠a completado
- ‚úÖ Resume funciona correctamente si se interrumpe

---

## 2. ESTRUCTURA FINAL DE DATOS (PASO 5 COMPLETADO)

```
D:\04_TRADING_SMALLCAPS\
‚îÇ
‚îú‚îÄ‚îÄ raw/polygon/
‚îÇ   ‚îú‚îÄ‚îÄ reference/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ticker_details/                (8,686 tickers)
‚îÇ   ‚îî‚îÄ‚îÄ trades/                             (PASO 5 ‚úÖ COMPLETADO)
‚îÇ       ‚îú‚îÄ‚îÄ BCRX/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ date=2008-10-15/
‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ... (63 d√≠as E0 para BCRX)
‚îÇ       ‚îî‚îÄ‚îÄ ... (67,439 archivos, 16.58 GB)
‚îÇ
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ ref/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ market_cap_dim/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ market_cap_dim.parquet      (SCD-2, 8,686 tickers)
‚îÇ   ‚îú‚îÄ‚îÄ daily_cache/                         (PASO 1 ‚úÖ COMPLETADO)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ticker=AAPL/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ daily.parquet
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ _SUCCESS
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (8,618 tickers)
‚îÇ   ‚îî‚îÄ‚îÄ universe/
‚îÇ       ‚îî‚îÄ‚îÄ info_rich/                       (PASO 3 ‚úÖ COMPLETADO)
‚îÇ           ‚îú‚îÄ‚îÄ daily/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ date=2004-01-02/watchlist.parquet
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ ... (5,934 watchlists)
‚îÇ           ‚îú‚îÄ‚îÄ topN_12m.parquet
‚îÇ           ‚îî‚îÄ‚îÄ topN_12m.csv
‚îÇ
‚îî‚îÄ‚îÄ 01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/
    ‚îú‚îÄ‚îÄ audits/                              (PASO 4 ‚úÖ COMPLETADO)
    ‚îÇ   ‚îú‚îÄ‚îÄ CARACTERISTICAS_E0.json
    ‚îÇ   ‚îî‚îÄ‚îÄ top_e0_tickers.csv
    ‚îú‚îÄ‚îÄ C.5_plan_ejecucion_E0_descarga_ticks.md
    ‚îú‚îÄ‚îÄ C.5.5_resultados_paso_5.md
    ‚îî‚îÄ‚îÄ notebooks/
        ‚îî‚îÄ‚îÄ analysis_paso5_executed.ipynb
```

**M√©tricas finales REALES (2025-10-27)**:
- **PASO 1** (Daily Cache): 8,617 tickers procesados
- **PASO 3** (Watchlists): 5,934 d√≠as, 29,555 eventos E0, 4,898 tickers √∫nicos
- **PASO 5** (Ticks): 4,875 tickers, 67,439 archivos, 16.58 GB, ~805M ticks, 92.2% cobertura

---

## 3. ESPECIFICACI√ìN T√âCNICA MULTI-EVENTO (E0 + E1-E17 FUTUROS)

**Roadmaps de Implementaci√≥n**:
- **[C.6 - Roadmap Ejecutivo Multi-Evento](C.6_roadmap_multi_evento.md)** - Estrategia H√≠brido A+B, decisiones, timeline
- **[C.7 - Especificaci√≥n T√©cnica Detallada](C.7_roadmap_post_paso5.md)** - C√≥digo ejecutable, algoritmos DIB/VIB, detectores completos

Esta secci√≥n documenta la **especificaci√≥n t√©cnica** de c√≥mo se almacenar√°n y procesar√°n m√∫ltiples eventos (E0-E17) de forma eficiente sin duplicar ticks.

### 3.1 Estado Actual

**ACTUALMENTE IMPLEMENTADO** (PASO 5 completado):
```
‚úÖ E0 (Generic Info-Rich) - 2004-2025
   - 67,439 archivos descargados
   - 16.58 GB storage
   - 92.2% cobertura (64,801 / 70,290 d√≠as trading)
   - Event window: ¬±1 d√≠a
   - Estructura: raw/polygon/trades/{TICKER}/date={YYYY-MM-DD}/trades.parquet
```

**PLANIFICADO** (Ver [C.1](C.1_estrategia_descarga_ticks_eventos.md) y [C.6](C.6_roadmap_multi_evento.md)):
- E1: Volume Explosion (RVOL > 5√ó)
- E4: Parabolic Move (+50% en ‚â§5 d√≠as)
- E7: First Red Day (patr√≥n m√°s confiable)
- E8: Gap Down (>15%)
- E13: Offering Pricing (dilution events)

### 3.2 Arquitectura de Almacenamiento Multi-Evento

**Pregunta**: ¬øC√≥mo guardar m√∫ltiples eventos sin duplicar ticks?

**Respuesta**: Watchlist unificado + metadata JSON por ticker-d√≠a

#### Opci√≥n A: Carpetas Separadas por Evento ‚ùå

**Problema**: Duplicaci√≥n masiva si `BCRX` tiene E0+E1+E4 el mismo d√≠a ‚Üí 3√ó `trades.parquet`

**Conclusi√≥n**: Descartada (no escala para ML, imposible "verdad √∫nica" por ticker-d√≠a)

#### Opci√≥n B: Watchlist Unificado + Metadata JSON ‚úÖ

**Estructura**:

```
processed/universe/multi_event/daily/date=YYYY-MM-DD/
‚îî‚îÄ‚îÄ watchlist.parquet
    # Columnas boolean por evento: E0_info_rich, E1_volume_explosion, E4_parabolic, E7_first_red, E8_gap_down
    # event_types: list[str]  (ej: ["E0", "E4"])
    # max_event_window: int   (ventana individual m√°s grande, ej: E4 ¬±3 ‚Üí 7 d√≠as)

raw/polygon/trades/TICKER/date=YYYY-MM-DD/
‚îú‚îÄ‚îÄ trades.parquet  # UN SOLO archivo (sin duplicados)
‚îú‚îÄ‚îÄ _SUCCESS
‚îî‚îÄ‚îÄ events.json     # Metadata: qu√© eventos, ventanas, is_event_day, window_offset
```

**Ventajas**:
- ‚úÖ UN solo `trades.parquet` por ticker-d√≠a (sin duplicaci√≥n)
- ‚úÖ Storage eficiente (~3-5x menos que carpetas separadas)
- ‚úÖ Filtrado flexible por evento(s)
- ‚úÖ Trazabilidad completa v√≠a `events.json`

### 3.3 Especificaci√≥n T√©cnica de Datos

#### Schema: `watchlist.parquet` (multi-evento)

```python
ticker: str
trading_day: date

# Columnas boolean legibles por evento
E0_info_rich: bool
E1_volume_explosion: bool
E4_parabolic: bool
E7_first_red_day: bool
E8_gap_down: bool

# Resumen compacto
event_types: list[str]         # C√≥digos cortos: ["E0", "E4"]
max_event_window: int          # Ventana individual m√°s grande (E4 ¬±3 ‚Üí 7 d√≠as)
```

**Nota**: `max_event_window` es el tama√±o total de la ventana M√ÅS EXIGENTE, NO la uni√≥n de ventanas.

#### Schema: `events.json` (por ticker-d√≠a descargado)

Ubicaci√≥n: `raw/polygon/trades/TICKER/date=YYYY-MM-DD/events.json`

```json
{
  "ticker": "BCRX",
  "date": "2020-03-14",

  "events_context": [
    {
      "event_type": "E4",
      "event_day": "2020-03-16",
      "is_event_day": false,
      "window_offset": -2,
      "window_size": 7
    },
    {
      "event_type": "E0",
      "event_day": "2020-03-16",
      "is_event_day": false,
      "window_offset": -2,
      "window_size": 3
    }
  ],

  "max_event_window": 7,
  "download_window_applied_days": ["2020-03-13", "2020-03-14", ..., "2020-03-19"],
  "_success": true
}
```

**Campos clave**:
- `is_event_day`: Distingue d√≠a del evento vs contexto pre/post (cr√≠tico para labeling)
- `window_offset`: D√≠as desde evento (`date - event_day`)
- `download_window_applied_days`: Auditor√≠a y reproducibilidad

#### L√≥gica `--resume` con Merge Inteligente

**Problema**: Nuevo evento E4 requiere ventana ¬±3, pero E0 ya descarg√≥ ¬±1

**Soluci√≥n**: Merge incremental en `events.json`

1. Leer `events.json` existente
2. Agregar nuevo evento a `events_context`
3. Recalcular `max_event_window` = max(window_size)
4. Regenerar `download_window_applied_days` (uni√≥n de ventanas)
5. Si hay d√≠as nuevos no cubiertos ‚Üí descargar adicionales

**Implementaci√≥n**: Ver `scripts/fase_C_ingesta_tiks/build_multi_event_watchlists.py`

---

### 3.4 Implementaci√≥n (Roadmap Completo)

**Ver documento completo**: [C.6_roadmap_multi_evento.md](C.6_roadmap_multi_evento.md)

**Scripts a implementar**:
- `scripts/fase_C_ingesta_tiks/event_detectors/` (E1, E4, E7, E8)

```python
def calculate_all_events(df: pl.DataFrame) -> pl.DataFrame:
    """
    Calcula todos los eventos E0-E17 en un solo pass del daily_cache.
    """
    return df.with_columns([
        # E0: Generic Info-Rich (ya implementado)
        ((pl.col('rvol30') >= 2.0) &
         (pl.col('pctchg_d').abs() >= 0.15) &
         (pl.col('dollar_vol_d') >= 5_000_000) &
         (pl.col('close_d') >= 0.20) &
         (pl.col('close_d') <= 20.00)).alias('E0_info_rich'),

        # E1: Volume Explosion
        (pl.col('rvol30') >= 5.0).alias('E1_volume_explosion'),

        # E2: Gap Up > 10%
        (pl.col('gap_pct') > 0.10).alias('E2_gap_up'),

        # E4: Parabolic Move (+50% en ‚â§5 d√≠as)
        (pl.col('change_5d') >= 0.50).alias('E4_parabolic'),

        # E5: Breakout ATH
        (pl.col('close_d') >= pl.col('ath_252d')).alias('E5_breakout_ath'),

        # ... E7, E8, E10, E12-E17

        # Metadata: lista de eventos activos
        pl.when(pl.col('E0_info_rich')).then(pl.lit('E0')).otherwise(pl.lit(None)).alias('e0_flag'),
        pl.when(pl.col('E1_volume_explosion')).then(pl.lit('E1')).otherwise(pl.lit(None)).alias('e1_flag'),
        # ... agregar todos los flags
    ]).with_columns([
        # Consolidar eventos en una lista
        pl.concat_list(['e0_flag', 'e1_flag', 'e4_flag', ...])
          .list.drop_nulls()
          .alias('event_types'),

        # Calcular ventana m√°xima
        pl.when(pl.col('E4_parabolic')).then(pl.lit(6))
          .when(pl.col('E5_breakout_ath')).then(pl.lit(4))
          .when(pl.col('E1_volume_explosion')).then(pl.lit(4))
          .when(pl.col('E0_info_rich')).then(pl.lit(3))
          .otherwise(pl.lit(1))
          .alias('max_event_window')
    ])
```

#### Paso 2: Modificar `download_trades_optimized.py`

Agregar soporte para multi-eventos:

```python
def load_multi_event_days(watchlist_root: Path, dfrom: date, dto: date,
                          event_types: List[str], allowed_tickers: Optional[set]) -> Dict[str, List[date]]:
    """
    Lee watchlists multi-evento y expande seg√∫n ventana m√°xima por ticker-d√≠a.

    Args:
        event_types: ['E0', 'E1', 'E4'] - qu√© eventos descargar
        Si None, descarga TODOS los eventos encontrados
    """
    days_by_ticker = {}

    for watchlist_path in sorted(watchlist_root.glob('date=*/watchlist.parquet')):
        df = pl.read_parquet(watchlist_path)
        day = datetime.strptime(watchlist_path.parent.name.split('=')[1], '%Y-%m-%d').date()

        # Filtrar por eventos solicitados (si se especifican)
        if event_types:
            event_filter = pl.lit(False)
            for event_type in event_types:
                event_filter = event_filter | pl.col(f'{event_type}_event')
            df_events = df.filter(event_filter)
        else:
            # Cualquier ticker con al menos un evento activo
            df_events = df.filter(pl.col('event_types').list.len() > 0)

        # Expandir seg√∫n max_event_window de cada ticker-d√≠a
        for row in df_events.iter_rows(named=True):
            ticker = row['ticker']
            if allowed_tickers and ticker not in allowed_tickers:
                continue

            max_window = row['max_event_window']

            # Expandir ventana: [day - max_window, day, day + max_window]
            for offset in range(-max_window, max_window + 1):
                expanded_day = day + timedelta(days=offset)
                if expanded_day >= dfrom and expanded_day <= dto:
                    days_by_ticker.setdefault(ticker, []).append(expanded_day)

    # Deduplicar y ordenar fechas
    for ticker in days_by_ticker:
        days_by_ticker[ticker] = sorted(set(days_by_ticker[ticker]))

    return days_by_ticker

# Agregar argumento --event-types al argparse
ap.add_argument("--event-types", type=str, default=None,
                help="Comma-separated list de eventos a descargar (ej: 'E0,E1,E4'). "
                     "Si no se especifica, descarga TODOS los eventos detectados.")
```

#### Paso 3: Guardar Metadata de Eventos

Al descargar cada ticker-d√≠a, guardar metadata:

```python
def download_span_with_metadata(ticker: str, day: date, watchlist_data: dict, ...):
    """
    Descarga ticks + guarda metadata de eventos.
    """
    # ... descargar ticks como siempre ...

    # Guardar metadata de eventos
    events_json = {
        'ticker': ticker,
        'date': str(day),
        'events': watchlist_data['event_types'],  # ["E0", "E4"]
        'event_windows': {
            'E0': 3,
            'E4': 6
        },
        'max_window_used': watchlist_data['max_event_window']
    }

    events_path = day_path / 'events.json'
    with open(events_path, 'w') as f:
        json.dump(events_json, f, indent=2)
```

### 3.5 Estructura Final de Datos (Multi-Evento)

```
raw/polygon/trades/
‚îî‚îÄ‚îÄ BCRX/
    ‚îú‚îÄ‚îÄ date=2020-03-15/          ‚Üê Ventana pre-evento
    ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
    ‚îÇ   ‚îú‚îÄ‚îÄ _SUCCESS
    ‚îÇ   ‚îî‚îÄ‚îÄ events.json           ‚Üê {"events": ["E0", "E4"], "reason": "window"}
    ‚îú‚îÄ‚îÄ date=2020-03-16/          ‚Üê D√çA DEL EVENTO
    ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
    ‚îÇ   ‚îú‚îÄ‚îÄ _SUCCESS
    ‚îÇ   ‚îî‚îÄ‚îÄ events.json           ‚Üê {"events": ["E0", "E4"], "reason": "event_day"}
    ‚îú‚îÄ‚îÄ date=2020-03-17/          ‚Üê Ventana post-evento (day+1)
    ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
    ‚îÇ   ‚îú‚îÄ‚îÄ _SUCCESS
    ‚îÇ   ‚îî‚îÄ‚îÄ events.json           ‚Üê {"events": ["E0", "E4"], "reason": "window"}
    ‚îú‚îÄ‚îÄ date=2020-03-18/          ‚Üê Ventana extendida (E4 requiere hasta day+3)
    ‚îÇ   ‚îú‚îÄ‚îÄ trades.parquet
    ‚îÇ   ‚îú‚îÄ‚îÄ _SUCCESS
    ‚îÇ   ‚îî‚îÄ‚îÄ events.json           ‚Üê {"events": ["E4"], "reason": "window_E4"}
    ‚îî‚îÄ‚îÄ ...
```

### 3.6 Uso Downstream (Multi-Evento)

```python
import polars as pl
from pathlib import Path

# Cargar todos los eventos
watchlists = pl.scan_parquet('processed/universe/multi_event/daily/**/*.parquet')

# Filtrar por eventos de inter√©s
e0_and_e4_events = watchlists.filter(
    pl.col('E0_info_rich') & pl.col('E4_parabolic')
).collect()

print(f"Tickers con E0+E4 simult√°neos: {len(e0_and_e4_events)}")

# Cargar ticks para un evento
for row in e0_and_e4_events.head(10).iter_rows(named=True):
    ticker = row['ticker']
    event_date = row['trading_day']

    # Cargar ticks del d√≠a del evento
    ticks_path = f'raw/polygon/trades/{ticker}/date={event_date}/trades.parquet'
    if Path(ticks_path).exists():
        ticks = pl.read_parquet(ticks_path)
        print(f"{ticker} {event_date}: {len(ticks):,} ticks - Eventos: {row['event_types']}")
```

### 3.7 Resumen: Respuesta a "¬øD√≥nde se Guardar√°n los Otros E's?"

1. **Ahora mismo**: NO SE GUARDAN porque E1-E17 no est√°n implementados (solo E0 existe)

2. **Cuando los implementes** (recomendaci√≥n):
   - **Watchlists**: UN solo archivo diario con columnas booleanas por cada evento
   - **Ticks**: UN solo archivo por ticker-d√≠a (sin duplicados)
   - **Metadata**: `events.json` indica qu√© eventos aplican a cada ticker-d√≠a
   - **Sin duplicaci√≥n**: Si BCRX tiene E0+E1+E4 el 2020-03-16 ‚Üí un solo `trades.parquet`

3. **Beneficios**:
   - Eficiencia de storage (~3-5x menos espacio)
   - An√°lisis downstream simplificado
   - Trazabilidad completa (metadata en JSON)
   - Flexible: puedes filtrar por cualquier combinaci√≥n de eventos

---

## 4. COMANDOS R√ÅPIDOS (RESUMEN)

```bash
# PASO 0: SCD-2 - DEPRECADO (solo cubre 2025-10-19‚Üí)
# NO ejecutar

# PASO 1: Cach√© diario (SIN market_cap)
python scripts/fase_C_ingesta_tiks/build_daily_cache.py \
  --intraday-root raw/polygon/ohlcv_intraday_1m \
  --outdir processed/daily_cache \
  --from 2004-01-01 --to 2025-10-21 \
  --parallel 8
  # SIN --cap-filter-parquet

# PASO 2: Actualizar config (remover cap_max)
# Editar: configs/universe_config.yaml
# Comentar o eliminar: cap_max: 2_000_000_000

# PASO 3: Universo E0 (sin filtro market_cap)
python scripts/fase_C_ingesta_tiks/build_dynamic_universe_optimized.py \
  --daily-cache processed/daily_cache \
  --outdir processed/universe/info_rich \
  --from 2004-01-01 --to 2025-10-21 \
  --config configs/universe_config.yaml

# PASO 4: Verificaci√≥n (script a crear)
python scripts/fase_C_ingesta_tiks/verify_inclusion_C_v1_vs_E0.py \
  --c_v1-watchlists processed/universe/info_rich_v1/daily \
  --e0-watchlists processed/universe/info_rich/daily \
  --from 2020-01-01 --to 2025-10-21 \
  --outdir audits

# PASO 5: Descarga ticks
python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --tickers-csv processed/universe/info_rich/topN_12m.csv \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

---

## 5. NOTAS FINALES

### Validaci√≥n conceptual
Este plan ejecuta la estrategia documentada en Contrato_E0.md v2.0.0:
- ‚úÖ E0 como "pegamento legal" entre C_v1 y C_v2
- ‚úÖ Filtros coherentes con mandato Small/MicroCap
- ‚úÖ Documentaci√≥n de diferencias C_v1 vs E0
- ‚úÖ Trazabilidad completa de exclusiones/inclusiones

### Garant√≠a de coherencia
- Pipeline √∫nico unificado (no C_v1 + C_v2 separados)
- Versionado formal (Contrato v2.0.0)
- Auditor√≠a emp√≠rica de inclusi√≥n
- Justificaci√≥n documentada de diferencias

### Escalabilidad a 21 a√±os
- SCD-2 para market cap hist√≥rico correcto
- Join temporal evita survivorship bias
- Watchlists por d√≠a permiten descarga selectiva
- Resume tolerance para ejecuciones largas

### Listo para ML
- Features pre-calculadas (rvol30, pctchg_d)
- Ticks listos para barras informativas
- Etiquetas por evento (E0, E1, ..., E13)
- Particionado por r√©gimen macro

---

**Documento creado**: 2025-10-25
**Autor**:  Alex Just Rodriguez
**Versi√≥n**: 1.0.0
**Basado en**: Contrato_E0.md v2.0.0
**Status**: LISTO PARA EJECUCI√ìN

**FIN DEL PLAN DE EJECUCI√ìN**
