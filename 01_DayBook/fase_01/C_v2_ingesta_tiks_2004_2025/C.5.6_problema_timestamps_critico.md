# C.5.6 - Problema Cr√≠tico: Timestamps Corruptos en PASO 5

**Fecha**: 2025-10-27
**Estado**: üî¥ CR√çTICO - RE-DESCARGA NECESARIA
**Impacto**: TODO el dataset E0 (67,439 archivos) puede estar corrupto
**Decisi√≥n**: Arreglar downloader y re-descargar ANTES de continuar con multi-evento

---

## √çNDICE

1. [Problema Identificado](#1-problema-identificado)
2. [Evidencia del Problema](#2-evidencia-del-problema)
3. [Causa Ra√≠z](#3-causa-ra√≠z)
4. [Impacto y Consecuencias](#4-impacto-y-consecuencias)
5. [Soluci√≥n Propuesta](#5-soluci√≥n-propuesta)
6. [Plan de Acci√≥n](#6-plan-de-acci√≥n)
7. [Verificaci√≥n Post-Fix](#7-verificaci√≥n-post-fix)

---

## 1. PROBLEMA IDENTIFICADO

### 1.1 Descripci√≥n

Durante validaci√≥n de **Track B (Prototipo DIB/VIB)**, se detect√≥ que m√∫ltiples archivos de ticks descargados tienen **timestamps corruptos** que causan error:

```
ValueError: year 52156 is out of range
```

### 1.2 Archivos Afectados (Confirmados)

```
raw/polygon/trades/BCRX/date=2020-03-09/trades.parquet  ‚ùå year 52156
raw/polygon/trades/BCRX/date=2020-01-27/trades.parquet  ‚ùå year 52041
raw/polygon/trades/VXRT/date=2020-03-17/trades.parquet  ‚ùå year 52178
```

### 1.3 Archivos que Funcionan (Aparentemente)

```
raw/polygon/trades/BCRX/date=2020-06-26/trades.parquet  ‚úÖ OK
raw/polygon/trades/BCRX/date=2020-12-04/trades.parquet  ‚úÖ OK
```

### 1.4 Tasa de Error Inicial

**Validaci√≥n v2**: 2/10 archivos OK (20% √©xito)
- 2 SUCCESS
- 3 ERROR (timestamps corruptos)
- 5 SKIP (archivos no existen)

---

## 2. EVIDENCIA DEL PROBLEMA

### 2.1 Error en Polars

```python
df = pl.read_parquet("raw/polygon/trades/BCRX/date=2020-03-09/trades.parquet")
ts_min = str(df['t'].min())

# ERROR:
# ValueError: year 52156 is out of range
```

### 2.2 Schema del Archivo

```python
Schema({
    't': Datetime(time_unit='us', time_zone=None),  # ‚Üê PROBLEMA AQU√ç
    'p': Float64,
    's': Int64,
    ...
})
```

**Problema**: Polars intenta convertir timestamps a `Datetime` con `time_unit='us'` (microsegundos), pero algunos valores no est√°n en esa escala, causando fechas imposibles (a√±o 52XXX).

### 2.3 Intentos de Lectura

```python
# Intento 1: Leer todo
df = pl.read_parquet(path)  # ‚ùå CRASH: year 52156

# Intento 2: Leer sin timestamp
df = pl.read_parquet(path, columns=['p', 's'])  # ‚úÖ FUNCIONA pero perdemos timestamps

# Intento 3: Convertir a dict
df['t'].min()  # ‚ùå CRASH al intentar convertir a Python datetime
```

---

## 3. CAUSA RA√çZ

### 3.1 Hip√≥tesis Principal

**El script `download_trades_optimized.py` est√° escribiendo timestamps de forma inconsistente.**

**Posibles causas:**

1. **Polygon API devuelve timestamps en diferentes escalas**:
   - Algunos d√≠as: nanosegundos (`ns`) ~ 1e18
   - Otros d√≠as: microsegundos (`us`) ~ 1e15
   - Otros d√≠as: milisegundos (`ms`) ~ 1e12

2. **El downloader asume siempre `time_unit='us'`**:
   ```python
   # ACTUAL (MAL):
   df = df.with_columns([
       pl.col('t').cast(pl.Datetime(time_unit='us'))
   ])
   ```

3. **Cuando el timestamp viene en nanosegundos pero se guarda como microsegundos**:
   - Valor real: `1584010800000000000` (ns, 2020-03-09)
   - Interpretado como: `1584010800000000` (us) ‚Üí a√±o 52156 ‚ùå

### 3.2 Por Qu√© Algunos Funcionan

Los archivos que "funcionan" (2020-06-26, 2020-12-04) pueden:
- Tener timestamps que **casualmente** coinciden en la escala correcta
- Venir de un endpoint diferente de Polygon que s√≠ usa `us`
- Ser de un per√≠odo donde Polygon cambi√≥ el formato

**IMPORTANTE**: No hay garant√≠a de sanidad en NING√öN archivo sin verificaci√≥n.

### 3.3 Impacto Sist√©mico

**Si 3/10 archivos fallan**, esto sugiere que:
- ‚ùå NO es un problema local de "3 d√≠as malos"
- ‚ùå ES un problema estructural del downloader
- ‚ùå Probablemente **TODOS los 67,439 archivos** tienen riesgo de timestamps mal interpretados

---

## 4. IMPACTO Y CONSECUENCIAS

### 4.1 Impacto Inmediato

**Track B (DIB/VIB)**:
- ‚ùå No podemos construir barras informativas sin timestamps
- ‚ùå Algoritmo L√≥pez de Prado requiere timestamps para ordenar ticks
- ‚ùå Features de microestructura requieren time deltas

**Validaci√≥n**:
- ‚ùå No podemos validar que el pipeline funciona
- ‚ùå No sabemos si los archivos que "funcionan" est√°n realmente bien

### 4.2 Impacto en Multi-Evento (Track A)

Si continuamos sin arreglar:

1. **Implementamos detectores E1-E8**: ‚úÖ No dependen de timestamps microestructura
2. **Descargamos E1-E13 adicionales**: ‚ùå Con el mismo bug ‚Üí +3-5 TB corruptos
3. **Construimos DIB/VIB**: ‚ùå Falla por timestamps corruptos
4. **RE-DESCARGA NECESARIA**: ‚ùå 3-5 TB a descargar de nuevo (semanas de trabajo)

### 4.3 Consecuencias de NO Arreglar Ahora

```
Timeline si NO arreglamos:

SEMANA 1-2: Detectores E1-E8 ‚úÖ
SEMANA 3-4: Descarga E1-E13 (+3-5 TB) ‚ùå Con bug
SEMANA 5: Intentar DIB/VIB ‚ùå Falla por timestamps
SEMANA 6: Descubrir problema sist√©mico
SEMANA 7-9: RE-DESCARGAR TODO (+20 TB total)

TOTAL: ~9 semanas, ~20 TB descargados 2 veces
```

```
Timeline si S√ç arreglamos:

HOY: Fix downloader (30 min)
HOY: Re-descargar E0 (1-2 horas, 16 GB)
MA√ëANA: Validar DIB/VIB ‚úÖ
SEMANA 1-2: Detectores + DIB/VIB ‚úÖ
SEMANA 3-4: Descarga E1-E13 limpia ‚úÖ
SEMANA 5: DIB/VIB sobre dataset completo ‚úÖ

TOTAL: ~5 semanas, ~20 GB descargados 1 vez
```

**Decisi√≥n obvia**: Arreglar ahora ahorra 4 semanas y terabytes de re-trabajo.

---

## 5. SOLUCI√ìN PROPUESTA

### 5.1 Modificaci√≥n del Downloader

**Archivo**: `scripts/fase_C_ingesta_tiks/download_trades_optimized.py`

**CAMBIO PRINCIPAL**: Guardar timestamps como **INT64 crudo** (sin conversi√≥n a Datetime)

#### Antes (Malo):
```python
# Asume siempre time_unit='us'
df = df.with_columns([
    pl.col('t').cast(pl.Datetime(time_unit='us'))
])
df.write_parquet(output_path)
```

#### Despu√©s (Correcto):
```python
# Guardar timestamp crudo como INT64
df = df.with_columns([
    pl.col('t').cast(pl.Int64).alias('t_raw')
])

# Detectar escala temporal
max_ts = int(df['t_raw'].max())
if max_ts > 1_000_000_000_000_000_000:
    time_unit = "ns"  # nanosegundos
elif max_ts > 1_000_000_000_000_000:
    time_unit = "us"  # microsegundos
else:
    time_unit = "ms"  # milisegundos

# Guardar escala como metadato
df = df.with_columns([
    pl.lit(time_unit).alias('t_unit')
])

# Escribir (sin datetime, solo ints)
df.write_parquet(output_path)
```

### 5.2 Ventajas de Esta Soluci√≥n

1. ‚úÖ **Sin conversiones peligrosas**: No intentamos interpretar timestamps en descarga
2. ‚úÖ **Trazabilidad completa**: Guardamos timestamp original de Polygon sin modificar
3. ‚úÖ **Metadata de escala**: Columna `t_unit` indica si es `ns`, `us`, o `ms`
4. ‚úÖ **Legible universalmente**: INT64 + String funcionan en cualquier Polars
5. ‚úÖ **Conversi√≥n posterior**: Transformamos a Datetime solo cuando realmente lo necesitemos

### 5.3 Schema Nuevo (Correcto)

```python
# NUEVO schema guardado:
Schema({
    't_raw': Int64,          # Timestamp crudo (microsegundos o nanosegundos)
    't_unit': String,        # "us" o "ns" (detectado autom√°ticamente)
    'p': Float64,            # Precio
    's': Int64,              # Size
    'c': List(Int64),        # Conditions
    'x': Int64,              # Exchange
    'z': Int64,              # Tape
    ...
})
```

### 5.4 Uso Posterior

Cuando necesitemos timestamps como Datetime (ej: DIB/VIB):

```python
# Leer archivo
df = pl.read_parquet(path)

# Convertir seg√∫n escala detectada
if df['t_unit'][0] == "ns":
    df = df.with_columns([
        pl.col('t_raw').cast(pl.Datetime(time_unit='ns')).alias('t')
    ])
elif df['t_unit'][0] == "us":
    df = df.with_columns([
        pl.col('t_raw').cast(pl.Datetime(time_unit='us')).alias('t')
    ])

# Ahora 't' est√° en formato correcto
```

---

## 6. PLAN DE ACCI√ìN

### PASO 1: Parar Descarga Actual ‚úÖ

**Status**: No hay descarga en curso (PASO 5 completado)

### PASO 2: Backup Dataset Actual (Opcional)

```bash
cd D:/04_TRADING_SMALLCAPS

# Opcional: Backup por si acaso
mv raw/polygon/trades raw/polygon/trades_OLD_CORRUPTED_20251027
```

### PASO 3: Aplicar Fix al Downloader

**Archivo a modificar**: `scripts/fase_C_ingesta_tiks/download_trades_optimized.py`

**Buscar funci√≥n** (aproximadamente l√≠nea 150-250):
```python
def download_ticker_day(...):
    # ...
    df = pl.DataFrame(trades_data)

    # BUSCAR ESTA SECCI√ìN:
    df.write_parquet(output_path)  # ‚Üê MODIFICAR AQU√ç
```

**Reemplazar con**:
```python
def download_ticker_day(...):
    # ...
    df = pl.DataFrame(trades_data)

    # FIX: Guardar timestamps como INT64 crudo
    if 't' in df.columns:
        df = df.with_columns([
            pl.col('t').cast(pl.Int64).alias('t_raw')
        ])

        # Detectar escala
        max_ts = int(df['t_raw'].max())
        time_unit = "ns" if max_ts > 1e17 else "us"

        df = df.with_columns([
            pl.lit(time_unit).alias('t_unit')
        ])

    df.write_parquet(output_path)
```

**Commit del fix**:
```bash
git add scripts/fase_C_ingesta_tiks/download_trades_optimized.py
git commit -m "fix: Save timestamps as Int64 to avoid corruption (year 52XXX error)

- Save 't' as 't_raw' (Int64) without datetime conversion
- Add 't_unit' column to track if timestamps are ns/us/ms
- Avoids Polars datetime conversion errors
- Enables proper timestamp handling in downstream processing"
```

### PASO 4: Borrar Dataset Corrupto

```bash
cd D:/04_TRADING_SMALLCAPS

# Borrar todo
rm -rf raw/polygon/trades/*

# Verificar vac√≠o
find raw/polygon/trades -name "*.parquet" | wc -l
# Output esperado: 0
```

### PASO 5: Re-Descargar E0 con Downloader Corregido

**Terminal 1** (Descarga):
```bash
cd D:/04_TRADING_SMALLCAPS

python scripts/fase_C_ingesta_tiks/download_trades_optimized.py \
  --watchlist-root processed/universe/info_rich/daily \
  --outdir raw/polygon/trades \
  --from 2004-01-01 --to 2025-10-21 \
  --mode watchlists \
  --event-window 1 \
  --page-limit 50000 \
  --rate-limit 0.15 \
  --workers 8 \
  --resume
```

**Terminal 2** (Monitor):
```bash
cd D:/04_TRADING_SMALLCAPS

# Esperar 2-3 minutos
python scripts/monitor_download_health.py
```

**Tiempo estimado**: 1-2 horas (ya lo hiciste antes)

### PASO 6: Validaci√≥n Post-Descarga

```bash
# Spot check de muestra aleatoria
python scripts/spot_check_timestamps.py

# Resultado esperado:
# OK: 20/20 (100.0%)
# [OK] All sampled files have correct timestamps!
```

### PASO 7: Actualizar Prototipo DIB/VIB

**Archivo**: `scripts/fase_D_barras/prototype_dib_vib_v3.py`

**Cambios**:
1. Arreglar `cumsum()` ‚Üí `cum_sum()` (API Polars)
2. Actualizar lectura de timestamps:

```python
# Cambiar l√≠nea ~108:
df_ticks = pl.read_parquet(ticks_path, columns=['t_raw', 't_unit', 'p', 's'])

# En build_simple_dib(), agregar timestamps:
bars = df.group_by('bar_id').agg([
    pl.col('t_raw').min().alias('bar_start_ts'),
    pl.col('t_raw').max().alias('bar_end_ts'),
    pl.col('p').first().alias('open'),
    # ...
])
```

### PASO 8: Validaci√≥n DIB/VIB Final

```bash
python scripts/fase_D_barras/prototype_dib_vib_v3.py

# Resultado esperado:
# SUCCESS: 10/12 ticker-days (83%+)
# [OK] VALIDACION EXITOSA
# [OK] Timestamps issue RESUELTO
# [OK] Pipeline estable - listo para escalar
```

---

## 7. VERIFICACI√ìN POST-FIX

### 7.1 Criterios de √âxito

- ‚úÖ **Downloader corregido**: Guarda `t_raw` (Int64) y `t_unit` (String)
- ‚úÖ **Re-descarga completa**: 67,439 archivos sin errores
- ‚úÖ **Spot check**: 100% archivos validados tienen timestamps correctos
- ‚úÖ **Monitor en vivo**: >90% OK durante descarga
- ‚úÖ **Prototipo DIB/VIB**: >70% ticker-days procesados sin crashes
- ‚úÖ **Sin errores "year 52XXX"**: Ning√∫n archivo con timestamps corruptos

### 7.2 Validaci√≥n Exhaustiva (Post Re-descarga)

```bash
# Script de validaci√≥n completa
python << 'EOF'
import polars as pl
from pathlib import Path

trades_dir = Path("raw/polygon/trades")
all_parquets = list(trades_dir.rglob("trades.parquet"))

print(f"Validando {len(all_parquets):,} archivos...")

errors = []
for pq in all_parquets:
    try:
        df = pl.read_parquet(pq)

        # Check 1: tiene t_raw?
        if 't_raw' not in df.columns:
            errors.append((str(pq), "missing_t_raw"))
            continue

        # Check 2: t_raw es Int64?
        if df['t_raw'].dtype != pl.Int64:
            errors.append((str(pq), f"t_raw is {df['t_raw'].dtype}"))
            continue

        # Check 3: valores en rango v√°lido?
        max_ts = int(df['t_raw'].max())
        if not (9e14 < max_ts < 2e18):
            errors.append((str(pq), f"timestamp out of range: {max_ts}"))

    except Exception as e:
        errors.append((str(pq), str(e)))

if len(errors) == 0:
    print(f"\n‚úÖ ALL {len(all_parquets):,} FILES VALIDATED")
    print("‚úÖ No timestamp corruption detected")
else:
    print(f"\n‚ùå {len(errors)} FILES WITH ISSUES:")
    for path, err in errors[:10]:
        print(f"  - {path}: {err}")
EOF
```

### 7.3 Documentaci√≥n Actualizada

Una vez validado:

1. ‚úÖ Actualizar `C.5_plan_ejecucion_E0_descarga_ticks.md`:
   - Marcar PASO 5 como "RE-EJECUTADO (timestamps corregidos)"
   - Agregar nota sobre fix aplicado

2. ‚úÖ Crear `C.5.7_resultados_paso_5_v2.md`:
   - Documentar re-descarga
   - M√©tricas finales con timestamps corregidos

3. ‚úÖ Commit consolidado:
```bash
git add -A
git commit -m "fix: Complete PASO 5 re-download with corrected timestamps

- Fixed download_trades_optimized.py to save t_raw (Int64)
- Re-downloaded all E0 ticks (67,439 files, 16.58 GB)
- Validated: 100% files have correct timestamps
- No more 'year 52XXX' errors
- DIB/VIB prototype now works on corrected data"
git push
```

---

## 8. LECCIONES APRENDIDAS

### 8.1 Detecci√≥n Temprana

‚úÖ **BUENO**: Detectamos el problema en validaci√≥n (Track B) ANTES de descargar +3 TB adicionales

‚ùå **MALO**: Validaci√≥n debi√≥ ejecutarse INMEDIATAMENTE despu√©s de PASO 5, no despu√©s

### 8.2 Validaci√≥n Exhaustiva

**Aprendizaje**: SIEMPRE validar archivos descargados ANTES de continuar al siguiente paso

**Implementaci√≥n**: Agregar `spot_check_timestamps.py` como parte obligatoria del PASO 5

### 8.3 No Asumir Formatos

**Aprendizaje**: APIs externas (Polygon) pueden devolver datos en formatos inconsistentes

**Soluci√≥n**: Guardar datos crudos (Int64) sin interpretaci√≥n, convertir solo cuando necesario

### 8.4 Costo de Re-trabajo

**Inversi√≥n ahora**: 3 horas (fix + re-descarga + validaci√≥n)
**Ahorro futuro**: 4 semanas + 20 TB re-descarga

**ROI**: 500:1 (invertir ahora es obvio)

---

## 9. ESTADO ACTUAL Y PR√ìXIMOS PASOS

### 9.1 Estado Actual (2025-10-27 23:00)

- üî¥ **PASO 5**: Dataset E0 actual (67,439 archivos) tiene timestamps corruptos
- ‚úÖ **Scripts de validaci√≥n**: Creados (`monitor_download_health.py`, `spot_check_timestamps.py`)
- ‚è∏Ô∏è **Track B (DIB/VIB)**: Pausado hasta re-descarga
- ‚è∏Ô∏è **Track A (Detectores)**: Pausado (decisi√≥n correcta: arreglar base primero)

### 9.2 Pr√≥ximos Pasos Inmediatos

**HOY (2025-10-27)**:
1. ‚úÖ Documentar problema (este documento)
2. ‚è≥ Aplicar fix a `download_trades_optimized.py`
3. ‚è≥ Re-descargar E0 completo (1-2 horas)
4. ‚è≥ Validar con spot check

**MA√ëANA (2025-10-28)**:
1. ‚úÖ Validar DIB/VIB prototype sobre datos corregidos
2. ‚úÖ Continuar Track A + Track B en paralelo
3. ‚úÖ Implementar detectores E1-E8

### 9.3 Roadmap Actualizado

```
SEMANA 1 (actual):
‚úÖ PASO 1-4 completados
‚è≥ PASO 5 RE-DESCARGA (en curso)
‚è≥ Track B validaci√≥n DIB/VIB

SEMANA 2:
‚úÖ Track A: Detectores E1-E8
‚úÖ Track B: DIB/VIB sobre E0 limpio

SEMANA 3-4:
‚úÖ Descarga E1-E13 (con timestamps correctos)
‚úÖ Dataset maestro multi-evento

SEMANA 5+:
‚úÖ Triple barrier labeling
‚úÖ ML pipeline
```

---

## CONCLUSI√ìN

**Problema identificado a tiempo**: Timestamps corruptos en downloader

**Decisi√≥n correcta**: Arreglar ahora y re-descargar ANTES de continuar

**Impacto**: Ahorra 4 semanas y terabytes de re-trabajo futuro

**Estado**: Documentado, fix listo para aplicar, validaci√≥n preparada

**Pr√≥ximo paso**: Aplicar fix y re-descargar (ejecutar PASO 3 del Plan de Acci√≥n)

---

**Documento creado**: 2025-10-27 23:30
**Autor**: Alex Just Rodriguez + Claude (Anthropic)
**Versi√≥n**: 1.0.0
**Status**: üî¥ CR√çTICO - ACCI√ìN REQUERIDA

**FIN DE C.5.6**
