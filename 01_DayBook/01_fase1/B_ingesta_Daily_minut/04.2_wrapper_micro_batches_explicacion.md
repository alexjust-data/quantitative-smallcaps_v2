# Wrapper Micro-Batches: Explicaci√≥n Completa

## ¬øQu√© es "wrapper micro-batches"?

El "wrapper micro-batches" es un **patr√≥n de arquitectura** que resuelve los problemas de memoria y estabilidad cuando descargas datos masivos. En lugar de tener procesos de larga duraci√≥n que pueden acumular memoria y colgarse, usas **procesos desechables** que viven poco tiempo y mueren al terminar.

---

## Comparaci√≥n Visual: Launcher vs Wrapper

### LAUNCHER (launch_intraday_windows.py)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LAUNCHER                                                 ‚îÇ
‚îÇ divide 3,107 tickers en 12 shards ‚Üí 12 procesos         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Worker 0         ‚îÇ Worker 1         ‚îÇ ...Worker 11     ‚îÇ
    ‚îÇ 259 tickers      ‚îÇ 259 tickers      ‚îÇ 259 tickers      ‚îÇ
    ‚îÇ PROCESO VIVO     ‚îÇ PROCESO VIVO     ‚îÇ PROCESO VIVO     ‚îÇ
    ‚îÇ DURANTE HORAS    ‚îÇ DURANTE HORAS    ‚îÇ DURANTE HORAS    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                    ‚Üì                    ‚Üì
      Procesa              Procesa              Procesa
      secuencialmente      secuencialmente      secuencialmente
      los 259 tickers      los 259 tickers      los 259 tickers

      SI FALLA en ticker 50 ‚Üí puede que muera sin procesar los 209 restantes
      Acumula RAM durante horas ‚Üí puede quedarse sin memoria
      Conexiones TLS abiertas durante horas ‚Üí pueden corromperse
```

**Problemas del Launcher:**
- ‚úó Procesos viven demasiado tiempo (horas)
- ‚úó Acumulan memoria gradualmente
- ‚úó Si un ticker problem√°tico mata el proceso, pierdes todos los pendientes
- ‚úó Dif√≠cil diagnosticar qu√© ticker caus√≥ el problema
- ‚úó Conexiones TLS pueden corromperse con el tiempo

---

### WRAPPER (batch_intraday_wrapper.py)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ WRAPPER                                                  ‚îÇ
‚îÇ divide 3,107 tickers en ~124 batches de 25 cada uno     ‚îÇ
‚îÇ ejecuta M√ÅXIMO 6 batches en paralelo                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Batch 0          ‚îÇ Batch 1          ‚îÇ ... Batch 5      ‚îÇ
    ‚îÇ 25 tickers       ‚îÇ 25 tickers       ‚îÇ 25 tickers       ‚îÇ
    ‚îÇ PROCESO          ‚îÇ PROCESO          ‚îÇ PROCESO          ‚îÇ
    ‚îÇ DESECHABLE       ‚îÇ DESECHABLE       ‚îÇ DESECHABLE       ‚îÇ
    ‚îÇ vive ~10-30 min  ‚îÇ vive ~10-30 min  ‚îÇ vive ~10-30 min  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                    ‚Üì                    ‚Üì
      Termina ‚Üí MUERE     Termina ‚Üí MUERE     Termina ‚Üí MUERE
      Libera RAM          Libera RAM          Libera RAM
      Cierra sockets      Cierra sockets      Cierra sockets
                        ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Batch 6          ‚îÇ Batch 7          ‚îÇ ... Batch 11     ‚îÇ
    ‚îÇ NUEVO PROCESO    ‚îÇ NUEVO PROCESO    ‚îÇ NUEVO PROCESO    ‚îÇ
    ‚îÇ RAM LIMPIA       ‚îÇ RAM LIMPIA       ‚îÇ RAM LIMPIA       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Ventajas del Wrapper:**
- ‚úì Procesos viven poco (~10-30 min)
- ‚úì Al morir, liberan TODA la RAM autom√°ticamente
- ‚úì Si falla un batch, solo pierdes 25 tickers (no 259)
- ‚úì Cada batch tiene su propio log ‚Üí f√°cil diagn√≥stico
- ‚úì Conexiones TLS frescas en cada batch
- ‚úì Reintento autom√°tico por batch (hasta 2 intentos)
- ‚úì Control de concurrencia (solo 6 batches a la vez)

---

## ¬øC√≥mo Funciona el Wrapper en Detalle?

### 1. Dividir tickers en batches

```python
# Universo: 3,107 tickers
# batch_size = 25
# ‚Üí Resultado: 124 batches

batches = chunk_list(tickers, args.batch_size)
# batch[0]   = [AAPL, MSFT, ..., TSLA]     (25 tickers)
# batch[1]   = [NVDA, AMD,  ..., INTC]     (25 tickers)
# ...
# batch[123] = [ZZZ, YYY, ...]             (7 tickers) ‚Üê √∫ltimo batch puede ser menor
```

### 2. Ejecutar batches con paralelismo controlado

```python
# max_concurrent = 6  ‚Üí  solo 6 procesos simult√°neos
with ThreadPoolExecutor(max_workers=6) as ex:
    # Lanza los 124 batches, pero solo 6 corren a la vez
    futs = {ex.submit(run_batch, i, b, args, ...): i for i, b in enumerate(batches)}
```

**Flujo de ejecuci√≥n:**
```
[Batch 0] [Batch 1] [Batch 2] [Batch 3] [Batch 4] [Batch 5]  ‚Üê 6 corriendo

Batch 2 termina ‚Üí MUERE
                ‚Üì
[Batch 0] [Batch 1] [Batch 6] [Batch 3] [Batch 4] [Batch 5]  ‚Üê Batch 6 toma su lugar

Batch 0 termina ‚Üí MUERE
    ‚Üì
[Batch 7] [Batch 1] [Batch 6] [Batch 3] [Batch 4] [Batch 5]  ‚Üê Batch 7 toma su lugar

... y as√≠ hasta completar los 124 batches
```

### 3. Cada batch = 1 subproceso del ingestor

```python
def run_batch(batch_id, tickers, ...):
    # 1. Crea CSV temporal con los 25 tickers de este batch
    csv_path = temp_dir / f"batch_{batch_id:04d}.csv"
    pl.DataFrame({"ticker": tickers}).write_csv(csv_path)

    # 2. Lanza subproceso del ingestor
    cmd = [
        sys.executable, "ingest_ohlcv_intraday_minute.py",
        "--tickers-csv", str(csv_path),
        "--outdir", args.outdir,
        "--from", args.date_from,
        "--to", args.date_to,
        "--rate-limit", str(args.rate_limit),
        "--max-tickers-per-process", str(len(tickers)),  # ‚Üê CLAVE: 25
    ]

    # 3. Ejecuta y captura log
    log_path = temp_dir / f"batch_{batch_id:04d}.log"
    proc = subprocess.run(cmd, stdout=log_file, stderr=subprocess.STDOUT)

    # 4. Proceso termina ‚Üí muere ‚Üí RAM liberada
    # 5. Retorna c√≥digo de salida
    return (batch_id, "success" if proc.returncode == 0 else "failed", elapsed)
```

### 4. El ingestor procesa su batch y MUERE

Dentro de `ingest_ohlcv_intraday_minute.py`:

```python
# args.max_tickers_per_process = 25
tickers = ["AAPL", "MSFT", ..., "TSLA"]  # 25 tickers del CSV

for t in tickers:
    fetch_and_stream_write(session, api_key, t, ...)
    processed += 1

    # Checkpoint cada 25 tickers ‚Üí en este caso, al finalizar
    if processed % 25 == 0:
        log(f"Progreso {processed}/{len(tickers)}")

    # Cuando proces√≥ todos sus tickers, sale limpio
    if args.max_tickers_per_process and processed >= args.max_tickers_per_process:
        log(f"Alcanzado --max-tickers-per-process={args.max_tickers_per_process}. Saliendo.")
        break  # ‚Üê SALE DEL SCRIPT

# Script termina ‚Üí proceso muere ‚Üí Python garbage collector libera TODA la RAM
```

---

## Reintentos Autom√°ticos y Manejo de Errores

### ¬øQu√© pasa si un batch falla?

El wrapper implementa **reintentos autom√°ticos a nivel de batch**:

```python
def run_batch(batch_id, tickers, ..., tries: int = 2):
    """
    Reintenta hasta 'tries' veces si el exit code != 0.
    """
    attempt = 0
    rc = 1  # c√≥digo de retorno (0 = √©xito, != 0 = error)

    while attempt < tries:
        attempt += 1
        with open(log_path, "a") as lf:
            lf.write(f"== BATCH {batch_id:04d} attempt {attempt}/{tries} ==\n")
            proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT)
            rc = proc.returncode

        if rc == 0:
            break  # ‚úì √âxito ‚Üí sale del loop

        time.sleep(3)  # Espera 3s antes de reintentar

    # Si despu√©s de 2 intentos sigue fallando ‚Üí marca como failed
    status = "success" if rc == 0 else f"failed(rc={rc})"
    return (batch_id, status, elapsed)
```

### Escenarios concretos:

#### ‚úì Escenario 1: Batch exitoso al primer intento
```
Batch 0 (25 tickers): AAPL, MSFT, ..., TSLA
  Attempt 1/2: Descarga OK ‚Üí exit code 0
  ‚úì Marcado como SUCCESS
  ‚Üí Contin√∫a con Batch 1
```

#### ‚úì Escenario 2: Batch falla por SSL, reintenta y tiene √©xito
```
Batch 5 (25 tickers): NVDA, AMD, ..., INTC
  Attempt 1/2: SSL error ‚Üí exit code 1
  (espera 3s)
  Attempt 2/2: Descarga OK ‚Üí exit code 0
  ‚úì Marcado como SUCCESS
  ‚Üí Contin√∫a con siguiente batch
```

#### ‚úó Escenario 3: Batch falla ambos intentos
```
Batch 12 (25 tickers): XYZ, ABC, ..., DEF
  Attempt 1/2: Timeout ‚Üí exit code 1
  (espera 3s)
  Attempt 2/2: Timeout ‚Üí exit code 1
  ‚úó Marcado como FAILED(rc=1)
  ‚Üí Log guardado en batch_0012.log
  ‚Üí Contin√∫a con siguiente batch (no detiene todo el proceso)
```

### ¬øQu√© pasa si un ticker se cuelga indefinidamente?

**Dentro del ingestor** (`ingest_ohlcv_intraday_minute.py`), cada request tiene timeout:

```python
TIMEOUT = 40  # segundos
r = session.get(url, params=params, headers=headers, timeout=TIMEOUT)
```

Si un ticker se cuelga:
1. Despu√©s de 40 segundos ‚Üí `requests.exceptions.Timeout`
2. El ingestor **captura la excepci√≥n** y contin√∫a:
   ```python
   for t in tickers:
       try:
           res = fetch_and_stream_write(session, api_key, t, ...)
           results.append(res)
       except Exception as e:
           results.append(f"{t}: ERROR {e}")  # ‚Üê Marca como error pero CONTIN√öA
       processed += 1
   ```
3. El batch **no se cuelga** ‚Üí procesa los 24 tickers restantes
4. Al final, el batch sale con exit code 0 (√©xito parcial)

**Pero:** Si el ticker tiene un bug que causa un **hang total** (no timeout, sino freeze del proceso):
- El batch se quedar√≠a colgado indefinidamente
- El wrapper **no tiene timeout a nivel de batch** actualmente
- Ese batch ocupar√≠a 1 de los 6 slots de concurrencia
- Los otros 5 slots seguir√≠an procesando normalmente

**Soluci√≥n recomendada** (no implementada a√∫n):
```python
# En run_batch(), usar subprocess con timeout
proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT,
                     text=True, timeout=3600)  # ‚Üê 1 hora max por batch
```

---

## ¬øSe auto-ejecuta hasta completar el 100% de tickers?

### Respuesta corta: NO autom√°ticamente, pero casi.

El wrapper garantiza:
- ‚úì Procesa **todos** los 124 batches (no se detiene si uno falla)
- ‚úì Cada batch reintenta hasta 2 veces autom√°ticamente
- ‚úó Si un batch falla 2 veces ‚Üí esos 25 tickers quedan como FAILED
- ‚úó **No** reintenta infinitamente (evita loops eternos)

### Ejemplo de ejecuci√≥n completa:

```
Total batches: 124
Ejecutando...

Batch 0000: success (45.3s) | Progreso 1/124 = 0.8%
Batch 0001: success (52.1s) | Progreso 2/124 = 1.6%
...
Batch 0012: failed(rc=1) (180.5s) | Progreso 13/124 = 10.5%  ‚Üê Fall√≥ despu√©s de 2 intentos
...
Batch 0123: success (48.7s) | Progreso 124/124 = 100.0%

================================================================
‚úì COMPLETADO: 122/124 batches OK | 2 fallidos
‚è±Ô∏è Tiempo total: 8.45 h
üßæ Logs por batch: raw/polygon/ohlcv_intraday_1m/_batch_temp/
================================================================
```

**Resultado:**
- 122 batches √ó 25 tickers = 3,050 tickers ‚úì completados
- 2 batches √ó 25 tickers = 50 tickers ‚úó fallidos
- **Total procesado: 98.4%** (no 100%, pero cercano)

### Para alcanzar el 100%:

**Opci√≥n 1: Reintentar manualmente los batches fallidos**
```bash
# Revisar logs de batches fallidos
cat raw/polygon/ohlcv_intraday_1m/_batch_temp/batch_0012.log

# Crear CSV con solo esos 25 tickers problem√°ticos
# Re-ejecutar el wrapper solo con ese CSV
python batch_intraday_wrapper.py \
  --tickers-csv failed_tickers.csv \
  --batch-size 5 \  # ‚Üê batches m√°s peque√±os para tickers problem√°ticos
  ...
```

**Opci√≥n 2: Usar --resume para completar faltantes**

El wrapper tiene l√≥gica de resume:
```python
if args.resume:
    completed = get_completed_tickers(outdir)  # Revisa qu√© tickers YA tienen datos
    tickers = [t for t in all_tickers if t not in completed]
    log(f"--resume: {len(completed):,} tickers ya con datos | pendientes: {len(tickers):,}")
```

Entonces puedes re-ejecutar:
```bash
python batch_intraday_wrapper.py \
  --tickers-csv processed/universe/cs_xnas_xnys_under2b_2025-10-21.csv \
  --resume \  # ‚Üê Excluye los que ya tienen datos
  ...
```

Solo procesar√° los 50 tickers que quedaron pendientes.

---

## ¬øQu√© pasa si hay errores internos (SSL, memoria, etc.)?

El **ingestor** maneja errores con **reintentos inteligentes**:

### Sistema de reintentos dentro del ingestor

```python
def http_get_json(session, url, params, headers):
    last_error = None
    for k in range(1, RETRY_MAX + 1):  # RETRY_MAX = 8
        try:
            r = session.get(url, params=params, headers=headers, timeout=TIMEOUT)

            if r.status_code == 429:  # Rate limit
                sl = int(r.headers.get("Retry-After", "2"))
                log(f"429 Rate Limit -> sleep {sl}s")
                time.sleep(sl)
                continue

            if 500 <= r.status_code < 600:  # Server error
                sl = min(30, BACKOFF ** k)
                log(f"{r.status_code} Server Error -> backoff {sl:.1f}s")
                time.sleep(sl)
                continue

            r.raise_for_status()
            return r.json()

        except Exception as e:
            last_error = e
            msg = str(e).lower()

            # Reintentos inteligentes seg√∫n tipo de error
            if "certificate" in msg or "ssl" in msg:
                sl = 2  # Retry r√°pido para SSL/TLS
            elif "allocate" in msg or "buffer" in msg or "decompress" in msg:
                sl = min(60, BACKOFF ** (k + 2))  # M√°s lento para memoria
            else:
                sl = min(30, BACKOFF ** k)

            log(f"GET error {e} -> backoff {sl:.1f}s")
            time.sleep(sl)

    # Despu√©s de 8 intentos ‚Üí levanta excepci√≥n
    raise RuntimeError(f"Failed after {RETRY_MAX} attempts: {last_error}")
```

### Flujo con errores:

```
Ticker AAPL, p√°gina 1:
  Intento 1: SSL error ‚Üí espera 2s ‚Üí reintenta
  Intento 2: SSL error ‚Üí espera 2s ‚Üí reintenta
  Intento 3: ‚úì OK ‚Üí descarga p√°gina 1

Ticker AAPL, p√°gina 2:
  Intento 1: ‚úì OK ‚Üí descarga p√°gina 2

Ticker AAPL, p√°gina 3:
  Intento 1: 429 Rate Limit ‚Üí espera 5s (seg√∫n Retry-After header) ‚Üí reintenta
  Intento 2: ‚úì OK ‚Üí descarga p√°gina 3

... (AAPL completado)

Ticker MSFT, p√°gina 1:
  Intento 1: Memory allocation error ‚Üí espera 2.6s ‚Üí reintenta
  Intento 2: Memory allocation error ‚Üí espera 4.1s ‚Üí reintenta
  Intento 3: Memory allocation error ‚Üí espera 6.6s ‚Üí reintenta
  Intento 4: ‚úì OK ‚Üí descarga p√°gina 1

... (MSFT completado)

Ticker XYZ (ticker problem√°tico), p√°gina 1:
  Intento 1: Timeout ‚Üí espera 1.6s
  Intento 2: Timeout ‚Üí espera 2.6s
  Intento 3: Timeout ‚Üí espera 4.1s
  ...
  Intento 8: Timeout ‚Üí espera 51.2s
  ‚Üí RuntimeError: "Failed after 8 attempts"
  ‚Üí Capturado por try/except ‚Üí se marca como "XYZ: ERROR ..."
  ‚Üí Batch CONTIN√öA con siguiente ticker
```

**Resultado:**
- AAPL: ‚úì completado (con 2 reintentos SSL)
- MSFT: ‚úì completado (con 3 reintentos memoria)
- XYZ: ‚úó error (despu√©s de 8 intentos)
- Batch termina con exit code 0 (√©xito parcial: 24/25 tickers OK)

---

## Ventajas del Wrapper vs Launcher

| Aspecto | Launcher | Wrapper |
|---------|----------|---------|
| **Duraci√≥n proceso** | Horas | Minutos |
| **Memoria** | Acumulativa | Liberada al morir |
| **Fallo catastr√≥fico** | Pierdes 259 tickers | Pierdes 25 tickers |
| **Diagn√≥stico** | Log √∫nico de 259 tickers | Log separado por batch |
| **Reintentos** | Manual | Autom√°tico (2 intentos) |
| **Conexiones TLS** | Reutilizadas (pueden corromperse) | Frescas por batch |
| **Control concurrencia** | Todos los workers a la vez | Solo 6 batches simult√°neos |
| **Resume** | Por carpeta ticker | Por carpeta ticker |
| **Rate limiting** | Compartido entre workers | Individual por batch |

---

## C√≥digo Completo del Wrapper

### Funci√≥n principal: run_batch()

```python
def run_batch(batch_id: int, tickers: List[str], args, script_path: Path,
              temp_dir: Path, tries: int = 2) -> Tuple[int, str, float]:
    """
    Lanza un subproceso del ingestor "streaming" procesando este batch.
    Reintenta hasta 'tries' veces si el exit code != 0.
    """
    start = time.time()

    # 1. Crear CSV temporal con los tickers de este batch
    csv_path = temp_dir / f"batch_{batch_id:04d}.csv"
    pl.DataFrame({"ticker": tickers}).write_csv(csv_path)

    # 2. Preparar comando del subproceso
    log_path = temp_dir / f"batch_{batch_id:04d}.log"
    cmd = [
        sys.executable, str(script_path),
        "--tickers-csv", str(csv_path),
        "--outdir", args.outdir,
        "--from", args.date_from,
        "--to", args.date_to,
        "--rate-limit", str(args.rate_limit),
        "--max-tickers-per-process", str(len(tickers)),  # ‚Üê CLAVE
        "--max-workers", "1",  # ignorado por ingestor streaming
    ]

    # 3. Heredar variables de entorno (API key, SSL config)
    env = os.environ.copy()

    # 4. Ejecutar con reintentos
    attempt = 0
    rc = 1
    while attempt < tries:
        attempt += 1
        with open(log_path, "a", encoding="utf-8") as lf:
            lf.write(f"== BATCH {batch_id:04d} attempt {attempt}/{tries} ==\n")
            lf.flush()
            proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT, text=True)
            rc = proc.returncode

        if rc == 0:
            break  # √âxito

        time.sleep(3)  # Espera antes de reintentar

    elapsed = time.time() - start

    # 5. Limpiar CSV temporal (conservar log para diagn√≥stico)
    try:
        csv_path.unlink(missing_ok=True)
    except Exception:
        pass

    status = "success" if rc == 0 else f"failed(rc={rc})"
    return (batch_id, status, elapsed)
```

### Ejecuci√≥n paralela de batches

```python
def main():
    # ... (parsear argumentos, leer tickers, aplicar --resume) ...

    # Dividir en batches
    batches = chunk_list(tickers, args.batch_size)

    log("== Config ==")
    log(f"  Universo pendiente: {len(tickers):,} tickers")
    log(f"  Batches: {len(batches)} √ó {args.batch_size} tickers")
    log(f"  Concurrencia: {args.max_concurrent} batches a la vez")

    start = time.time()
    results = []

    # ThreadPoolExecutor para lanzar SUBPROCESOS (IO-bound)
    with ThreadPoolExecutor(max_workers=args.max_concurrent) as ex:
        # Enviar todos los batches (124), pero solo 6 corren simult√°neamente
        futs = {ex.submit(run_batch, i, b, args, script_path, temp_dir): i
                for i, b in enumerate(batches)}

        # Recoger resultados conforme terminan
        for fut in as_completed(futs):
            bid, status, elapsed = fut.result()
            results.append((bid, status, elapsed))

            done = len(results)
            pct = done / len(batches) * 100
            log(f"üì¶ Batch {bid:04d}: {status} ({elapsed:.1f}s) | "
                f"Progreso {done}/{len(batches)} = {pct:.1f}%")

    # Reporte final
    ok = sum(1 for _, s, _ in results if s == "success")
    fail = len(results) - ok
    elapsed_all = time.time() - start

    log("\n" + "="*60)
    log(f"‚úì COMPLETADO: {ok}/{len(results)} batches OK | {fail} fallidos")
    log(f"‚è±Ô∏è Tiempo total: {elapsed_all/3600:.2f} h")
    log(f"üßæ Logs por batch: {temp_dir}/")
```

---

## Uso Pr√°ctico

### Comando completo:

```bash
export POLYGON_API_KEY=tu_api_key_aqui

python scripts/fase_1_Bloque_B/tools/batch_intraday_wrapper.py \
  --tickers-csv processed/universe/cs_xnas_xnys_under2b_2025-10-21.csv \
  --outdir raw/polygon/ohlcv_intraday_1m \
  --from 2004-01-01 \
  --to 2010-12-31 \
  --batch-size 25 \
  --max-concurrent 6 \
  --rate-limit 0.20 \
  --ingest-script scripts/fase_1_Bloque_B/ingest_ohlcv_intraday_minute.py \
  --resume
```

### Par√°metros clave:

- `--batch-size 25`: Cada batch procesa 25 tickers ‚Üí 124 batches total
- `--max-concurrent 6`: Solo 6 batches corriendo a la vez
- `--rate-limit 0.20`: Espera 0.2s entre p√°ginas (5 p√°ginas/segundo)
- `--resume`: Excluye tickers que ya tienen datos descargados
- `--ingest-script`: Ruta al ingestor "streaming" (sin hilos internos)

### Monitoreo durante ejecuci√≥n:

```bash
# Ver progreso en tiempo real
tail -f raw/polygon/ohlcv_intraday_1m/_batch_temp/batch_0001.log

# Contar batches completados
ls raw/polygon/ohlcv_intraday_1m/_batch_temp/*.log | wc -l

# Ver √∫ltimas l√≠neas de todos los logs
for log in raw/polygon/ohlcv_intraday_1m/_batch_temp/*.log; do
    echo "=== $log ==="
    tail -n 3 "$log"
done
```

---

## Resumen Final

### El wrapper micro-batches es:

1. **Divide y vencer√°s**: 3,107 tickers ‚Üí 124 batches peque√±os
2. **Procesos desechables**: Cada batch vive ~10-30 min y muere ‚Üí libera RAM
3. **Paralelismo controlado**: Solo 6 batches simult√°neos ‚Üí no saturar CPU/red
4. **Reintentos autom√°ticos**: 2 intentos por batch si falla
5. **Diagn√≥stico sencillo**: Log separado por batch
6. **Resiliente a errores**: Si 1 batch falla ‚Üí contin√∫a con los otros 123

### ¬øCompleta el 100%?

**No autom√°ticamente**, pero:
- ‚úì Procesa todos los batches (no se detiene si uno falla)
- ‚úì Cada batch reintenta 2 veces
- ‚úì Errores internos (SSL, memoria) se manejan con hasta 8 reintentos por p√°gina
- ‚úó Si un batch falla 2 veces ‚Üí esos 25 tickers quedan pendientes
- ‚úì Puedes usar `--resume` para re-ejecutar solo los faltantes

**Resultado t√≠pico: 98-99% completado** en primera ejecuci√≥n, 100% despu√©s de 1-2 re-ejecuciones con `--resume`.

### ¬øPor qu√© es mejor que el launcher?

| Problema del Launcher | Soluci√≥n del Wrapper |
|----------------------|---------------------|
| Procesos viven horas ‚Üí acumulan memoria | Procesos viven minutos ‚Üí mueren y liberan |
| Si falla worker ‚Üí pierdes 259 tickers | Si falla batch ‚Üí pierdes 25 tickers |
| Log √∫nico gigante dif√≠cil de diagnosticar | Log separado por batch, f√°cil de revisar |
| Sin reintentos autom√°ticos | 2 reintentos autom√°ticos por batch |
| Conexiones TLS pueden corromperse | Conexiones frescas en cada batch |
| Dif√≠cil controlar concurrencia | `--max-concurrent` controla cu√°ntos a la vez |

---

## Pr√≥ximos Pasos Recomendados

1. **Ejecutar el wrapper** en lugar del launcher para la descarga 2004-2010
2. **Monitorear logs** de batches para detectar problemas
3. **Usar --resume** para completar tickers faltantes despu√©s de primera ejecuci√≥n
4. **Ajustar par√°metros** seg√∫n tu m√°quina:
   - `--batch-size`: M√°s peque√±o si hay muchos errores (ej. 15)
   - `--max-concurrent`: M√°s alto si tienes buena conexi√≥n (ej. 10)
   - `--rate-limit`: M√°s bajo si tienes plan Premium de Polygon (ej. 0.10)

---

**Fecha de creaci√≥n**: 2025-10-21
**Versi√≥n del ingestor**: Streaming (sin hilos internos)
**Versi√≥n del wrapper**: Micro-batches con reintentos autom√°ticos
