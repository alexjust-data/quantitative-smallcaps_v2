¡Listo! Ya he leído tus documentos y tengo el mapa claro del proyecto y del estado actual. Te dejo (1) un resumen fiel de lo que hay y (2) el plan de verificación “de lo más groso a lo más fino” con checks concretos y criterios de aceptación para certificar 100% OK.

## 1) Qué hay hecho (según tus archivos)

* **Universo y referencia (sin sesgo de supervivencia)** con SCD-2 y reglas DQ para inactivos/delistados, splits, etc. 
* **Política de “info-rich”** (RVOL≥2 ∨ |%chg|≥15% ∨ $Vol≥5M) alineada con tu Playbook y con López de Prado; justificación teórica/empírica y umbrales contrastados.
* **Descarga de ticks (trades) para 1,906 tickers / 11,054 días** con auditoría final de completitud e integridad al 100%, incluyendo fixes de paginación/cursor y range-splitting.
* **Constructor de barras informacionales (DIB/VIB)** sobre ticks con fix de timestamps ns→µs; esquema y parámetros claros.
* **Labeling Triple-Barrier** (PT=3σ, SL=2σ, T1=120) y **Sample Weights** (unicidad + |ret| + decay). 
* **ML dataset** (join de barras+labels+weights, 14 features, split walk-forward con purging) y meta.json. 
* **Diseño global de pipeline**: Polygon endpoints, features (incl. FFD), rutas de carpetas, y la estrategia “rolling 3–5y ticks + 20y 1-min/daily”.

## 2) Plan de verificación integral (coarse → fine)

**Objetivo:** demostrar, con trazabilidad y artefactos reproducibles, que *cada dataset dice exactamente la realidad que debía descargar/generar*.

### Capa A — Inventario y completitud (filesystem-level)

**Qué validar**

* Conteo de `_SUCCESS` y `trades.parquet` = **11,054/11,054**; fechas dentro de [2020-01-03, 2025-10-21]; sin huecos.
* Particionado `{ticker}/date=YYYY-MM-DD/…` consistente en **raw** y **processed**.

**Criterios de aceptación**

* Completitud 100%, sin “futuros”, sin directorios huérfanos. (Ref: auditoría final) 

**Artefacto**

* `audit_results_final.json` + log con comandos de verificación. (Ya reflejado en auditoría) 

### Capa B — Esquema y sanidad básica (file-level)

**Qué validar**

* **Trades**: columnas mínimas `t,p,s` presentes, tipos correctos, `t` ordenable y **monótono por archivo**, `s>0`, `p>0`.
* **Barras DIB**: esquema (`t_open,t_close,o,h,l,c,v,n,dollar,imbalance_score`) y **invariantes OHLC** (H≥max, L≤min, O/C in range). 
* **Labels/Weights**: joinable por `anchor_ts`, `label∈{-1,0,1}`, `0≤weight≤1` y **∑weight=1 por archivo**. 

**Criterios**

* Cero nulls críticos; 0 errores de esquema; orden temporal válido. (Tu auditoría ya muestreó 50 archivos sin nulls) 

**Artefacto**

* `audit_schema_sanity.json` con totales de errores (esperado: 0).

### Capa C — Consistencia temporal y microestructura (tick↔bar)

**Qué validar**

* **Unidad temporal**: todos los `t` en µs tras el fix ns→µs. Reaplicar prueba “año>3000” antes de castear. 
* **Conservación de masa**:

  * Suma de `s` en ticks ≈ `v` en barras agregadas por día;
  * Suma de `p*s` ≈ `dollar` en barras (tolerancia por redondeos).
* **Cobertura**: últimos ticks de un día ≈ `t_close` de la última barra; sin gaps largos no explicados por halts.

**Criterios**

* Errores relativos < 0.5% por día (redondeos/compresión).
* Secuencias de tiempo estrictamente crecientes por archivo.

**Artefacto**

* `audit_tick_to_bar.json` con métricas por (ticker, day).

### Capa D — Consistencia estadística (intraday/daily)

**Qué validar**

* **DIB density**: barras/día dentro de rango esperado para `target_usd=300k` (decenas-centenas). 
* **Distribución de labels**: evitar degeneración (>90% de una clase). 
* **Weights**: concentración razonable (p.ej., **Gini < 0.9** guía de sanidad). 

**Criterios**

* Percentiles de barras/día coherentes por sector/día; proporciones label ±1/0 sin colapsar; Gini bajo el umbral.

**Artefacto**

* `audit_stats.json` con histogramas/percentiles y métricas (labels/weights/barras).

### Capa E — Referencial y reglas de negocio (universo y decisiones)

**Qué validar**

* **Trazabilidad universo→ticks**: cada (ticker,day) con tick proviene de una watchlist **info-rich** ese día (o de Top-N). 
* **SCD-2 y simbología**: cambios de estado (delisted, exchange) no rompen enlaces a datos; splits/dividends coherentes con referencia. 
* **Fallbacks**: si faltase tick (no es el caso ahora), barras desde 1-min documentadas como tal. 

**Criterios**

* 100% de (ticker,day) justificado por `info_rich` o Top-N; sin “intrusos”.

**Artefacto**

* `lineage_universe_to_ticks.json` con conteos y excepciones (esperado: 0).

### Capa F — Determinismo y reproducibilidad (pipeline)

**Qué validar**

* Scripts idempotentes (`--resume`, `_SUCCESS`), seeds, y mismas salidas al re-ejecutar con misma versión y config. 
* **Meta.json** del dataset ML declarando columnas, fechas, split, purging. 

**Criterios**

* Checksum por archivo estable; diffs vacíos entre runs iguales.

**Artefacto**

* `reproducibility_report.json` (hashes por carpeta clave + versiones de lib).

---

## 3) Scripts/checks que propongo (plug-and-play)

* **`checks/01_inventory_check.py`** → cuenta `_SUCCESS`/parquet y fechas válidas; exporta `audit_results_final.json`. (Refuerza tu auditoría) 
* **`checks/02_schema_and_nulls.py`** → valida esquemas por dataset (raw/processed). 
* **`checks/03_tick_to_bar_conservation.py`** → compara sumas tick vs barras por día (v y dollar). 
* **`checks/04_labels_weights_stats.py`** → distribución de `label` y Gini de `weight`. 
* **`checks/05_universe_lineage.py`** → cruce watchlists/Top-N ↔ (ticker,day) descargados. 
* **`checks/06_reproducibility.py`** → hashing y versión de scripts/config usada. 

Cada script debe:

1. leer en paralelo; 2) producir **JSON** con métricas y **exit code ≠0** si no pasa umbral; 3) dejar **README corto** con “cómo interpretar” los resultados.

---

## 4) Criterios de “certificación 100% OK”

Tu lote queda **CERTIFICADO** cuando:

* A: `11,054/11,054` archivos y **0** futuros/huérfanos. 
* B: **0** errores de esquema / nulls críticos; tiempo monótono. 
* C: Conservación tick→barra con error relativo <0.5% y sin gaps injustificados. 
* D: Labels no degenerados; **Gini(weights) < 0.9** y densidad de barras coherente. 
* E: 100% lineage universo→ticks; SCD-2 sin roturas. 
* F: Re-run determinista (hashes idénticos) y **meta.json** completo. 

---

## 5) Árbol del proyecto para cerrar la verificación

Cuando compartas tu **árbol de proyecto** (rutas `raw/`, `processed/`, `scripts/`, `reports/`), ejecutaríamos (o dejaría listos para que ejecutes) los 6 checks arriba **apuntando a tus rutas reales** y generando los JSON de auditoría en `reports/audits/…`.


### Creado `D:\04_TRADING_SMALLCAPS\DATA_STRUCTURE_MAP.json`

