# Validation Pipeline - Checkpoint Map
Certifica la ejecuci√≥n completa del proyecto desde su inicio, que certifique cada paso completado con evidencia tangible + links a documentaci√≥n detallada.  
**√öltima actualizaci√≥n**: 2025-10-30  

## √çndice

* **Fundamento Te√≥rico**
    * [Eventos: fases del ciclo pump & dump](#eventos-a--fase-del-ciclo-pump--dump)
    * [Ventanas temporales de estos eventos](#ventanas-temporales-de-estos-eventos)

* **Pipeline Fase 1**
    * [A. Universo](#fase_01--a_universo)
    * [B. Ingesta Daily/Minute](#fase_01--b_ingesta_daily_minut_v2)
    * [C. Ingesta Ticks Event-Driven](#fase_01--c_v2_ingesta_tiks_2004_2025-)
        * [PASO 1: Daily Cache](#paso-1-resumen-diario-desde-barras-1-minuto-390-barras--1-fila)
        * [PASO 2: Configuraci√≥n Filtros E0](#paso-2-configuraci√≥n-filtros-e0)
        * [PASO 3: Generaci√≥n Watchlists E0](#paso-3-generaci√≥n-watchlists-e0-universeinforichdaily)
        * [PASO 4: An√°lisis Caracter√≠sticas E0](#paso-4-an√°lisis-caracter√≠sticas-e0)
        * [PASO 5: Descarga Ticks Selectiva](#paso-5-descarga-ticks-selectiva)
        * [Estudio datos E0 en mercado](#estudio-datos-e0-en-mercado)
    * [D. Creando DIB/VIB 2004-2025](#fase_01--d_creando_dib_vib_2004_2025)
        * [D.1: Dollar Imbalance Bars](#d1-dollar-imbalance-bars-dib)
        * [D.2: Triple Barrier Labeling](#d2-triple-barrier-labeling)
        * [D.3: Sample Weights](#d3-sample-weights-uniqueness--magnitude--time-decay)
        * [D.4: ML Dataset Builder](#d4-ml-dataset-builder-features--walk-forward-split)
    * [E. Influencia L√≥pez de Prado](#---a_universo--1_influencia_marcoslopezdepradromd)

**OBJETIVO de este pipeline**  
Descargar datos tick-by-tick (trades) de Polygon API, `SOLO para ventanas temporales donde ocurren eventos clave` detectables en el universo hibrido (8,686 tickers, 21 anos, 3,092 tikers activos y 5,594 inactivos). NO necesitamos ticks de TODO el historico (2004-2025): Solo necesitamos ticks de periodos con `actividad informativa relevante = eventos de pump & dump`. Estos eventos marcan las ventanas temporales criticas para descargar ticks.

**FUNDAMENTO TEORICO**

* Lopez de Prado: Information-Driven Bars : De "Advances in Financial Machine Learning" Cap 2.3.2 (pp. 29-32):

    > "The purpose of information-driven bars is to sample more frequently when new information arrives to the market."
    >
    >**Dollar Imbalance Bars (DIBs)** y **Dollar Runs Bars (DRBs)** requieren datos tick-by-tick:
    >- **DIBs:** Detectan desbalance compra/venta (pump initiation)
    >- **DRBs:** Detectan sweeping agresivo (informed traders)

* EduTrades: Eventos Clave en Small Caps : Del Playbook Operativo (14 estrategias)
    > 1. **Explosion de volumen** (RVOL > 5x)
    > 2. **Gaps significativos** (>15%)
    > 3. **Movimientos parabolicos** (>50% en 1-5 dias)
    > 4. **First Red Day** (primer dia rojo tras corrida)
    > 5. **Dilution events** (offerings, correlacionados con colapsos)


## EVENTOS a : fase del ciclo pump & dump:

```
FASE 1: DORMIDO (skip - no descargar ticks)
    +-- Bajo volumen, sin volatilidad

FASE 2: CATALIZADOR (EVENTO 1)
    +-- [E1] Volume Explosion: RVOL > 5x
    +-- [E2] Gap Up Significativo: Gap > 10%
    +-- [E3] Price Spike Intraday: +20% intrad√≠a

FASE 3: PUMP / EXTENSION (EVENTO 2)
    +-- [E4] Parabolic Move: +50% en 1-5 dias
    +-- [E5] Breakout ATH/52W: Nuevo high
    +-- [E6] Multiple Green Days: 3+ dias verdes consecutivos

FASE 4: DUMP / COLLAPSE (EVENTO 3)
    +-- [E7] First Red Day (FRD): Primer dia rojo post-pump
    +-- [E8] Gap Down Violento: Gap < -15%
    +-- [E9] Crash Intraday: -30% en <2 horas

FASE 5: BOUNCE (EVENTO 4)
    +-- [E10] First Green Day Bounce: Verde post-dump
    +-- [E11] Volume Spike on Bounce: RVOL > 3x en rebote

FASE 6: MUERTE (skip - no descargar ticks)
    +-- Volver a niveles base, dormido
```

**Eventos Especiales (Ortogonales al Ciclo)**

```
DILUTION EVENTS (EVENTO 5)
    +-- [E12] S-3 Effective Date +/- 2 dias
    +-- [E13] 424B Pricing Date +/- 2 dias
    +-- [E14] Warrant Exercise Events

MICROSTRUCTURE ANOMALIES (EVENTO 6)
    +-- [E15] Halts (LUDP, LUDS)
    +-- [E16] SSR Trigger (Short Sale Restriction)
    +-- [E17] Extreme Spread Events (bid/ask > 10%)
```

**VENTANAS temporales de estos eventos**

Para cada evento detectado, descargar ticks en ventana

* E0 -> +1 -1



# Pipeline

## fase_01 / A_universo  (34,380 tickers - activos + inactivos)

**Descargas:**  Script desarrollado: `scripts/fase_A_universo/download_complete_snapshot.py`  

```bash
D:\04_TRADING_SMALLCAPS\
‚îú‚îÄ‚îÄ raw\polygon\reference\tickers_snapshot\
‚îÇ   ‚îú‚îÄ‚îÄ snapshot_date=2025-10-19\
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tickers.parquet                    (11,845 - solo activos, LEGACY)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ snapshot_date=2025-10-24\              ‚¨ÖÔ∏è NUEVO UNIVERSO COMPLETO
‚îÇ       ‚îú‚îÄ‚îÄ tickers_all.parquet                (34,380 tickers - activos + inactivos)
‚îÇ       ‚îú‚îÄ‚îÄ tickers_active.parquet             (11,853 tickers - solo activos)
‚îÇ       ‚îî‚îÄ‚îÄ tickers_inactive.parquet           (22,527 tickers - solo inactivos)
‚îÇ
‚îî‚îÄ‚îÄ temp_active_counts_complete.csv            (resumen CSV con conteos)
```
Metadatos de archivos:

| Archivo | Tama√±o | Filas | Columnas | Descripci√≥n |
|---------|--------|-------|----------|-------------|
| `tickers_all.parquet` | ~15 MB | 34,380 | 14 | Dataset completo unificado |
| `tickers_active.parquet` | ~5 MB | 11,853 | 13 | Solo activos (referencia r√°pida) |
| `tickers_inactive.parquet` | ~10 MB | 22,527 | 14 | Solo inactivos (tiene columna `delisted_utc`) |
| `temp_active_counts_complete.csv` | <1 KB | 2 | 3 | Resumen: active, count, percentage |


```
# Distribuci√≥n por TIPO DE ACTIVO (activos):  
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ type    ‚îÇ count ‚îÇ percentage ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ CS      ‚îÇ 5,226 ‚îÇ 44.1%      ‚îÇ ‚¨ÖÔ∏è Common Stocks (nuestro objetivo)
‚îÇ ETF     ‚îÇ 4,361 ‚îÇ 36.8%      ‚îÇ
‚îÇ PFD     ‚îÇ   441 ‚îÇ  3.7%      ‚îÇ
‚îÇ WARRANT ‚îÇ   418 ‚îÇ  3.5%      ‚îÇ
‚îÇ ADRC    ‚îÇ   389 ‚îÇ  3.3%      ‚îÇ
‚îÇ FUND    ‚îÇ   536 ‚îÇ  4.5%      ‚îÇ
‚îÇ Otros   ‚îÇ   482 ‚îÇ  4.1%      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```
Distribuci√≥n por EXCHANGE (activos):  
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ primary_exchange ‚îÇ count  ‚îÇ percentage ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ XNAS (Nasdaq)    ‚îÇ 5,127  ‚îÇ 43.3%      ‚îÇ
‚îÇ XNYS (NYSE)      ‚îÇ 2,882  ‚îÇ 24.3%      ‚îÇ
‚îÇ ARCX (NYSE Arca) ‚îÇ 2,473  ‚îÇ 20.9%      ‚îÇ
‚îÇ BATS             ‚îÇ 1,061  ‚îÇ  9.0%      ‚îÇ
‚îÇ XASE (NYSE Amer) ‚îÇ   302  ‚îÇ  2.5%      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```
Calidad de datos (identificadores):

CIK (SEC Identifier):
  ‚úÖ Activos con CIK:     10,555 / 11,853 (89.1%)
  ‚ùå Activos sin CIK:      1,298 / 11,853 (10.9%)

FIGI (Bloomberg ID):
  ‚úÖ Activos con FIGI:     9,840 / 11,853 (83.1%)
  ‚ùå Activos sin FIGI:     2,013 / 11,853 (16.9%)
```
> M√°s descargas ejecutadas:
>
>**Splits**: 26,641 splits hist√≥ricos (31 archivos parquet)
>```sh
>2. Splits (/v3/reference/splits)
>    üìÇ raw/polygon/reference/splits/
>    üìä 26,641 splits hist√≥ricos
>    üìÑ 31 archivos parquet (particionado)
>```
>
>**Dividends**: 1,878,357 dividendos (31 archivos parquet)
>```sh
>3. Dividends (/v3/reference/dividends)
>    üìÇ raw/polygon/reference/dividends/
>    üìä 1,878,357 dividendos hist√≥ricos
>    üìÑ 31 archivos parquet (particionado)
>```
>
>‚ö†Ô∏è  **Ticker Details**: INCOMPLETO (<1% completitud)
>```sh
>4. Ticker Details (/v3/reference/tickers/{ticker})
>    üìÇ raw/polygon/reference/ticker_details/
>    üìÑ 2 archivos parquet (enriquecimiento parcial)
>    ‚ö†Ô∏è  INCOMPLETO - Solo sample ejecutado
>```

### Filtro para poblacion target : Small Caps (market cap < $2B, XNAS/XNYS, CS)
---  
  
>**[ADVERTENCIA]** **Polygon API `/v3/reference/tickers/{ticker}` NO devuelve `market_cap` para tickers inactivos/delistados.**  
>Esto significa:
>- [X] Imposible filtrar inactivos por market_cap historico
>- [X] Si solo usamos activos < $2B -> **SURVIVORSHIP BIAS SEVERO**
>- [X] Perdemos 5,594 tickers delistados (los MAS importantes para entrenar pump & dump terminal)

Pipeline ejecutado:

```sh
D:\04_TRADING_SMALLCAPS\
‚îú‚îÄ‚îÄ raw\polygon\reference\tickers_snapshot\
    ‚îú‚îÄ‚îÄ snapshot_date=2025-10-19\
    ‚îÇ   ‚îî‚îÄ‚îÄ tickers.parquet                    (11,845 - solo activos, LEGACY)
    ‚îÇ
    ‚îî‚îÄ‚îÄ snapshot_date=2025-10-24\              ‚¨ÖÔ∏è NUEVO UNIVERSO COMPLETO
        ‚îú‚îÄ‚îÄ tickers_all.parquet                (34,380 tickers - activos + inactivos)
        ‚îú‚îÄ‚îÄ tickers_active.parquet             (11,853 tickers - solo activos)
        ‚îî‚îÄ‚îÄ tickers_inactive.parquet           (22,527 tickers - solo inactivos)

        NUEVOS FILTROS A 34,380 tickers - activos + inactivos
                      ‚Üì
            Filtro: type=CS, exchange=XNAS/XNYS
            ‚îú‚îÄ Activos: 5,005
            ‚îî‚îÄ Inactivos: 5,594
            RESULTADO: 10,599 CS en XNAS/XNYS
                      ‚Üì
            Filtro market_cap < $2B (SOLO ACTIVOS)
            ‚îú‚îÄ Activos: 3,092 ‚Üê FILTRADOS
            ‚îî‚îÄ Inactivos: 5,594 ‚Üê SIN FILTRAR (todos)(ANTI-SURVIVORSHIP BIAS)
            RESULTADO: 8,686 tickers (Universo H√≠brido para descargar OHLCV)
                      ‚Üì
                   Exporta:
                   - cs_xnas_xnys_hybrid_2025-10-24.parquet (SIN market_cap a√∫n)
                   - cs_xnas_xnys_hybrid_2025-10-24.csv (6 columnas b√°sicas)  
```

**`cs_xnas_xnys_hybrid_2025-10-24.csv` no tiene market_cap**: El CSV se usa solo como input para scripts de descarga (como ingest_ohlcv_daily.py) que solo necesitan el ticker. 

```py
# L√≠nea 84 en create_hybrid_universe.py:
cols_csv = ["ticker", "name", "primary_exchange", "type", "active", "cik"]
df_hybrid.select([col for col in cols_csv if col in df_hybrid.columns]).write_csv(output_csv)
```

[`cs_xnas_xnys_hybrid_enriched_2025-10-24.parquet`](../processed/universe/cs_xnas_xnys_hybrid_enriched_2025-10-24.parquet) S√ç tiene market_cap y 23 columnas completas:

```sh
# PARQUET: 23 columnas (dataset completo con todas las features)
['active', 'cik', 'composite_figi', 'currency_name', 'delisted_utc', 
 'description', 'homepage_url', 'last_updated_utc', 'list_date', 
 'locale', 'market', 'market_cap', 'name', 'primary_exchange', 
 'share_class_figi', 'share_class_shares_outstanding', 'sic_code', 
 'sic_description', 'snapshot_date', 'ticker', 'total_employees', 
 'type', 'weighted_shares_outstanding']
```

**Criterios de Filtrado:**

* Para ACTIVOS (11,853 ‚Üí `3,092`):
    * **Type** = CS (Common Stock) - Elimina ETFs, warrants, preferred, ADRCs
    * **Exchange** = XNAS o XNYS (Nasdaq o NYSE) - Elimina ARCX, BATS, XASE
    * **Market Cap** < $2B - Filtro de small caps
    * **Market Cap IS NOT NULL** - Solo activos con datos de capitalizaci√≥n

* Para INACTIVOS (22,527 ‚Üí `5,594`):
    * **Type** = CS (Common Stock)
    * **Exchange** = XNAS o XNYS
    * **SIN filtro de market cap** - Incluye TODOS porque ya no tienen market_cap (no cotizan)


**¬øD√≥nde se ejecuta este filtrado?**
* Mencionado todo en [4.1_estrategia_dual_enriquecimiento.md](../01_DayBook/fase_01/A_Universo/4.1_problemas_&_decisiones.md)
* Archivo creado: [`../processed/universe/cs_xnas_xnys_hybrid_enriched_2025-10-24.parquet` (Fase A)](../processed/universe/cs_xnas_xnys_hybrid_enriched_2025-10-24.parquet)
* Resultado exportado**: [`../processed/universe/cs_xnas_xnys_hybrid_2025-10-24.csv` (8,686 tickers)](../processed/universe/cs_xnas_xnys_hybrid_2025-10-24.csv)
* EVIDENCIA de los resultados: [A_Universo / notebooks / notebook2.ipynb](../01_DayBook/fase_01/A_Universo/notebooks/notebook2.ipynb)  


## fase_01 / B_ingesta_Daily_Minut_v2

**Objetivo**: Descargar `OHLCV (Open, High, Low, Close, Volume)` completo del Universo H√≠brido: 8,686 tickers para:

* Eliminar survivorship bias (L√≥pez de Prado Ch.1)  
* Preparar datos para Event Detection (pumps & dumps)  
* Base para construcci√≥n de DIB bars (Cap.2)  
* OHLCV Daily  
* OHLCV Intraday 1-minute  


```sh
hemos hecho :

../fase_01/A_universo (34,380 tickers) 
                            ‚Üì
                        Filtrado Small Caps (market cap < $2B, XNAS/XNYS, CS)
                            ‚Üì
                        Universo H√≠brido: 8,686 tickers
                            ‚îú‚îÄ‚îÄ 3,092 activos
                            ‚îî‚îÄ‚îÄ 5,594 inactivos (ANTI-SURVIVORSHIP BIAS)
                            RESULTADO: 8,686 tickers (Universo H√≠brido para descargar OHLCV)
                                    ‚Üì
                                Exporta:
                                - cs_xnas_xnys_hybrid_2025-10-24.parquet (SIN market_cap a√∫n)
                                - cs_xnas_xnys_hybrid_2025-10-24.csv (6 columnas b√°sicas)  
ahora toca :

../fase_01/B_ingesta ‚Üí OHLCV Polygon.io
```

### Scripts Utilizados

**Daily**:
- Ingestor: `scripts/fase_B_ingesta_Daily_minut/ingest_ohlcv_daily.py`

**Intrad√≠a**:
- Launcher: `scripts/fase_B_ingesta_Daily_minut/tools/launch_wrapper.ps1`
- Wrapper: `scripts/fase_B_ingesta_Daily_minut/tools/batch_intraday_wrapper.py`
- Ingestor: `scripts/fase_B_ingesta_Daily_minut/ingest_ohlcv_intraday_minute.py`



### Logs de Descarga

**Daily**:
- Log principal: `logs/daily_download_20251024_221953.log`
- Log final: `raw/polygon/ohlcv_daily/daily_download.log`

**Intrad√≠a**:
- Wrapper log: `logs/intraday_wrapper_20251024_223730.log`
- Batch logs: `raw/polygon/ohlcv_intraday_1m/_batch_temp/batch_*.log`



### Datos

**Universo**:
- CSV: `processed/universe/cs_xnas_xnys_hybrid_2025-10-24.csv` (8,686 tickers)
- Parquet enriched: `processed/universe/cs_xnas_xnys_hybrid_enriched_2025-10-24.parquet`

**OHLCV**:
- Daily: `raw/polygon/ohlcv_daily/` (8,618 tickers)
- Intrad√≠a: `raw/polygon/ohlcv_intraday_1m/` (8,620 tickers)



**Output critical**:  `OHLCV` historical data es input para:
* **Event Detection (E1-E11)**: Detectar VolExplosion, GapUp, Parabolic, etc.
* **Daily features**: RVOL, volatility, %change
* **Intraday bars**: Construcci√≥n de 1-min OHLCV

```sh
Descargas completadas:

1. OHLCV Daily (/v2/aggs/ticker/{ticker}/range/1/day/)
    üìÇ raw/polygon/ohlcv_daily/
    üìä 8,619 tickers (99.22% del universo)
    Per√≠odo: 2004-01-01 ‚Üí 2025-10-24 (21 a√±os)
    Volumen: ~43 GB
    Estructura: TICKER/year=YYYY/daily.parquet
    Duraci√≥n: 25 minutos (360 tickers/min)
    Columnas disponibles (DAILY): C10 (ticker, date, t, o, h, l, c, v, n, vw)
    ‚úÖ Success rate: 99.98%

2. OHLCV Intraday 1-minute (/v2/aggs/ticker/{ticker}/range/1/minute/)
    üìÇ raw/polygon/ohlcv_intraday_1m/
    üìä 8,623 tickers (99.27% del universo)
    Per√≠odo: 2004-01-01 ‚Üí 2025-10-24 (21 a√±os)
    Volumen: ~2.15 TB (ZSTD level 2)
    Estructura: TICKER/year=YYYY/month=MM/minute.parquet
    Duraci√≥n: 10.48 horas (534 tickers/hora)
    Columnas disponibles (DAILY): C10 (ticker, date, t, o, h, l, c, v, n, vw)
    ‚úÖ Success rate: 100% (280/280 batches)

4. Tickers Faltantes
    ‚úì Impacto: M√çNIMO (no afectan an√°lisis)
    An√°lisis de Faltantes: Normalizaci√≥n de texto pendiente Algunos tickers con may√∫sculas/min√∫sculas diferentes (ADSw vs ADSW, HW vs Hw)
    ‚ö†Ô∏è  Solo en daily: 3 tickers
    Ejemplos: ['ADSw', 'AEBIV', 'HW']
    ‚ö†Ô∏è  Solo en intraday: 6 tickers
    Ejemplos: ['ADSW', 'ASTI', 'Hw', 'MURAV', 'RNVA']
```

> EVIDENCIA de los resulados: [B_ingesta_Daily_Minut_v2 / notebooks / notebook2.ipynb](../01_DayBook/fase_01/B_ingesta_Daily_Minut_v2/notebooks/notebook2.ipynb)

--- 

## fase_01 \ C_v2_ingesta_tiks_2004_2025 \ 

```sh
hemos hecho :

../fase_01/A_universo (34,380 tickers) 
                            ‚Üì
                    Filtrado Small Caps (market cap < $2B, XNAS/XNYS, CS)
                            ‚Üì
                    Universo H√≠brido: 8,686 tickers
                        ‚îú‚îÄ‚îÄ 3,092 activos
                        ‚îî‚îÄ‚îÄ 5,594 inactivos (ANTI-SURVIVORSHIP BIAS)
                            
../fase_01/B_ingesta ‚Üí OHLCV (8,619 daily + 8,623 intraday tickers)
                            ‚Üì

ahora toca :

../fase_01/C_v2_ingesta_tiks_2004_2025 (Event-Driven Pipeline)
                            ‚Üì
        [PASO 1] Agregaci√≥n OHLCV 1m ‚Üí Daily Cache
                 Input: raw/polygon/ohlcv_intraday_1m/ (de fase B)
                 Output: processed/daily_cache/
                 Features: rvol30, pctchg_d, dollar_vol_d
                 Script: build_daily_cache.py
                            ‚Üì
        [PASO 2] (editar YAML) NO depende de PASO 1, puedes hacerlo antes/despu√©s
                 Configuraci√≥n Filtros E0
                 genera universe_config.yaml : RVOL‚â•2, |%chg|‚â•15%, $vol‚â•$5M, precio $0.20-$20
                            ‚Üì
        [PASO 3] Input: necesita AMBOS:
                    - processed/daily_cache/ (del PASO 1)
                    - universe_config.yaml (del PASO 2)
                 Genera Watchlists E0
                 Output: processed/universe/info_rich/daily/
                 5,934 watchlists con 29,555 d√≠as info-rich
                 Script: build_universe.py
                            ‚Üì
        [PASO 4] An√°lisis Caracter√≠sticas E0
                 Input: processed/universe/info_rich/daily/ (del PASO 3)
                 Validaci√≥n: 4,898 tickers √∫nicos, umbrales OK
                 Script: analyze_e0_characteristics.py
                            ‚Üì
        [PASO 5] Descarga Ticks Selectiva ‚Üê AQU√ç RECI√âN SE DESCARGAN TRADES
                 Input: watchlists E0 (d√≠as info-rich + ventana ¬±1)
                 Output: raw/polygon/trades/
                 64,801 ticker-d√≠as tick-by-tick (16.58 GB)
                 Script: download_trades.py
```

### [PASO 1] Resumen diario desde barras 1-minuto (390 barras ‚Üí 1 fila)

**Explicacion detallada**: [proceso [PASO 1]](EXPLICACION_PASO1_DAILY_CACHE.md) .  Este paso est√° agregando LAS barras OHLCV de 1-minuto EN barras diarias

`INPUT`: Las barras 1-minuto de Fase B (`raw/polygon/ohlcv_intraday_1m/`)

```sh
# hora NY
INPUT: Barras OHLCV de 1-minuto (ya existen, descargadas en Fase B)
raw/polygon/ohlcv_intraday_1m/AAM/date=2024-01-02/
‚îú‚îÄ‚îÄ 09:30 | o=$25.00, h=$25.10, l=$24.90, c=$25.05, v=10,000
‚îú‚îÄ‚îÄ 09:31 | o=$25.05, h=$25.20, l=$25.00, c=$25.15, v=5,000
‚îú‚îÄ‚îÄ 09:32 | o=$25.15, h=$25.30, l=$25.10, c=$25.25, v=8,000
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ 16:00 | o=$26.00, h=$26.10, l=$25.95, c=$26.00, v=8,000

Total: 390 barras OHLCV de 1-minuto (ya descargadas)
```

`TRANSFORMACI√ìN`: Agregaci√≥n b√°sica (group by ticker + d√≠a), resumir esas 390 barras en 1 sola barra diaria.     
Features calculados  
* **pctchg_d** - Cambio porcentual diario  
* **rvol30** - Volumen relativo 30 sesiones  
* **dollar_vol_d** - Volumen en d√≥lares

```sh
# El script NO descarga nada nuevo
# Solo lee las 390 barras y las resume en 1 fila

close_d = barras_1m[-1].c          # √öltimo close = $26.00
vol_d = sum(barras_1m[:].v)        # Suma de vol√∫menes = 2,500,000
dollar_vol_d = sum(v √ó vw)         # $64,750,000
```

`OUTPUT`: 1 fila diaria con features calculados

```sh
processed/daily_cache/ticker=AAM/daily.parquet
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ticker     ‚îÇ date     ‚îÇ close_d   ‚îÇ vol_d        ‚îÇ pctchg_d ‚îÇ rvol30 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ AAM        ‚îÇ2024-01-02‚îÇ $26.00    ‚îÇ 2,500,000    ‚îÇ +0.15    ‚îÇ 2.5    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1 fila diaria (agregada desde 390 barras de 1-min)
```

```sh
OUTPUT: Daily Cache enriquecido  
processed/daily_cache/ticker=AAM/daily.parquet

Columnas finales:
- ticker
- trading_day
- close_d          ‚Üê Close del d√≠a
- vol_d            ‚Üê Volumen total acciones
- dollar_vol_d     ‚Üê Volumen en d√≥lares (VWAP-weighted)
- vwap_d           ‚Üê VWAP del d√≠a
- pctchg_d         ‚Üê % change vs d√≠a anterior
- return_d         ‚Üê Log return
- rvol30           ‚Üê Volumen relativo 30 sesiones
- session_rows     ‚Üê Cu√°ntas barras 1m
- has_gaps         ‚Üê ¬øFaltaron barras?
```
### [PASO 2] Configuraci√≥n Filtros E0
Justificacion completa del porqu√© de los Filtros E0 : [LINK](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/anotaciones/JUSTIFICACION_FILTROS_E0_COMPLETA.md)

PASO 2 NO depende de PASO 1, puedes hacerlo antes/despu√©s.  
Genera un YAML `universe_config.yaml` con :   
`RVOL‚â•2`, `|%chg|‚â•15%`, `$vol‚â•$5M`, `precio $0.20-$20`  


**Resumen de Justificaci√≥n Filtros E0** (Generic Info-Rich):
>
>| Filtro | Formula | Fundamento | Rationale |
>|--------|---------|------------|-----------|
>| **RVOL ‚â• 2.0** | `vol_d / MA30` | L√≥pez de Prado (2018, Ch.1) - Event-based sampling | Detecta actividad 2x superior ‚Üí pumps, bounces, first red days |
>| **\|%chg\| ‚â• 15%** | `abs((close/prev)-1)` | EduTrades Playbook - Gap&Go +15%, FRD -15% | Movimientos extremos (runners o collapses) |
>| **$vol ‚â• $5M** | `Œ£(v√óvwap)` 1-min | Easley et al. (2012) - Flow toxicity | Filtra zombis, solo flujo institucional real |
>| **Precio $0.20-$20** | `close_d` | Small caps proxy + penny stocks v√°lidos | $0.20-$0.50 pueden tener patrones info-rich v√°lidos |


### [PASO 3] Generaci√≥n Watchlists E0 (universe/info_rich/daily/)

1. Lee `processed/daily_cache/` (OUTPUT del PASO 1)
2. Aplica filtros de `universe_config.yaml` (PASO 2)
3. Filtra d√≠as que cumplen: `RVOL‚â•2.0 AND |%chg|‚â•15% AND $vol‚â•$5M...`
4. Escribe watchlists en `processed/universe/info_rich/daily/`

```sh
Input: 
- processed/daily_cache/ (del PASO 1)
- universe_config.yaml (del PASO 2)

# Filtra d√≠as que cumplen: RVOL‚â•2.0 AND |%chg|‚â•15% AND $vol‚â•$5M...
Output:   
processed/universe/info_rich/daily/   
‚îú‚îÄ‚îÄ date=2024-01-02/watchlist.parquet ‚Üê Solo d√≠as que pasan filtros E0  
‚îú‚îÄ‚îÄ date=2024-01-03/watchlist.parquet  
‚îî‚îÄ‚îÄ ...
```
> EVIDENCIA de resulados: [[PASO 3] Generaci√≥n Watchlists E0](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/analysis_paso3_executed.ipynb)

### [PASO 4] An√°lisis Caracter√≠sticas E0

1. Lee watchlists E0 del PASO 3
2. Analiza distribuciones de features (rvol30, pctchg_d, dollar_vol_d)
3. Valida que todos los eventos cumplen umbrales
4. Genera estad√≠sticas descriptivas

```sh
python scripts/fase_C_ingesta_tiks/analyze_e0_characteristics.py \
  --universe-root processed/universe/info_rich/daily \
  --outdir analysis/e0_characteristics
```

```sh
OUTPUT t√≠pico:
üìä An√°lisis E0 Characteristics
================================
Total eventos E0: 29,555
Tickers √∫nicos: 4,898

Distribuci√≥n RVOL30:
- Min: 2.00  (threshold OK ‚úÖ)
- Median: 3.47
- Max: 125.6

Distribuci√≥n |%chg|:
- Min: 0.15  (threshold OK ‚úÖ)
- Median: 0.21
- Max: 0.89
```

‚úÖ Validaci√≥n: 100% eventos cumplen umbrales E0
‚úÖ 4,898 tickers √∫nicos con eventos E0
‚úÖ Stats guardadas en analysis/e0_characteristics/

> EVIDENCIA de resulados: 
> [PASO 4 (An√°lisis Caracter√≠sticas)](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/analysis_paso4_executed.ipynb)
> [PASO 4 (validaci√≥n adicional)](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/analysis_caracteristicas_paso4.ipynb)


### [PASO 5] Descarga Ticks Selectiva 

1. Lee watchlists E0 del PASO 3
2. Expande ventana: para cada evento E0, incluye d√≠a-1 y d√≠a+1
3. Descarga trades tick-by-tick de Polygon API solo para esos d√≠as
4. Escribe en `raw/polygon/trades/`

```sh
# Ejemplo de expansi√≥n de ventana:
Watchlist E0 contiene:
AAM | 2024-01-02 | RVOL=2.5, %chg=+15%  ‚Üê D√≠a E0

PASO 5 descarga:
‚îú‚îÄ‚îÄ AAM | 2024-01-01  ‚Üê d√≠a E0 - 1
‚îú‚îÄ‚îÄ AAM | 2024-01-02  ‚Üê d√≠a E0 (el evento)
‚îî‚îÄ‚îÄ AAM | 2024-01-03  ‚Üê d√≠a E0 + 1

Total: 3 ticker-d√≠as por evento E0 (ventana ¬±1)
```

```sh
INPUT:
processed/universe/info_rich/daily/
‚îú‚îÄ‚îÄ date=2024-01-02/watchlist.parquet  ‚Üê 50 eventos
‚îú‚îÄ‚îÄ date=2024-01-03/watchlist.parquet  ‚Üê 120 eventos
‚îî‚îÄ‚îÄ ...                                ‚Üê 5,934 watchlists totales
```

```sh
OUTPUT:
raw/polygon/trades/
‚îú‚îÄ‚îÄ ticker=AAM/
‚îÇ   ‚îú‚îÄ‚îÄ date=2024-01-01/trades.parquet  ‚Üê Tick-by-tick (price, size, conditions)
‚îÇ   ‚îú‚îÄ‚îÄ date=2024-01-02/trades.parquet
‚îÇ   ‚îî‚îÄ‚îÄ date=2024-01-03/trades.parquet
‚îú‚îÄ‚îÄ ticker=BCRX/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...

Total: 64,801 ticker-d√≠as √ó ~250 KB promedio = 16.58 GB
```
> EVIDENCIA de resulados: 
>* [PASO 5 (Descarga Ticks)](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/analysis_paso5_executed.ipynb)  
>* [PASO 5 (validaci√≥n adicional)](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/analysis_paso5_executed_2.ipynb)  
>* [Visualizaciones globales](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/analysis_estadisticas_visuales_executed.ipynb)  


## Estudio datos E0 en mercado

> ---  
>**Analisis profundo de eventos E0** : [**Link**](../01_DayBook/fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/ANALISIS_PROFUNDO_EVENTOS_E0_FIXED.ipynb)  
> * Analiza trades tick-by-tick y encuentra la hora exacta del trigger E0
> * ¬øcu√°ndo ocurren los eventos?
> ---  

![](./fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/graficos/e0_distribucion_temporal_FIXED.png)

* Eventos E0 totales (2004-2025): 29,555 eventos
* Eventos E0 √∫ltimos 5 a√±os (2020-2025): 17,836 eventos (60.3%)   
* Triggers encontrados con trades (2004-2025): 7,306 (24.7%)

AN√ÅLISIS INTRADAY: HORA EXACTA DEL TRIGGER E0

An√°lisis completado:

* Per√≠odo: 2004-01-01 ‚Üí 2025-10-21
* Eventos analizados: 29,555
* Triggers encontrados: 7,306
* % con trades disponibles: 24.7%

![](./fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/graficos/e0_triggers_por_hora_COMPLETO.png)


AN√ÅLISIS E0: √öLTIMOS 5 A√ëOS (2020-2025)

[Link to .csv](./fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/data/eventos_E0_CON_HORA_EXACTA_2020_2025_TRADINGVIEW.csv)

Eventos E0 filtrados:

* Per√≠odo: 2020-01-01 ‚Üí 2025-10-21
* Total eventos: 17,836
* Tickers √∫nicos: 3,402
* % del total E0: 60.3%

![](./fase_01/C_v2_ingesta_tiks_2004_2025/notebooks/graficos/e0_triggers_por_hora_2020_2025.png)


## fase_01 \ D_creando_DIB_VIB_2004_2025
```sh
hemos hecho :

../fase_01/A_universo (34,380 tickers) 
                            ‚Üì
                    Filtrado Small Caps (market cap < $2B, XNAS/XNYS, CS)
                    Universo H√≠brido: 8,686 tickers
                        ‚îú‚îÄ‚îÄ 3,092 activos
                        ‚îî‚îÄ‚îÄ 5,594 inactivos (ANTI-SURVIVORSHIP BIAS)
                            
../fase_01/B_ingesta ‚Üí OHLCV (8,619 daily + 8,623 intraday tickers)
                            ‚Üì
../fase_01/C_v2_ingesta_tiks_2004_2025 (Event-Driven Pipeline)
        [PASO 1] 
        [PASO 2] 
        [PASO 3] 
        [PASO 4] 
        [PASO 5] Descarga Ticks Selectiva con eventos E0 (+1 / -1 d√≠a)
                            ‚Üì
                OUTPUT:
                raw/polygon/trades/
                ‚îú‚îÄ‚îÄ ticker=AAM/
                ‚îÇ   ‚îú‚îÄ‚îÄ date=2024-01-01/trades.parquet  ‚Üê Tick-by-tick (price, size, conditions)
                ‚îÇ   ‚îú‚îÄ‚îÄ date=2024-01-02/trades.parquet
                ‚îÇ   ‚îî‚îÄ‚îÄ date=2024-01-03/trades.parquet
                ‚îú‚îÄ‚îÄ ticker=BCRX/
                ‚îÇ   ‚îî‚îÄ‚îÄ ...
                ‚îî‚îÄ‚îÄ ...

                            ‚Üì

ahora toca :

  raw/polygon/trades/                    (PASO 5 output - 60,825 d√≠as)
          ‚îÇ
          ‚îú‚îÄ‚îÄ[D.1]‚îÄ‚îÄ> processed/bars/              (Dollar Imbalance Bars)
          ‚îÇ               ‚îÇ
          ‚îÇ               ‚îú‚îÄ‚îÄ[D.2]‚îÄ‚îÄ> processed/labels/        (Triple Barrier Labels)
          ‚îÇ               ‚îÇ               ‚îÇ
          ‚îÇ               ‚îÇ               ‚îú‚îÄ‚îÄ[D.3]‚îÄ‚îÄ> processed/weights/     (Sample Weights)
          ‚îÇ               ‚îÇ               ‚îÇ               ‚îÇ
          ‚îÇ               ‚îÇ               ‚îÇ               ‚îî‚îÄ‚îÄ[D.4]‚îÄ‚îÄ> processed/datasets/
          ‚îÇ               ‚îÇ               ‚îÇ                               ‚îú‚îÄ‚îÄ daily/
          ‚îÇ               ‚îÇ               ‚îÇ                               ‚îú‚îÄ‚îÄ global/
          ‚îÇ               ‚îÇ               ‚îÇ                               ‚îî‚îÄ‚îÄ splits/
          ‚îÇ               ‚îÇ               ‚îÇ                                    ‚îú‚îÄ‚îÄ train.parquet (3.49M rows)
          ‚îÇ               ‚îÇ               ‚îÇ                                    ‚îî‚îÄ‚îÄ valid.parquet (872K rows)
```

**Objetivo**:  

* 1. Construir barras informacionales `DIB` (Dollar Imbalance Bars) desde tick data, 
* 2. aplicar `Triple Barrier Labeling`, 
* 3. calcular `Sample Weights` con unicidad temporal, 
* 4. y generar `ML Dataset walk-forward` listo para entrenamiento supervisado.   

**Cobertura**: 2004-2025 (21 a√±os), 4,874 tickers, 64,801 d√≠as √∫nicos   
**Resultado final**: 4.36M eventos ML-ready con 14 features intraday + labels + weights.    

---

### **fase_01 / D_creando_DIB_VIB_2004_2025**

---

#### **[D.1] Dollar Imbalance Bars (DIB)**

>**Explicaci√≥n detallada**:
>- [D.0_Constructor_barras_Dollar_Vol_Imbalance.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.0_Constructor_barras_Dollar_Vol_Imbalance.md)
>- [D.1.1_notas_6.1_DIB.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.1.1_notas_6.1_DIB.md) - Par√°metros target-usd y ema-window
>

**Script**: `scripts/fase_D_creando_DIB_VIB/build_bars_from_trades.py`

`INPUT`:
- `raw/polygon/trades/{ticker}/date={YYYY-MM-DD}/trades.parquet` 
- (60,825 archivos, formato NUEVO con t_raw + t_unit)

`TRANSFORMACI√ìN`:

```python
# Event-driven sampling (L√≥pez de Prado 2018)
# Acumula flujo de d√≥lares hasta umbral adaptativo
for cada tick:
    dollar_flow += price √ó size √ó tick_sign
    if dollar_flow >= threshold_adaptativo:
        flush_bar(t_open, t_close, OHLC, volume, n_trades, imbalance_score)
        threshold = EMA(threshold, window=50)
```

- Par√°metros clave:
    - `--target-usd 300000`: $300k por barra (~1-2% volumen diario small cap)
    - `--ema-window 50`: Suavizaci√≥n adaptativa del umbral (memoria ~sesi√≥n completa)
    - `--parallel 8`: Workers concurrentes

`OUTPUT`:
- `processed/bars/{ticker}/date={YYYY-MM-DD}/dollar_imbalance.parquet`
- **64,801 archivos** (100% completitud)
- Schema: `{t_open, t_close, o, h, l, c, v, n, dollar, imbalance_score}`
- Promedio: ~57 barras/d√≠a, ~190 KB/archivo

> ---
>   ...  
> EVIDENCIA de resultados:   
> [D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md)  
> ...  


#### **[D.2] Triple Barrier Labeling**

Triple Barrier Labeling es un m√©todo que etiqueta cada evento con +1 (ganancia), -1 (p√©rdida) o 0 (neutral) seg√∫n qu√© barrera se toque primero: profit target (PT), stop loss (SL), o l√≠mite de tiempo (t1). En otras palabras: define 3 "barreras" (arriba=ganancia, abajo=p√©rdida, tiempo=expiraci√≥n) y clasifica cada trade seg√∫n cu√°l toca primero, creando as√≠ las etiquetas supervisadas para machine learning.

---

**Explicaci√≥n detallada**: [D.1.2_notas_6.1_tripleBarrierLabeling.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.1.2_notas_6.1_tripleBarrierLabeling.md)   
**Script**: `scripts/fase_D_creando_DIB_VIB/triple_barrier_labeling.py`

`INPUT`:
- `processed/bars/{ticker}/date={YYYY-MM-DD}/dollar_imbalance.parquet`

`TRANSFORMACI√ìN`:
```python
# Triple Barrier Method (L√≥pez de Prado Ch.3)
# Para cada barra como "anchor":
œÉ = EMA(|log_returns|, span=50)  # Volatilidad adaptativa

# Barreras horizontales:
PT = price_anchor √ó (1 + 3.0 √ó œÉ)  ‚Üí label = +1 si toca primero
SL = price_anchor √ó (1 - 2.0 √ó œÉ)  ‚Üí label = -1 si toca primero

# Barrera vertical:
t1 = anchor_ts + 120 barras (~medio d√≠a)  ‚Üí label = 0 si expira sin tocar PT/SL

# Asim√©trico: PT=3œÉ vs SL=2œÉ favorece captura de momentum (pumps explosivos)
```

* Par√°metros clave:
    - `--pt-mul 3.0`: Profit target = 3 √ó œÉ (significancia estad√≠stica)
    - `--sl-mul 2.0`: Stop loss = 2 √ó œÉ (asim√©trico, stop m√°s cercano)
    - `--t1-bars 120`: Vertical barrier ~2-3 horas trading
    - `--vol-est ema --vol-window 50`: Estimaci√≥n volatilidad adaptativa

`OUTPUT`:
- `processed/labels/{ticker}/date={YYYY-MM-DD}/labels.parquet`
- **64,800 archivos** (99.998% completitud, 1 archivo faltante)
- Schema: `{anchor_ts, t1, pt_hit, sl_hit, label, ret_at_outcome, vol_at_anchor}`



> ---  
> EVIDENCIA de resultados: 
> * [D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md](./D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md#2-triple-barrier-labeling)   
> * [validacion_dib_produccion_executed](../01_DayBook/fase_01/D_creando_DIB_VIB_2004_2025/notebooks/validacion_dib_produccion_executed.ipynb)  
> ...
---

#### **[D.3] Sample Weights (Uniqueness + Magnitude + Time-Decay)**

Sample Weights asigna un peso de importancia a cada evento para machine learning, reduciendo el peso de eventos solapados temporalmente (no independientes) y priorizando movimientos grandes y recientes. En otras palabras: no todos los eventos valen lo mismo para entrenar - los eventos √∫nicos (no concurrentes), grandes (alto retorno) y recientes pesan m√°s que los eventos amontonados, peque√±os y antiguos.

---

**Explicaci√≥n detallada**: [D.1.3_notas_6.1_SampleWeights.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.1.3_notas_6.1_SampleWeights.md)  
**Script**: `scripts/fase_D_creando_DIB_VIB/make_sample_weights.py`  

`INPUT`:
- `processed/labels/{ticker}/date={YYYY-MM-DD}/labels.parquet`

`TRANSFORMACI√ìN`:
```python
# F√≥rmula (L√≥pez de Prado Ch.4):
weight[i] = (|ret_at_outcome[i]| / concurrency[i]) √ó decay[i]

# Componentes:
# 1. |ret_at_outcome|: Peso base por magnitud (eventos +80% > +0.3%)
# 2. concurrency[i]: #ventanas [anchor_ts, t1] que contienen evento i
#    ‚Üí Reduce peso de eventos solapados (no independientes)
# 3. decay[i]: 0.5 ^ (age_days / 90) - Prioriza recencia
#    (actualmente stub=1.0 intra-d√≠a, activable cross-day futuro)

# Normalizaci√≥n: ‚àëweights = 1.0 por ticker-day
```

* Par√°metros clave:
    - `--uniqueness`: Ajusta por concurrency (evita overfit a racimos temporales)
    - `--abs-ret-weight`: Peso base = |ret| (prioriza eventos significativos)
    - `--time-decay-half_life 90`: Semivida 90 d√≠as (hook preparado para cross-day)

`OUTPUT`:
- `processed/weights/{ticker}/date={YYYY-MM-DD}/weights.parquet`
- **64,801 archivos** (100% completitud)
- Schema: `{anchor_ts, weight}`



> --- 
> EVIDENCIA de resultados: 
> * [D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md)     
> * [validacion_dib&labels_executed](./fase_01/D_creando_DIB_VIB_2004_2025/notebooks/validacion_dib&labels_executed.ipynb)  
> ...    

---

#### [D.4] ML Dataset Builder (Features + Walk-Forward Split)

---


**Script**: `scripts/fase_D_creando_DIB_VIB/build_ml_daser.py`

`INPUT`:
- `processed/bars/{ticker}/date={day}/dollar_imbalance.parquet`
- `processed/labels/{ticker}/date={day}/labels.parquet`
- `processed/weights/{ticker}/date={day}/weights.parquet`

`TRANSFORMACI√ìN`:
```python
# 1. Feature Engineering (14 columnas intraday):
ret_1 = log(c / c_prev)
range_norm = (h - l) / |c_prev|
vol_f, dollar_f, imb_f = volume/dollar/imbalance fractional changes
ret_1_ema10, ret_1_ema30, range_norm_ema20, ...
vol_z20, dollar_z20 = z-scores volumen/d√≥lar (20-bar window)

# 2. Join componentes:
dataset = bars.join(labels, left_on="t_close", right_on="anchor_ts")
              .join(weights, on="anchor_ts")

# 3. Walk-Forward Split (no aleatorio):
timeline = sorted(anchor_ts)
train = primeros 80% d√≠as - purge_bars=50
valid = √∫ltimos 20% d√≠as

# Purged K-Fold: gap 50 barras entre train/valid (evita leakage temporal)
```

* Par√°metros clave:
    - `--split walk_forward`: Split temporal (no random)
    - `--folds 5`: Divide timeline en 5 folds
    - `--purge-bars 50`: Embargo period entre train/valid
    - `--parallel 12`: Workers concurrentes

`OUTPUT`:
- `processed/datasets/daily/{ticker}/date={day}/dataset.parquet` (**64,801 archivos**)
- `processed/datasets/global/dataset.parquet` (**4,359,730 rows**)
- `processed/datasets/splits/train.parquet` (**3,487,734 rows, 80.0%**)
- `processed/datasets/splits/valid.parquet` (**871,946 rows, 20.0%**)
- `processed/datasets/meta.json` (metadata: features, folds, purge, stats)

**Features generadas (14)**:
```
ret_1, range_norm, vol_f, dollar_f, imb_f,
ret_1_ema10, ret_1_ema30, range_norm_ema20,
vol_f_ema20, dollar_f_ema20, imb_f_ema20,
vol_z20, dollar_z20, n
```

> ---  
> EVIDENCIA de resultados: 
> * [D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md](./fase_01/D_creando_DIB_VIB_2004_2025/D.1_Ejecucion_Pipeline_DIB_Labels_Weights.md) )  
> * [validacion_ml_dataset_executed](./fase_01/D_creando_DIB_VIB_2004_2025/notebooks/validacion_fase4_ml_dataset_executed.ipynb)  
> ...  


---

### ..  / A_universo / [1_influencia_MarcosLopezDePadro.md](fase_01/A_Universo/1_influencia_MarcosLopezDePadro.md)

**Obtetivo** : Construir m√∫ltiples tipos de barras para comparaci√≥n.

1. **Descargar tick data de Polygon:**

   - `/v3/trades/{ticker}` ‚Üí precio, volumen, timestamp, condiciones
   - `/v3/quotes/{ticker}` ‚Üí bid/ask spread para tick rule mejorado

2. **Construir m√∫ltiples tipos de barras para comparaci√≥n:**

   **a) Dollar Bars (baseline):**
   **b) Dollar Imbalance Bars (DIBs) - RECOMENDADO para pumps:**
   **c) Dollar Runs Bars (DRBs) - Para detectar sweeping agresivo:**

3. **Validar propiedades estad√≠sticas** (ejercicios del Cap√≠tulo 2):
   - Contar barras por semana ‚Üí DIBs/DRBs deben ser m√°s estables que time bars
   - Medir correlaci√≥n serial de retornos ‚Üí debe ser menor en information-driven bars
   - Test de normalidad (Jarque-Bera) ‚Üí retornos deben estar m√°s cerca de Gaussiana



---


